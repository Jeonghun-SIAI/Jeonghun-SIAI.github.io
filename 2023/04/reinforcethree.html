<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">

<head>
  <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 3) Deep Q-learning을 통한 discrete control 도출 | A test page</title>
<meta name="description" content="이전 포스팅에서도 언급했듯, 이 문제에서 state는 직전 24시간 동안의 태양광 발전량과 부하 및 직전 1시간의 배터리 내 에너지양이고, action은 1.1kW 수전/ 1.1kW 송전/ idle 3가지이다. (action 인덱스는 0,1,2라 하자). 이 때 심층신경망은 state를 입력받아 3개 action 각각의 Q-value의 추정치 $\hat{Q}(s_{t},0), \hat{Q} (s_{t},1), \hat{Q} (s_{t},2)$ 를 출력으로 계산한다. 이 심층신경망은 매 훈련 주기마다 튜플 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다.">


  <meta name="author" content="Jeonghun Song">
  
  <meta property="article:author" content="Jeonghun Song">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="A test page">
<meta property="og:title" content="강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 3) Deep Q-learning을 통한 discrete control 도출">
<meta property="og:url" content="http://localhost:4000/2023/04/reinforcethree.html">


  <meta property="og:description" content="이전 포스팅에서도 언급했듯, 이 문제에서 state는 직전 24시간 동안의 태양광 발전량과 부하 및 직전 1시간의 배터리 내 에너지양이고, action은 1.1kW 수전/ 1.1kW 송전/ idle 3가지이다. (action 인덱스는 0,1,2라 하자). 이 때 심층신경망은 state를 입력받아 3개 action 각각의 Q-value의 추정치 $\hat{Q}(s_{t},0), \hat{Q} (s_{t},1), \hat{Q} (s_{t},2)$ 를 출력으로 계산한다. 이 심층신경망은 매 훈련 주기마다 튜플 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다.">







  <meta property="article:published_time" content="2023-04-17T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/2023/04/reinforcethree.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Jeonghun Song",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="A test page Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



  <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<head>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
</head>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    </script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<!-- end custom head snippets -->
</head>

<body
  class="layout--single">
  <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

  

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="A test page"></a>
        
        <a class="site-title" href="/">
          A test page
          <span class="site-subtitle">learning Github Page</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/aboutme/">About Me</a>
            </li><li class="masthead__menu-item">
              <a href="/search/">Search</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tag</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">카테고리 목록</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


  <div class="initial-content">
    




  
    



<nav class="breadcrumbs">
  <ol itemscope itemtype="https://schema.org/BreadcrumbList">
    
    
    
      
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/" itemprop="item"><span itemprop="name">Home</span></a>

          <meta itemprop="position" content="1" />
        </li>
        <span class="sep">/</span>
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#2023" itemprop="item"><span itemprop="name">2023</span></a>
          <meta itemprop="position" content="2" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        
        <li itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem">
          <a href="/categories/#04" itemprop="item"><span itemprop="name">04</span></a>
          <meta itemprop="position" content="3" />
        </li>
        <span class="sep">/</span>
      
    
      
      
        <li class="current">강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 3) Deep Q-learning을 통한 discrete control 도출</li>
      
    
  </ol>
</nav>

  


<div id="main" role="main">
  

  <div class="sidebar sticky">
    
  
  
  
  
    
    
      
    
    
  
  
   <!-- three lines added by Jeonghun  -->
    

<nav class="nav__list">
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">카테고리 목록</label>
  <ul class="nav__items" id="category_tag_menu">
      <!--전체 글 수-->
      
      <li>
        <!--span 태그로 카테고리들을 크게 분류 ex) C/C++/C#-->
        <span class="nav__sub-title">범주1</span>
            <!--ul 태그로 같은 카테고리들 모아둔 페이지들 나열-->
            <ul>
                <!--Cpp 카테고리 글들을 모아둔 페이지인 /categories/cpp 주소의 글로 링크 연결-->
                <!--category[1].size 로 해당 카테고리를 가진 글의 개수 표시--> 
                
                    
                
                    
                
                    
                        <li><a href="/code" class="">코드 (1)</a></li>
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                        <li><a href="/theory" class="">이론 (2)</a></li>
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/energy" class="">에너지 (17)</a></li>
                    
                
            </ul>
        <span class="nav__sub-title">범주2</span>
            <ul>
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/project" class="">프로젝트 (1)</a></li>
                    
                
                    
                
            </ul>
            <ul>
                
                    
                        <li><a href="/etc" class="">기타 (3)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
      </li>
  </ul>
</nav>
  
  

  </div>




  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 3) Deep Q-learning을 통한 discrete control 도출">
    <meta itemprop="description" content="이전 포스팅에서도 언급했듯, 이 문제에서 state는 직전 24시간 동안의 태양광 발전량과 부하 및 직전 1시간의 배터리 내 에너지양이고, action은 1.1kW 수전/ 1.1kW 송전/ idle 3가지이다. (action 인덱스는 0,1,2라 하자). 이 때 심층신경망은 state를 입력받아 3개 action 각각의 Q-value의 추정치 $\hat{Q}(s_{t},0), \hat{Q} (s_{t},1), \hat{Q} (s_{t},2)$ 를 출력으로 계산한다. 이 심층신경망은 매 훈련 주기마다 튜플 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다.">
    <meta itemprop="datePublished" content="2023-04-17T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/2023/04/reinforcethree.html" class="u-url" itemprop="url">강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 3) Deep Q-learning을 통한 discrete control 도출
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-17T00:00:00+09:00">2023-04-17</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Contents</h4></header> 
              
 <!-- 우측 TOC -->
            </nav>
          </aside>
        
        <p>이전 포스팅에서도 언급했듯, 이 문제에서 state는 직전 24시간 동안의 태양광 발전량과 부하 및 직전 1시간의 배터리 내 에너지양이고, action은 1.1kW 수전/ 1.1kW 송전/ idle 3가지이다. (action 인덱스는 0,1,2라 하자). 이 때 심층신경망은 state를 입력받아 3개 action 각각의 Q-value의 추정치 $\hat{Q}(s_{t},0), \hat{Q} (s_{t},1), \hat{Q} (s_{t},2)$ 를 출력으로 계산한다. 이 심층신경망은 매 훈련 주기마다 튜플 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다.</p>

<p><br />
심층신경망 구성은 아래 그림과 같다.</p>

<p><img src="/assets/images/reinforcethree/nn.png" alt="nn" class="align-center" /></p>

<p>직전 24시간의 태양광 발전량은 첫 번째 Conv1D 층에, 직전 24시간의 부하는 두 번째 Conv1D 층에, 그리고 직전 1시간의 배터리 내 에너지양은 위 두 Conv1D층과 연결되는 Dense층에 바로 연결된다. 그리고 Dense층이 하나 더 있고, 이 층을 거쳐서 최종적으로 3개의 output node가 각 action별 Q-value를 출력한다.</p>

<p>해당 심층신경망 훈련을 위한 training set은 특정 2년 (17,520시간) 동안의 시간별 태양광발전량과 부하 자료이다. 해당 모델이 직전 24시간의 정보를 state로 사용하므로 control은 $t=25,26,\cdots, 17520$ 에 대해 정해진다. Validation set은 별도의 특정 1년 (8,760시간) 동안의 시간별 태양광 발전량과 부하 자료이다.</p>

<p>Training set에 대해서는 epsilon-greedy policy를, validation set에 대해서는 greedy policy를 적용해 action을 결정한다. 매 시간별로 에너지 흐름을 계산하고, 매 24시간 주기로 심층신경망 훈련을 gradient descent로 수행한다. 이를 training set의 17,520-24 시간에 대해 수행하면 1 epoch이다.</p>

<p><br />
이제 훈련 concept는 대략 이해가 될 것이니, 코드를 보자.</p>

<p>(이 코드는 본인이 직접 작성하였다. 마이크로그리드 케이스에 대한 학위논문에서 저자가 사용한 코드의 Github 링크를 제공하나, 각 모듈별로 코드 파일들을 지나치게 분리해 놓아 사용이 여의치 않았다. 이에 필자가 ‘모든 기능들을 한 파일에 넣은 공부용’ 코드를 따로 만들었다. 다만 코드 작성 시 <a href="https://product.kyobobook.co.kr/detail/S000001810262">핸즈온 머신러닝</a>의 강화학습 chapter의 Cartpole 예제에 대한 Deep Q-Network 코드를 많이 참고하였음을 밝힌다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="c1">### hyperparameters
</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span> <span class="c1"># learning rate 너무 높으면 발산할 수 있음에 주의
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.98</span>
<span class="n">period_step_fortrain</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">rewardscalefactor</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">20000</span>



<span class="c1">### microgrid system data
</span>
<span class="n">PV_prod_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_train.npy'</span><span class="p">)</span> <span class="c1"># [0,1] 구간 내로 scaled된 데이터임, unscaling은 play_one_step 함수 내에서 이루어짐
</span><span class="n">PV_prod_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_test.npy'</span><span class="p">)</span> 

<span class="n">load_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_train.npy'</span><span class="p">)</span> <span class="c1"># [0,1] 구간 내로 scaled된 데이터임, unscaling은 play_one_step 함수 내에서 이루어짐
</span><span class="n">load_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_test.npy'</span><span class="p">)</span>

<span class="n">prate_h2</span> <span class="o">=</span> <span class="mf">1.1</span> <span class="c1"># 수전/송전 상한
</span><span class="n">eff_h2</span> <span class="o">=</span> <span class="mf">0.65</span> <span class="c1"># 수소-전기 변환효율
</span>
<span class="n">capa_batt</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1"># 배터리 용량 (겉보기용량 말고 SOC 상하한 고려한 실용량이라 가정)
</span><span class="n">eff_batt</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># 배터리 충방전 효율
</span><span class="n">initialenergy_batt</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># epoch의 시작에서 배터리 내 에너지량 (최대저장가능량 대비 상대비율, Qval NN에는 이 상대비율이 입력되며, play_one_step 함수 내에서의 에너지시스템 밸런스 수식에서는 실제 에너지값으로 변환됨
</span>
<span class="n">price_h2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">cost_loss</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">load_peak</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pv_peak</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">inputlen_load</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">inputlen_pv</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### Neural net configuration
</span>
<span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">input_load</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 과거 24시간의 부하, shape의 두번째 숫자는 채널 수 (컬러사진의 RGB 등), 채널 수를 정의해야 Conv1D가 작동함
</span><span class="n">input_pv</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 과거 24시간의 태양광발전량
</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">input_load</span><span class="p">)</span>
<span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">input_pv</span><span class="p">)</span>
<span class="n">concat_conv</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">concat_conv</span><span class="p">)</span>
<span class="n">flatten_conv</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">()(</span><span class="n">hidden_conv_concat</span><span class="p">)</span> <span class="c1"># Dense층 직전에 Conv층을 Flatten해야 함
</span><span class="n">input_others</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 직전 시간의 배터리 내 에너지량
</span><span class="n">concat_all</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">input_others</span><span class="p">])</span> 
<span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">concat_all</span><span class="p">)</span>
<span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">hidden_dense_1</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">n_outputs</span><span class="p">)(</span><span class="n">hidden_dense_2</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>



<span class="k">def</span> <span class="nf">e_greedy_policy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span><span class="n">epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span> <span class="c1"># epsilon-greedy policy
</span>    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span> <span class="c1"># exploration
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># action을 랜덤하게 선택
</span>    <span class="k">else</span><span class="p">:</span> <span class="c1"># exploitation
</span>        <span class="n">input_load</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Conv1D의 input이므로 채널 수 1 명시
</span>        <span class="n">input_pv</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">input_others</span> <span class="o">=</span><span class="n">state</span><span class="p">[(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Dense층의 input이므로 채널 수는 필요 없음
</span>        <span class="n">Q_values</span> <span class="o">=</span> <span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span> <span class="c1"># 각 action 별 Q-value 도출
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 가장 큰 Q-value에 대응하는 action 선택      
</span>        <span class="c1"># 주의: for loop 안에서 DNN에 input을 입력해 output 계산 시 model()로 해야지, model.predict()로 하면 안 됨! 메모리 누수가 발생함 (model.predict는 대량의 input data를 'model.predict를 한 번만 호출해서' 처리하는 데 특화됨, https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict 참고)
</span>


<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="n">replay_buffer</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span> <span class="c1"># replay buffer 정의의
</span>
<span class="k">def</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> <span class="c1"># batch_size만큼의 경험들의 state들, action들, reward들, nextstate들의 리스트들을 반환
</span>    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1"># replay buffer 내 경험들 중 랜덤하게 batch_size만큼의 경험들을 지정 (인덱스 불러옴)
</span>    <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span> <span class="c1"># 위에서 불러온 인덱스를 이용해 batch_size 만큼의 경험들을 batch 리스트에 담음
</span>    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">experience</span><span class="p">[</span><span class="n">field_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span> <span class="c1"># 하나의 array 안에 batch 내 각 경험별 값들이 들어감 
</span>        <span class="k">for</span> <span class="n">field_index</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span> <span class="c1"># 총 4개의 array를 반환, 각각은 (batch 내 sample경험들의) state들, action들, reward들, nextstate들의 리스트임
</span>    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span>



<span class="k">def</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">profile_load</span><span class="p">,</span><span class="n">profile_pv</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]))</span> <span class="p">)</span>
    
    <span class="n">action</span> <span class="o">=</span> <span class="nf">e_greedy_policy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span><span class="n">epsilon</span><span class="p">)</span> <span class="c1"># epsilon-greedy policy에 따라 action 도출
</span>    <span class="n">p_h2_send</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 수소로 생산된 전기 수전
</span>        <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="n">prate_h2</span>
    <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># 수소 생산용 전기 송전
</span>        <span class="n">p_h2_send</span> <span class="o">=</span> <span class="n">prate_h2</span>
       

    <span class="n">p_load</span> <span class="o">=</span> <span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">load_peak</span> <span class="c1"># 현재 시간의 부하 (action 결정 기준이 아님!), 입력자료가 [0,1]로 scaled된 걸 unscaling
</span>    <span class="n">p_pv</span> <span class="o">=</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">pv_peak</span> <span class="c1"># 현재 시간의 발전량 (action 결정 기준이 아님!), 입력자료가 [0,1]로 scaled된 걸 unscaling  
</span>    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">capa_batt</span> <span class="c1"># 입력자료가 [0,1]로 scaled된 걸 unscaling
</span>    
    <span class="c1">#p_curtail = 0
</span>    <span class="n">p_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">p_net_beforebatt</span> <span class="o">=</span> <span class="n">p_pv</span> <span class="o">-</span> <span class="n">p_load</span> <span class="o">+</span> <span class="n">p_h2_receive</span> <span class="o">-</span> <span class="n">p_h2_send</span> <span class="c1"># 태양광 생산, 부하 충족, H2 보내거나 받은 후 수용가 입장에서 전기에너지가 남으면 양수, 부족하면 음수
</span>    
    <span class="k">if</span> <span class="n">p_net_beforebatt</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 전기에너지가 남으므로 배터리에 저장하고, 만약 배터리도 꽉 찬다면 curtail함
</span>        <span class="k">if</span> <span class="n">capa_batt</span> <span class="o">&gt;=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span><span class="p">:</span> <span class="c1"># 배터리에 잔여 충전 가능한 에너지가 위에서 남은 에너지(에서 변환손실 제한 에너지) 이상일 경우
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># 남은 에너지를 배터리에 다 충전하면 꽉 차고도 남아서, curtail해야 함
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">capa_batt</span>
            <span class="c1">#p_curtail = (energy_batt + p_net_beforebatt*eff_batt - capa_batt)/eff_batt # 괄호 안은 배터리 내부 기준이며, 수용가 모선 기준 양을 구하려면 eff_batt로 나눠줘야 함
</span>    <span class="k">else</span><span class="p">:</span> <span class="c1"># 전기에너지가 부족하므로 배터리 에너지를 써야 함, 배터리 에너지로도 부족하면 loss임
</span>        <span class="k">if</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span><span class="p">:</span> <span class="c1"># 배터리 에너지로 충당 가능한 경우
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">/</span><span class="n">eff_batt</span> <span class="c1"># p_net_beforebatt가 음수이므로 마이너스값이 부족한 에너지'량'이고 그걸 '빼'므로 결과적으로 플러스
</span>        <span class="k">else</span><span class="p">:</span> <span class="c1"># 부족해 loss 발생
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">p_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span> <span class="o">-</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span>           
    
    <span class="n">reward</span> <span class="o">=</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_send</span><span class="o">*</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_receive</span><span class="o">/</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">cost_loss</span><span class="o">*</span><span class="n">p_loss</span>
    <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt_after</span><span class="o">/</span><span class="n">capa_batt</span> <span class="c1"># 배터리 내 저장량을 [0,1] 범위로 scaling함
</span>    
    <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_load</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt_after</span><span class="p">]))</span> <span class="p">)</span>         
        <span class="n">replay_buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="o">*</span><span class="n">rewardscalefactor</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span> <span class="c1"># replay buffer에는 scaled reward를 넣으며, tuple을 append함에 주의
</span>    <span class="k">return</span> <span class="n">energy_batt_after</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="c1"># scaled 배터리 내 저장량, unscaled reward, action index 반환
</span>


<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>

    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">input_load</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">input_pv</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">input_load_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_pv_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
      
    <span class="n">next_Q_values</span> <span class="o">=</span> <span class="nf">model</span><span class="p">((</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">))</span> <span class="c1"># Q-learning을 위해, 'next'state에서의 각 action 별 Q-value 추정치들 반환
</span>    <span class="n">max_next_Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">next_Q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 각 경험별로 nextstate에 대한 Q-value가 더 높은 행동의 Q-value 사용
</span>    <span class="n">target_Q_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">max_next_Q_values</span><span class="p">)</span> <span class="c1"># Q-value를 reward와 nextstate에 대한 Q-value(discounted)의 합으로 표현
</span>    <span class="n">target_Q_values</span> <span class="o">=</span> <span class="n">target_Q_values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 뒤의 Q_values와 차원 맞춰줌
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span> <span class="c1"># 각 경험 별 action을 one-hot encoding 형태로 만들어줌 (각 행이 경험)
</span>    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> <span class="c1"># 자동 미분
</span>        <span class="n">all_Q_values</span> <span class="o">=</span> <span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span> 
        <span class="n">Q_values</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">all_Q_values</span> <span class="o">*</span> <span class="n">mask</span><span class="p">,</span> <span class="c1"># mask를 곱해서, 각 경험별로 그 state에서 취하지 않은 action에 대해서는 Q-value에 0이 곱해지도록 함
</span>                                 <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># 각 행 별 합을 구함, 위의 masking 덕분에 그 state에서 취한 action에 대한 Q-value가 됨, keepdims를 True로 설정해 2차원 행렬 형태 유지
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">target_Q_values</span><span class="p">,</span><span class="n">Q_values</span><span class="p">))</span> <span class="c1"># 평균제곱오차 계산
</span>    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="c1"># loss 함수를 model의 trainable variables 전체에 대해 미분
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span> <span class="c1"># Adam optimizer로 parameter update 수행, zip으로 gradient와 parameter pair를 맞춰줌
</span>


<span class="n">profits_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">elapsedtime_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_return_test</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 맨 첫 번째 epoch에서는 훈련을 시작하지 않고 buffer를 채움, 두 번째 epoch부터는 buffer에 sample들이 채워졌으므로 훈련함
</span>        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    
    <span class="c1">### Train for each epoch
</span>    
    <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> <span class="c1"># 시작시점
</span>    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>  <span class="c1"># 배터리 내 에너지의 초기값
</span>    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_train</span><span class="p">)</span><span class="o">-</span><span class="mi">25</span><span class="p">):</span> <span class="c1"># 데이터 내의 마지막 시점이 nextstate에만 포함될 때까지 (대신 termination state는 따로 없음)
</span>        <span class="n">count_step_fortrain</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epoch</span> <span class="o">/</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span> <span class="c1"># epsilon을 1에서 시작해 조금씩 선형적으로 줄임, 이 경우 초반에는 거의 다 exploration이므로 한 epoch가 매우 빨리 계산되나, 중반을 넘어가면 거의 exploitation이며 이 때 매 step마다 DNN을 call하므로 느려짐
</span>        <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_train</span><span class="p">,</span><span class="n">PV_prod_train</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># energy_batt가 반복 갱신됨
</span>        <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># 다음 시간으로  
</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">count_step_fortrain</span> <span class="o">&gt;</span> <span class="n">period_step_fortrain</span><span class="p">:</span> <span class="c1"># 훈련 주기
</span>                <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1"># DNN 훈련을 위한 Gradient Descent 수행
</span>                <span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>


    <span class="c1">### Validation for each epoch  
</span>    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">testcase_actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">testcase_battenergy</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">epoch_return_test</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># return (각 시점별 수익의 총 합) 초기화
</span>        
        <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> <span class="c1"># 시작시점   
</span>        <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span> <span class="c1"># 배터리 내 에너지의 초기값
</span>        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_test</span><span class="p">)</span><span class="o">-</span><span class="mi">24</span><span class="p">):</span> <span class="c1"># 데이터 내의 마지막 시점이 nextstate에만 포함될 때까지 (대신 termination state는 따로 없음)
</span>            <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_test</span><span class="p">,</span><span class="n">PV_prod_test</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># energy_batt가 반복 갱신됨
</span>            <span class="n">testcase_actions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">testcase_battenergy</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">energy_batt</span><span class="p">)</span>
            <span class="n">epoch_return_test</span> <span class="o">+=</span> <span class="n">reward</span> <span class="c1"># 누적보상 계산
</span>            <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># 다음 시간으로    
</span>        
        <span class="n">profits_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">)</span> <span class="c1"># 각 epoch별 총 수익 로그 저장
</span>        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_profit_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">profits_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                
        <span class="k">if</span> <span class="n">max_return_test</span> <span class="o">&lt;</span> <span class="n">epoch_return_test</span><span class="p">:</span> <span class="c1"># Validation set에서의 총 수익의 최대값값 갱신시마다 저장 (unlearn하게 되더라도 중간에 best performance였던 모델을 남김김)
</span>            <span class="n">max_return_test</span> <span class="o">=</span> <span class="n">epoch_return_test</span>
            <span class="n">model</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'trainedmodel_dqn.h5'</span><span class="p">)</span> <span class="c1"># 모델 가중치 저장
</span>                    
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_actions_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># Validation case에서의 시간별 action 로그 저장
</span>                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_actions</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_battenergy_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># Validation case에서의 시간별 배터리 내 저장된 에너지 로그 저장
</span>                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_battenergy</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                        
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>   
        <span class="n">elapsedtime_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"Validation: profit of epoch {} is {}, maximum profit is {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="nf">round</span><span class="p">(</span><span class="n">max_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'one epoch 수행에 {}초 걸렸습니다'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_time_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># 각 epoch별 소요시간 로그 장장
</span>            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">elapsedtime_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>코드의 주요 부분은 다음과 같다.</p>

<p>(하이퍼파라미터들 설정 -&gt; 훈련이 안 될 경우 바꿔줌, 이를테면 learning rate를 너무 크게 하면 발산하므로 충분히 작게 해야 함)</p>

<p>(시스템 파라미터 및 데이터)</p>

<p>(심층신경망 정의)</p>

<p>(epsilon-greedy policy 수행: epsilon의 확률로 0,1,2 중 하나의 action을 완전 랜덤하게, 1-epsilon의 확률로 심층신경망의 계산 결과 중 가장 큰 값에 대응하는 action을 선택. 이 때 model.predict()가 아니라 model()을 써야 함에 주의. model.predict()를 쓰면 메모리 누수가 발생한다.)</p>

<p>(훈련 동안 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 튜플들을 저장하는 replay buffer 정의)</p>

<p>(시스템 모델, 즉 매 시간별로 state를 알고 action을 결정했을 때 에너지시스템 내의 에너지 흐름을 계산하고, 그 결과인 손익 및 배터리 내 에너지 저장량을 계산함, 훈련 시 이를 replay buffer에도 저장함. 데이터가 미리 0~1 사이로 스케일링되어 있으므로 에너지 흐름 계산을 위해서는 unscaling해주며, replay buffer에 대한 tuple은 다시 scaled된 값으로 둠에 주의)</p>

<p>(심층신경망 훈련을 Gradient descent로 진행. 목적함수는 $\hat{Q}(s_{t},a_{t})$와 $r_{t+1} + \gamma \text{max}_{a_{t+1}} \hat{Q}(s_{t+1},a_{t+1})$ 간 차이의 평균제곱합임, input이 0~1 사이로 스케일된 데이터임에 주의)</p>

<p>(training과 validation을 반복문으로 수행, Exploration은 DQN에서는 e-greedy (epsilon 값을 1부터 시작해서 일정 수준까지 낮춤, 매 시간마다 train하면 1epoch 시간이 너무 길어지고 overfitting 우려도 있어, 매 24시간마다 훈련함, 첫 epoch는 replay buffer를 채우고 나머지 99 epoch 동안 훈련함, 1epoch 계산 시간이 긴 이유: 매 step별로 action 결정시마다 Qnet 또는 actor로 계산해야 하기 때문 (이를 8760x2-24번 해야 하므로), 심지어 validation set에 대한 metric 계산 시에도 마찬가지이므로 (여기서 또 8760-24번)</p>

<p><br />
훈련을 수행하면, validation case 기준으로 불과 몇 epoch만에 누적 비용이 200유로 이하로 줄어든다 (random control에서 누적비용이 2500~2700유로였음). 그리고 99 epoch 훈련 동안 validation case에 대해 가장 좋은 결과를 보인 모델의 경우 누적 비용이 27유로이다. Random control 대비해서, 이상적인 선형계획처럼 미래를 알 때의) control 시의 비용 -50유로에 근접했다. 과거 24시간 정보만 갖고 control한 것 치고는 훌륭해 보인다.</p>

<p>Action인 계통 수전/송전 패턴이 선형계획과 DQN에서 각각 어떻게 결정되었는지를 아래 그림과 같이 보자.</p>

<p>(그림)</p>

<p>대체로 비슷한 편임, LP 솔루션 기준으로 수전하는 시간대에 DQN 솔루션에서도 수전하고, LP에서 송전하는 시간대에 DQN에서도 송전하고, LP에서 idle인 시간대에 DQN에서도 idle임, LP는 continuous임에도 최대송전/최대수전/idle인 경우도 많다는 점이 특기할 만함. 그래도 송전/수전/idle의 지속시간은 차이가 있고, 이 3개 값이 아닌 다른 값인 경우도 분명히 존재함, 즉 최대량이 아닌 양으로 송전/수전하는 경우가 있음.</p>

<p><br />
그렇다면 discrete action으로 단순화하지 않고, -1.1에서 +1.1 사이의 실수로 action을 도출하는 continuous control을 위한 심층강화학습 기법을 쓰면, 이런 최대량이 아닌 송전/수전까지 반영한 controller를 훈련함으로써 validation case에 대해 더 낮은 비용을 달성하는 것도 가능할 것으로 기대된다.</p>

<p>다음 포스팅에서는 continuous control을 위한 심층강화학습 중 가장 기본적이면서 중요한 방법인 Deep Deterministic Policy Gradient (DDPG) 를 적용하는 방법 및 결과를 설명한다.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#beautifulsoup" class="page__taxonomy-item p-category" rel="tag">BeautifulSoup</a><span class="sep">, </span>
    
      <a href="/tags/#python" class="page__taxonomy-item p-category" rel="tag">python</a>
    
    </span>
  </p>



<!-- 
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#energy" class="page__taxonomy-item p-category" rel="tag">Energy</a>
    
    </span>
  </p>

 -->
        <!-- 

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time class="dt-published" datetime="2023-04-17T00:00:00+09:00">2023-04-17</time></p>
 -->
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <!-- <a href="https://twitter.com/intent/tweet?text=%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5+%EA%B8%B0%EB%B0%98+%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EA%B7%B8%EB%A6%AC%EB%93%9C+%EB%82%B4+%EB%B0%B0%ED%84%B0%EB%A6%AC+%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81+-+3%29+Deep+Q-learning%EC%9D%84+%ED%86%B5%ED%95%9C+discrete+control+%EB%8F%84%EC%B6%9C%20http%3A%2F%2Flocalhost%3A4000%2F2023%2F04%2Freinforcethree.html" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> -->

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F2023%2F04%2Freinforcethree.html" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2F2023%2F04%2Freinforcethree.html" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      <p></p>
        <h4 class="page__meta-title"><span>Energy</span> <span>카테고리 내 다른 글 보러가기</span></h4>
        


  

  

  

  

  

  
  	
  	
  	
  	
  	

<nav class="pagination_prev_next"> <!-- 식빵맘 코드에서 조금 수정함 -->

  
    
      <a href="/2023/04/reinforcefour.html" class="pagination_prev_next--pager"><span class="prev_next">다음 글  &nbsp  </span>강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 4) DDPG를 통한 continuous control 도출</a>
    
    
      <a href="/2023/04/reinforcetwo.html" class="pagination_prev_next--pager"><span class="prev_next">이전 글  &nbsp</span>강화학습 기반 마이크로그리드 내 배터리 스케줄링 - 2) Q-learning 개념</a>
        
  

</nav>
      <p></p>
    </div>

    
  </article>

  
  <!-- 
    <div class="page__related">
      <h2 class="page__related-title">참고</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/logo.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/2023/04/monthlyenergythree.html" rel="permalink">건축물 별 월별 에너지 사용량 데이터셋 - 3) 월별 사용량 크기가 이상한 data point 제거
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-23T00:00:00+09:00">2023-04-23</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">저번 포스팅에서는 건물 월별 에너지 사용량의 ‘추이’가 이상한 data point를 판별하는 방법을 설명했다. 이번 포스팅에서는 월별 에너지 사용량의 ‘크기(magnitude)’가 이상한 data point를 판별하는 방법을 설명한다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/logo.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/2023/04/monthlyenergytwo.html" rel="permalink">건축물 별 월별 에너지 사용량 데이터셋 - 2) 월별 사용 추이가 이상한 data point 제거
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-22T00:00:00+09:00">2023-04-22</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">이전 포스팅에서, 각 건물의 지번별/월별 전기와 도시가스 사용량 데이터를 소개하였다. 또한 이를 표제부와 결합해 건물 에너지 분석에 활용할 수 있으며, 그 결합 방법 또한 소개하였다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/logo.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/2023/04/cudadudnn.html" rel="permalink">WSL2 Ubuntu 22.04에 CUDA &amp; cuDNN 설치하기
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-21T00:00:00+09:00">2023-04-21</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">자신의 NVIDIA 그래픽카드 모델명에 맞는 NVIDIA driver를 다운로드 웹페이지 찾아서 윈도우에서 설치
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/logo.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/2023/04/monthlyenergyone.html" rel="permalink">건축물 별 월별 에너지 사용량 데이터셋 - 1) 모든 월에 대한 통합 및 표제부와의 결합 후 SQLite DB화
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-20T00:00:00+09:00">2023-04-20</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">필자에게 있어 각별한 데이터셋이 있다. (비주거용) 건축물 별 월별 에너지 사용량 데이터셋이다. 각지번 주소 단위의 개별 비주거용 건물별로 특정 월에 소비한 전기와 가스의 양을 kWh 단위로 기록한 데이터셋이다.
</p>
  </article>
</div>

        
      </div>
    </div> -->
  
  <!--  -->
</div>

  </div>

  

  <aside class="sidebar__top">
    <a href="#site-nav"> <i class="fas fa-angle-double-up fa-2x"></i></a>
    </aside>

  <div id="footer" class="page__footer">
    <footer>
      <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
      <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
          <li><a href="https://github.com/Jeonghun-SIAI" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Jeonghun Song. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

    </footer>
  </div>

  
  <script src="/assets/js/main.min.js"></script>










</body>

</html>