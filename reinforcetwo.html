<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">

<head>
  <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>강화학습 기반 마이크로그리드 스케줄링 - 2) Q-learning 개념 | 에너지엔데이터연구소</title>
<meta name="description" content="지난 포스팅에서, Vincent의 태양광 기반 마이크로그리드의 누적 비용을 최소화하는 최적 control 문제를 소개했다. 또한 이를 선형계획법으로 풀 경우 ‘미래의 태양광 발전량과 부하를 안다’라는, ‘비현실적’인 가정 하에서 control을 얻게 됨을 논했다.">


  <meta name="author" content="Jeonghun Song">
  
  <meta property="article:author" content="Jeonghun Song">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="에너지엔데이터연구소">
<meta property="og:title" content="강화학습 기반 마이크로그리드 스케줄링 - 2) Q-learning 개념">
<meta property="og:url" content="http://localhost:4000/reinforcetwo.html">


  <meta property="og:description" content="지난 포스팅에서, Vincent의 태양광 기반 마이크로그리드의 누적 비용을 최소화하는 최적 control 문제를 소개했다. 또한 이를 선형계획법으로 풀 경우 ‘미래의 태양광 발전량과 부하를 안다’라는, ‘비현실적’인 가정 하에서 control을 얻게 됨을 논했다.">







  <meta property="article:published_time" content="2023-04-16T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/reinforcetwo.html">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Jeonghun Song",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="에너지엔데이터연구소 Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



  <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<head>
    <link rel="apple-touch-icon" sizes="144x144" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
</head>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        TeX: {
          equationNumbers: {
            autoNumber: "AMS"
          }
        },
        tex2jax: {
        inlineMath: [ ['$', '$'] ],
        displayMath: [ ['$$', '$$'] ],
        processEscapes: true,
      }
    });
    MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
          alert("Math Processing Error: "+message[1]);
        });
    </script>
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<!-- end custom head snippets -->
</head>

<body
  class="layout--single">
  <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

  

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/clean.jpg" alt="에너지엔데이터연구소"></a>
        
        <a class="site-title" href="/">
          에너지엔데이터연구소
          <span class="site-subtitle">스마트한 에너지 전환엔 데이터의 활용이 필요합니다</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/aboutme/">About Me</a>
            </li><li class="masthead__menu-item">
              <a href="/search/">Search</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Category</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tag</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">카테고리 목록</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


  <div class="initial-content">
    





<div id="main" role="main">
  

  <div class="sidebar sticky">
    
  
  
  
  
    
    
      
    
    
  
  
   <!-- three lines added by Jeonghun  -->
    

<nav class="nav__list">
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">카테고리 목록</label>
  <ul class="nav__items" id="category_tag_menu">
      <!--전체 글 수-->
      
      <li>
        <!--span 태그로 카테고리들을 크게 분류 ex) C/C++/C#-->
        <span class="nav__sub-title">Categories</span>
            <!--ul 태그로 같은 카테고리들 모아둔 페이지들 나열-->
            <ul>
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/optimalsystem" class="">Optimal system (7)</a></li>
                    
                
                    
                
                    
                
            </ul>
            <ul>
                <!--Cpp 카테고리 글들을 모아둔 페이지인 /categories/cpp 주소의 글로 링크 연결-->
                <!--category[1].size 로 해당 카테고리를 가진 글의 개수 표시--> 
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/energymanagement" class="">EMS (5)</a></li>
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                        <li><a href="/estimation" class="">Estimation (2)</a></li>
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                        <li><a href="/dataset" class="">Dataset (4)</a></li>
                    
                
                    
                
            </ul>
            <ul>
                
                    
                        <li><a href="/mathstat" class="">Math. & Stat. (2)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
            <ul>
                
                    
                
                    
                        <li><a href="/etc" class="">Etc. (2)</a></li>
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
      </li>
  </ul>
</nav>
  
  

  </div>




  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="강화학습 기반 마이크로그리드 스케줄링 - 2) Q-learning 개념">
    <meta itemprop="description" content="지난 포스팅에서, Vincent의 태양광 기반 마이크로그리드의 누적 비용을 최소화하는 최적 control 문제를 소개했다. 또한 이를 선형계획법으로 풀 경우 ‘미래의 태양광 발전량과 부하를 안다’라는, ‘비현실적’인 가정 하에서 control을 얻게 됨을 논했다.">
    <meta itemprop="datePublished" content="2023-04-16T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/reinforcetwo.html" class="u-url" itemprop="url">강화학습 기반 마이크로그리드 스케줄링 - 2) Q-learning 개념
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-16T00:00:00+09:00">2023-04-16</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Contents</h4></header> 
              <ul class="toc__menu"><li><a href="#누적-보상의-개념">누적 보상의 개념</a></li><li><a href="#exploration탐색의-필요성">Exploration(탐색)의 필요성</a></li><li><a href="#stateaction이-무한할-경우">State/action이 무한할 경우</a></li><li><a href="#q-value-근사를-위한-딥러닝과-강화학습의-결합">Q-value 근사를 위한 딥러닝과 강화학습의 결합</a></li></ul>
 <!-- 우측 TOC -->
            </nav>
          </aside>
        
        <p>지난 포스팅에서, Vincent의 태양광 기반 마이크로그리드의 누적 비용을 최소화하는 최적 control 문제를 소개했다. 또한 이를 선형계획법으로 풀 경우 ‘미래의 태양광 발전량과 부하를 안다’라는, ‘비현실적’인 가정 하에서 control을 얻게 됨을 논했다.</p>

<p>이번 포스팅에서는 ‘매 시점별로 과거의 자료만을 갖고’ control하는 데 필요한 강화학습의 이론적 내용을 최대한 간단히 소개한다 (강화학습에 대한 상세 내용은 <a href="https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf">Sutton의 Introduction</a> 참고 바람)</p>

<p><br /></p>

<h2 id="누적-보상의-개념">누적 보상의 개념</h2>
<p>먼저 Q-learning을 간단히 되짚고 넘어가자. 어떤 환경에서 시점 t에 상태 $s_{t}$에 있고, 이 때 action $a_{t}$를 수행하면 보상 $r_{t+1}$을 받으면서 상태 $s_{t+1}$로 전이된다고 하자.</p>

<p><img src="/assets/images/reinforceone/reinforcement_basic.png" alt="reinforcement_basic" class="align-center" width="70%" />
<em>강화학습 개요. State $S_t$에서 Action $A_t$를 취하면 Reward $R_{t+1}$을 얻으면서 State $S_{t+1}$로 전이됨.</em></p>

<p>Vincent의 마이크로그리드 사례에서는, 상태는 $t-N, t-(N-1), …, t-1$ 시점들의 태양광발전량과 부하 및 $t-1$시점의 배터리 내 에너지량들의 총 $2N+1$차원 벡터로 두었고, action은 net 수전량 $p_{\text{import}}[t]-p_{\text{export}}[t]$이다 (net 송전 시 마이너스). 보상은 계통으로 송전시의 수익 (양의 보상) 또는 계통으로부터 수전하거나 loss of load가 발생할 때의 비용 (음의 보상) 이다.</p>

<p>참고로 ESS의 충/방전은 계통 수전/송전 값이 결정되면 에너지 밸런스를 맞추도록 자동으로 결정된다고 가정한다. 이런 식으로 action의 자유도(degree of freedom)을 줄여야 실제 계산이 용이해진다.</p>

<p><br />
이 때 ‘미래의 보상들을 합친 누적 보상의 기대값’ $Q(s_{t},a_{t})$는 다음과 같다.</p>

<p>$ Q(s_{t},a_{t}) = \mathbb{E} [r_{t+1} + \gamma r_{t+2} + \gamma^2 r_{t+3} + \cdots] $</p>

<p>우변에 기대값 기호 $ \mathbb{E}$가 붙은 이유는, 일반적으로는 같은 $s_{t}$에서 같은 $a_{t}$를 수행하더라도, 그 결과인 $r_{t+1}$과 $s_{t+1}$는 그때그때 다를 수 있으며 (즉 random, stochastic일 수 있음), 이에 따라 $t+1$시점 이후의 보상과 상태 전이도 달라질 수 있기 때문이다. 이번 마이크로그리드 케이스의 경우에도, 태양광 발전량과 부하는 외생적으로 random하게 결정되며 이에 따라 수전/송전량이 결정되므로 보상도 random하게 결정된다.</p>

<p>$\gamma$는 1보다는 작되 1에 가까운 양수로 discount factor이다. 이걸 곱하는 이유는 곱하지 않으면, 환경에서의 행동이 특정 시점에 반드시 끝나는 게 아닌 한 누적비용이 무한대가 될 수 있기 때문이다. Discount factor를 곱해줘야 누적비용이 유한한 값으로 보장된다.</p>

<p>그런데 시점 $t+1$에 대해서도 미래 누적 보상의 기대값 $Q(s_{t+1},a_{t+1})$이 정의되므로, 위 식은 아래와 같이 쓸 수 있다.</p>

<p>$ Q(s_{t},a_{t}) = \mathbb{E} [r_{t+1} + \gamma Q(s_{t+1},a_{t+1}) ] $</p>

<p>이 관계를 이용해서, 각 state-action pair $(s_{t},a_{t})$에 대해 $\hat{Q}(s_{t},a_{t})$를 iterative하게 계산한다. 실제로는 $Q(s_{t},a_{t})$의 정확한 값을 모르니까 모든 state-action pair들에 대해 0으로 초기화하고, 시점 $t$에서 action을 결정해서 $t+1$로 넘어갈 때마다 아래와 같이 업데이트 한다.</p>

<p>$ \hat{Q}(s_{t},a_{t}) \leftarrow (1-\alpha) \hat{Q}(s_{t},a_{t}) + \alpha [r_{t+1} + \gamma \text{max}_{a_{t+1}} \hat{Q}(s_{t+1},a_{t+1})] $</p>

<p>여기서 $\alpha$는 작은 양수로, learning rate이다. 우변의 max는 상태 $s_{t+1}$에서 누적보상을 최대화하는 행동을 선택한다는 가정이 반영된 결과이다. 이렇게 현재 state에서 가능한 모든 action들 중 state-action pair의 Q-value를 최대화하는 action만을 고르는 정책 (각 state에 대해 action을 도출하는 함수) 을 greedy policy라 한다.</p>

<p>시뮬레이션을 계속 함에 따라 실제 보상 $r_{t+1}$ 정보가 계속 반영되면서, $\hat{Q}(s_{t},a_{t})$이 점차 실제 $Q(s_{t},a_{t})$에 가까워짐이 알려져 있다. 이를 Q-learning이라 한다.</p>

<p>Vincent의 마이크로그리드 사례에서 실제 수전량은 -1.1에서 +1.1 사이의 실수이지만 (마이너스값은 송전), 문제를 간단히 하기 위해 세 가지의 discrete action들로 구성된 action set을 가정한다. 1.1kW로 수전, 1.1kW로 송전, 수전도 송전도 하지 않음 (0, idle)이다. 각 action의 인덱스를 0,1,2라 하자.</p>

<p>그러면 매 시점별로 $\hat{Q}(s_{t},0)$, $\hat{Q}(s_{t},1)$, $\hat{Q}(s_{t},2)$ 중에서 최대값에 대응하는 action을 선택하면 (greedy policy), 누적보상을 최대화하는 control이 될 것이다.</p>

<p><br /></p>

<h2 id="exploration탐색의-필요성">Exploration(탐색)의 필요성</h2>
<p>그러나 greedy policy는 controller 훈련을 끝낸 후 ‘validation 및 실제 구동 시’에 적용해야지, ‘훈련 중’에 적용하는 것은 적절하지 않다.</p>

<p>학습 초기에 아직 아무 정보도 학습하지 못했는데 단순히 $\hat{Q}$ 값이 가장 큰 action만을 계속 하는 것은, 마치 평균적 보상이 다른 여러 개의 슬롯머신을 눈 앞에 두고도, 처음에 고른 한두개의 슬롯머신만 계속 눌러보는 것과 비슷하다.</p>

<p>누적 보상을 최대화하려면 어떤 슬롯머신이 가장 (평균적으로) 큰 보상을 주는지 확인하는 절차가 먼저 필요하며, 이를 위해 초반에는 여러 슬롯머신들을 random하게 눌러봐야 한다. 강화학습에서는 이를 exploration(탐색)이라 한다.</p>

<p>탐색을 통해 어떤 슬롯머신이 보상을 많이 주는지 감이 잡히면 그때부터 보상을 많이 주는 슬롯머신을 계속 누르면 되며, 이를 exploitation이라 한다. Q-learning에서도 greedy policy는 exploitation’만’ 하는 것에 해당한다.</p>

<p>훈련 시에는 (특히 초반에는) exploration을 겸해서 해 줘야 더 좋은 action을 판별할 가능성이 열리기 때문에, 보통 주어진 확률 $\epsilon$으로 action을 $\hat{Q}$ 값에 상관없이 random하게 결정한다 ($1-\epsilon$의 확률로 $\hat{Q}$ 값이 최대가 되는 action을 고른다). 이를 epsilon-greedy policy라 한다. (물론 훈련을 끝낸 신경망을 validation/ test case에 적용할 때는 greedy policy를 따른다)</p>

<p>(Exploration/ exploitation에 대해 제대로 이해하고 싶으면, Sutton의 책 2장의 ‘Multi-armed Bandits’를 공부하기 바란다)</p>

<p><br /></p>

<h2 id="stateaction이-무한할-경우">State/action이 무한할 경우</h2>
<p>지금까지 설명한 방법은, state-action pair의 수가 많지 않을 경우 각 state-action pair별 $\hat{Q}$값들을 담는 table을 만들어 그대로 적용할 수 있다. 이를테면 아래와 같은 공간에서 상하좌우로 한 칸씩 이동 가능한 환경에서 최단거리를 찾는 문제 (Gridworld) 에서는, 격자 수가 한정되어 있으므로 각 격자(state)-이동방향(action) pair 별로 $\hat{Q}$값들을 따로 계산할 수 있다.</p>

<p><img src="/assets/images/reinforcetwo/gridworld.png" alt="gridworld" class="align-center" />
<em>Gridworld 환경. 칸이 38개이고 action은 상하좌우 4개이므로, state-action pair 총 152개 각각에 대해 Q-value를 추정할 수 있다.</em></p>

<p>하지만 많은 경우 state가 continuous이거나, discrete라도 그 수가 매우 많다. 잘 알려진 cartpole 문제의 경우, action은 ‘수레를 정해진 힘으로 왼쪽으로 가속/ 오른쪽으로 가속’ 딱 두 개의 값 중 하나를 가지는 이진수로 볼 수 있으나, state는 ‘수레의 위치와 속도, 막대의 각도와 각속도’로 4차원의 연속된 벡터로 볼 수 있다. State의 수가 무한하므로, 각 state-action pair에 대해 table 방식으로 $\hat{Q}$값들을 따로 계산할 수는 없다.</p>

<p><img src="/assets/images/reinforcetwo/cart_pole.gif" alt="cart_pole" class="align-center" width="70%" />
<em>Cartpole 환경. State 수가 무한하므로, 각 state-action pair에 대해 Q-value를 정의할 수 없다.</em></p>

<p>이 포스팅 시리즈에서 다루는 마이크로그리드 케이스에서도 마찬가지이다. State (직전 $N$시간 동안의 시간별 부하와 태양광 발전량, 그리고 배터리에 저장된 에너지)가 $2N+1$차원의 continuous vector이기 때문이다.</p>

<p>이런 경우 ‘모든 state-action pair 각각에 대해’ $\hat{Q}$를 계산한다는 것은 사실상 불가능하다. 그렇다면 어떻게 해야 하나?</p>

<p><br /></p>

<h2 id="q-value-근사를-위한-딥러닝과-강화학습의-결합">Q-value 근사를 위한 딥러닝과 강화학습의 결합</h2>
<p>만약 state-action pair와 Q값 간의 관계가 어떤 domain knowledge에 의해 명확하게 정의될 수 있다면, 해당 관계를 명확한 수식으로 표현하여 $\hat{Q}$를 쉽게 계산할 수 있을 것이다. 그러나 이 케이스를 포함한 많은 경우, state-action과 Q값 간의 관계식을 명확한 수식으로 나타낼 수 있을 것이라 기대되지 않는다.</p>

<p>그렇다면, state를 입력으로 받고 각 action 별 $\hat{Q}$값을 출력으로 하는 심층신경망 (Deep Neural Network, DNN) 모델을 훈련하는 것이 현실적인 방법이다. 심층신경망은 계산비용은 매우 높지만, node 수가 충분하면 어떤 비선형 함수도 근사할 수 있기 때문에 nonlinear function approximator로 기능한다는 점을 이용하는 것이다.</p>

<p><img src="/assets/images/reinforcetwo/reinforcement_deep.png" alt="reinforcement_deep" class="align-center" width="80%" />
<em>‘심층’강화학습 개요. Action 결정이 심층신경망에 기반해 이루어짐.</em></p>

<p>이 심층신경망 모델은 매 훈련 주기 (꼭 매 시간은 아닐 수 있음) 마다 튜플 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다. 업데이트 시 최소화 대상 목적함수는 $\hat{Q}(s_{t},a_{t})$와 $r_{t+1} + \gamma \text{max}_{a_{t+1}} \hat{Q}(s_{t+1},a_{t+1})$ 간 차이의 제곱이다. 이를 Deep Q-Network (DQN) 이라 한다. 위 cartpole 문제를 푸는 데에도 DQN이 적용된다.</p>

<p>다음 포스팅에서는 마이크로그리드 문제에 Deep Q-Network를 적용하는 과정과 결과에 대해 상세히 설명한다.</p>

<div class="notice--info">

강화학습 기반 마이크로그리드 스케줄링<br /><br />

1) <a href="/reinforceone.html">문제의식 및 케이스 소개</a><br />
2) <b>Q-learning 개념</b><br />
3) <a href="/reinforcethree.html">Deep Q-learning을 통한 discrete control 도출</a><br />
4) <a href="/reinforcefour.html">DDPG를 통한 continuous control 도출</a><br />
5) <a href="/reinforcefive.html">TD3, SAC를 통한 continuous control 도출</a>

</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5" class="page__taxonomy-item p-category" rel="tag">강화학습</a>
    
    </span>
  </p>



<!-- 
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#energymanagement" class="page__taxonomy-item p-category" rel="tag">energymanagement</a>
    
    </span>
  </p>

 -->
        <!-- 

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time class="dt-published" datetime="2023-04-16T00:00:00+09:00">2023-04-16</time></p>
 -->
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">공유하기</h4>
  

  <!-- <a href="https://twitter.com/intent/tweet?text=%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5+%EA%B8%B0%EB%B0%98+%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EA%B7%B8%EB%A6%AC%EB%93%9C+%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81+-+2%29+Q-learning+%EA%B0%9C%EB%85%90%20http%3A%2F%2Flocalhost%3A4000%2Freinforcetwo.html" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a> -->

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Freinforcetwo.html" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Freinforcetwo.html" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="공유하기 LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      <p></p>
        <h4 class="page__meta-title"><span>energymanagement</span> <span>카테고리 내 다른 글 보러가기</span></h4>
        


  

  

  

  
  	
  	
  	
  	
  	

<nav class="pagination_prev_next"> <!-- 식빵맘 코드에서 조금 수정함 -->

  
    
      <a href="/reinforcethree.html" class="pagination_prev_next--pager"><span class="prev_next">다음 글  &nbsp  </span>강화학습 기반 마이크로그리드 스케줄링 - 3) Deep Q-Network를 통한 discrete control 도출</a>
    
    
      <a href="/reinforceone.html" class="pagination_prev_next--pager"><span class="prev_next">이전 글  &nbsp</span>강화학습 기반 마이크로그리드 스케줄링 - 1) 문제의식 및 케이스 소개</a>
        
  

</nav>
      <p></p>
    </div>

    
  </article>

  
  <!-- 
    <div class="page__related">
      <h2 class="page__related-title">참고</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/linprogfive.html" rel="permalink">선형계획법 기반 분산에너지시스템 최적화 - 5) 정수 (integer) 변수 도입으로 현실 설명력 증대
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-24T00:00:00+09:00">2023-04-24</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">지금까지의 선형계획 관련 포스팅들에서는, 모든 변수들을 ‘음이 아닌 실수’ 라고 가정했다. 그러나, 만약 규격 용량이 정해진 발전기를 도입한다면, ‘이 발전기를 3.5대 도입하는 것이 최적이다’ 라고 보고하는 것은 비현실적이다. 발전기 대수는 3대 또는 4대이기 때문이다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/monthlyenergythree.html" rel="permalink">건축물 별 월별 에너지 사용량 데이터셋 - 3) 월별 사용량 크기가 이상한 data point 제거
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-23T00:00:00+09:00">2023-04-23</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">이전 포스팅에서는 건물 월별 에너지 사용량의 ‘추이’가 이상한 data point를 판별하는 방법을 설명했다. 이번 포스팅에서는 월별 에너지 사용량의 ‘크기(magnitude)’가 이상한 data point를 판별하는 방법을 설명한다.
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/monthlyenergytwo.html" rel="permalink">건축물 별 월별 에너지 사용량 데이터셋 - 2) 월별 사용 추이가 이상한 data point 제거
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-22T00:00:00+09:00">2023-04-22</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">이전 포스팅에서 건물 에너지 관련 연구를 위한, 각 건물의 지번별/월별 전기/도시가스 사용량 데이터와 표제부의 결합을 소개했다. 그렇다면 결합된 데이터를 그대로 쓰면 되는가? 그렇지 않다. 분명히 ‘이상한’ data point들이 존재할 것이기 때문이다. 데이터 기반의 연구개발을 ...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/cudadudnn.html" rel="permalink">WSL2 Ubuntu 22.04에 CUDA &amp; cuDNN 설치하기
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2023-04-21T00:00:00+09:00">2023-04-21</time>
      </span>
    

    

    
  </p>


    <p class="archive__item-excerpt" itemprop="description">이 블로그의 글을 무리 없이 읽을 정도의 독자라면, 복잡한 컴퓨터 환경 구축 때문에 많은 시간을 소비해 본 경험이 있을 것이다. 필자도 마찬가지다. 빠른 딥러닝 연산을 위해 NVIDIA CUDA를 설치하려다가, 계속되는 시행착오에 반나절을 넘게 컴퓨터만 붙잡고 있었다.
</p>
  </article>
</div>

        
      </div>
    </div> -->
  
  <!--  -->
</div>

  </div>

  

  <aside class="sidebar__top">
    <a href="#site-nav"> <i class="fas fa-angle-double-up fa-2x"></i></a>
    </aside>

  <div id="footer" class="page__footer">
    <footer>
      <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
      <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
          <li><a href="https://github.com/song4energyndata" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2023 Jeonghun Song. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

    </footer>
  </div>

  
  <script src="/assets/js/main.min.js"></script>










</body>

</html>