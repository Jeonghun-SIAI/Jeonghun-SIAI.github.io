<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://song4energyndata.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://song4energyndata.github.io/" rel="alternate" type="text/html" /><updated>2023-07-02T00:21:27+09:00</updated><id>https://song4energyndata.github.io/feed.xml</id><title type="html">에너지엔데이터연구소</title><subtitle>에너지 전환기를 맞아 에너지 분야의 데이터가 급증하고 있습니다. 이를 계산통계학/ 최적화 역량 기반으로 올바르게 분석/ 활용하여, 에너지 시스템/ 정책/ 시장 등에 관한 유익한 결과물들을 도출할 수 있도록 돕습니다.</subtitle><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><entry><title type="html">강화학습 기반 마이크로그리드 control - 5) TD3/ SAC를 통한 continuous control 도출</title><link href="https://song4energyndata.github.io/reinforcefive.html" rel="alternate" type="text/html" title="강화학습 기반 마이크로그리드 control - 5) TD3/ SAC를 통한 continuous control 도출" /><published>2023-07-01T00:00:00+09:00</published><updated>2023-07-01T00:00:00+09:00</updated><id>https://song4energyndata.github.io/reinforcefive</id><content type="html" xml:base="https://song4energyndata.github.io/reinforcefive.html"><![CDATA[<p>Deep Deterministic Policy Gradient (DDPG) 로 도출한 수전/송전의 continuous control이, 놀랍게도(?) Vincent의 마이크로그리드 사례에서는, DQN으로 도출한 3-actions discrete control 대비 더 좋지 않았다 (3개 action들은 각각 1.1kW 수전/ 1.1kW 송전/ idle).</p>

<p><img src="/assets/images/reinforceone/system.png" alt="system" class="align-center" />
<em>Vincent의 연구에서 가정된 마이크로그리드.</em></p>

<p>그렇다면 continuous control 도출을 위해 DDPG 이후에 개발된 더 진보된 방법을 쓴다면 어떨까?</p>

<p>진보된 방법들의 대표 사례들로, <a href="https://arxiv.org/abs/1802.09477">Twin Delayed Deep Deterministic policy gradient (TD3)</a>와 <a href="https://arxiv.org/abs/1812.05905">Soft Actor-Critic (SAC)</a>이 있다.</p>

<p><br /></p>

<h2 id="twin-delayed-ddpg-td3">Twin Delayed DDPG (TD3)</h2>

<p>TD3가 DDPG와 비교해 갖는 차이점은 대략 아래와 같다 (항상 그렇지만 상세한 내용은 논문 원문을 참고하자).</p>

<p>1) critic 신경망을 한 개가 아닌 두 개 사용한다. 그리고 $Q(s_{t+1},a_{t+1})$을 두 개의 target critic 신경망 각각에 대해 계산하고 그 중 ‘더 작은 값’을 사용한다. 마찬가지로 actor 훈련시의 목적함수 내 $Q(s_{t},a_{t})$ 또한 두 critic 신경망 각각에 대해 계산하고 그 중 ‘더 작은 값’을 사용한다. 이를 통해 Q-learning 특유의 overestimation 문제를 완화할 수 있다.</p>

<p>2) $a_{t+1}$을 결정 시 actor로부터 도출한 결과를 그대로 쓰는 게 아니라, clipped noise를 추가한다. 이를 통해 smoothing regularization 효과를 얻는다.</p>

<p>3) Critic이 여러 번 업데이트될 동안 actor는 한 번 업데이트된다. 이러한 `delayed’ policy update를 통해 value estimation의 variance를 줄인다.</p>

<p><br />
TD3 훈련 코드는 아래와 같다. 코드 내 주석은 지난 포스팅의 DDPG 코드 대비 다른 부분에 대해서만 추가하였다. (<a href="https://github.com/song4energyndata/Codes/tree/main/reinforcementlearning/microgrid_Vincent">GitHub Repo 링크</a>)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="c1">### hyperparameters
</span>
<span class="n">actor_lr</span> <span class="o">=</span> <span class="mf">0.0001</span> 
<span class="n">critic_lr</span> <span class="o">=</span> <span class="mf">0.0002</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">rewardscalefactor</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.98</span>
<span class="n">clippednoise_std</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># clipped noise를 생성하는 평균이 0인 정규분포의 표준편차
</span><span class="n">clippednoise_interval</span> <span class="o">=</span> <span class="mf">0.15</span> <span class="c1"># clipped noise의 구간 설정
</span><span class="n">period_step_fortrain</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### microgrid system data
</span>
<span class="n">PV_prod_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_train.npy'</span><span class="p">)</span>
<span class="n">PV_prod_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_test.npy'</span><span class="p">)</span> 

<span class="n">load_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_train.npy'</span><span class="p">)</span>
<span class="n">load_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_test.npy'</span><span class="p">)</span>

<span class="n">prate_h2</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="n">eff_h2</span> <span class="o">=</span> <span class="mf">0.65</span>

<span class="n">capa_batt</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">eff_batt</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">initialenergy_batt</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="n">price_h2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">cost_loss</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">load_peak</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pv_peak</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">inputlen_load</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">inputlen_pv</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### Neural net configuration
</span>
<span class="k">class</span> <span class="nc">Critic</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Critic</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>          
        <span class="n">self</span><span class="p">.</span><span class="n">input_load</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_pv</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_others</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_action</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_all</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_action</span><span class="p">])</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_all</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_qval</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_action</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">output_qval</span><span class="p">])</span>     
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">input_action</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">input_action</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">Actor</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Actor</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>    
        <span class="n">self</span><span class="p">.</span><span class="n">input_load</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_pv</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_others</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_all</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">])</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_all</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_action</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'tanh'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">output_action</span><span class="p">])</span>     
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">):</span>       
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span>

<span class="n">critic_one_learning</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span>
<span class="n">critic_one_target</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span>
<span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_one_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_one_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span>

<span class="n">critic_two_learning</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span> <span class="c1"># Critic NN을 2개 사용함
</span><span class="n">critic_two_target</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span> <span class="c1"># 두 번째 critic NN의 target net
</span><span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_two_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_two_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span>

<span class="n">actor_learning</span> <span class="o">=</span> <span class="nc">Actor</span><span class="p">()</span>
<span class="n">actor_target</span> <span class="o">=</span> <span class="nc">Actor</span><span class="p">()</span>
<span class="n">actor_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">actor_lr</span><span class="p">))</span>
<span class="n">actor_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">actor_lr</span><span class="p">))</span>
<span class="n">actor_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">actor_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span>



<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="n">replay_buffer</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">experience</span><span class="p">[</span><span class="n">field_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">field_index</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span>



<span class="k">def</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">profile_load</span><span class="p">,</span><span class="n">profile_pv</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]))</span> <span class="p">)</span>
    
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span> <span class="ow">and</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">action</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)).</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
   
    <span class="n">p_h2_send</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="n">prate_h2</span><span class="o">*</span><span class="n">action</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p_h2_send</span> <span class="o">=</span> <span class="o">-</span><span class="n">prate_h2</span><span class="o">*</span><span class="n">action</span>
    <span class="n">p_load</span> <span class="o">=</span> <span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">load_peak</span>
    <span class="n">p_pv</span> <span class="o">=</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">pv_peak</span>
    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">capa_batt</span>   
    
    <span class="c1">#p_curtail = 0
</span>    <span class="n">p_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">p_net_beforebatt</span> <span class="o">=</span> <span class="n">p_pv</span> <span class="o">-</span> <span class="n">p_load</span> <span class="o">+</span> <span class="n">p_h2_receive</span> <span class="o">-</span> <span class="n">p_h2_send</span>
    
    <span class="k">if</span> <span class="n">p_net_beforebatt</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">capa_batt</span> <span class="o">&gt;=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">capa_batt</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">/</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">p_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span> <span class="o">-</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span>           
    
    <span class="n">reward</span> <span class="o">=</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_send</span><span class="o">*</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_receive</span><span class="o">/</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">cost_loss</span><span class="o">*</span><span class="n">p_loss</span>
    <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt_after</span><span class="o">/</span><span class="n">capa_batt</span>
    
    <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_load</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt_after</span><span class="p">]))</span> <span class="p">)</span>         
        <span class="n">replay_buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="o">*</span><span class="n">rewardscalefactor</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">energy_batt_after</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span>



<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">actorupdate</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">input_load</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">input_pv</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">input_load_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_pv_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">clippednoise_std</span><span class="p">,</span><span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="o">-</span><span class="n">clippednoise_interval</span><span class="p">,</span> <span class="n">clippednoise_interval</span><span class="p">)</span>
    <span class="n">actions_by_target</span> <span class="o">=</span> <span class="nf">actor_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">noise</span> <span class="c1"># clipped noise 추가 (smoothing 효과 얻음)
</span>    <span class="n">actions_by_target</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">actions_by_target</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># clipped noise를 추가하더라도 action이 [-1,1] 범위에 들게 제한
</span>    
    <span class="n">Q_values_one_by_target</span> <span class="o">=</span> <span class="nf">critic_one_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">,</span><span class="n">actions_by_target</span><span class="p">)</span>
    <span class="n">Q_values_two_by_target</span> <span class="o">=</span> <span class="nf">critic_two_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">,</span><span class="n">actions_by_target</span><span class="p">)</span> <span class="c1"># 두 번째 critic net을 사용해서 nextstate에 대한 Q-value 계산
</span>    <span class="n">Q_values_min_by_target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">minimum</span><span class="p">(</span><span class="n">Q_values_one_by_target</span><span class="p">,</span> <span class="n">Q_values_two_by_target</span><span class="p">)</span> <span class="c1"># 두 Q-value들 중 작은 값을 사용 (over-estimation 문제 완화)
</span>    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">stop_gradient</span><span class="p">(</span><span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">Q_values_min_by_target</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> 
        <span class="n">Q_values_one</span> <span class="o">=</span> <span class="nf">critic_one_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 
        <span class="n">loss_critic_one</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Q_values_one</span><span class="p">))</span> 
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_critic_one</span><span class="p">,</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span> 
    <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> 
        <span class="n">Q_values_two</span> <span class="o">=</span> <span class="nf">critic_two_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">loss_critic_two</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Q_values_two</span><span class="p">))</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_critic_two</span><span class="p">,</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">actorupdate</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>    
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> 
            <span class="n">actions_by_learner</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">)</span>
            <span class="n">Q_values_one</span> <span class="o">=</span> <span class="nf">critic_one_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions_by_learner</span><span class="p">)</span>
            <span class="n">Q_values_two</span> <span class="o">=</span> <span class="nf">critic_two_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions_by_learner</span><span class="p">)</span>
            <span class="n">Q_values_min</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">minimum</span><span class="p">(</span><span class="n">Q_values_one</span><span class="p">,</span> <span class="n">Q_values_two</span><span class="p">)</span>
            <span class="n">loss_actor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">Q_values_min</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_actor</span><span class="p">,</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">actor_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="n">actor_weights</span> <span class="o">=</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">target_actor_weights</span> <span class="o">=</span> <span class="n">actor_target</span><span class="p">.</span><span class="n">weights</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">actor_weights</span><span class="p">)):</span>
            <span class="n">target_actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">actor_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_actor_weights</span><span class="p">)</span>
        
        <span class="n">critic_one_weights</span> <span class="o">=</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">critic_two_weights</span> <span class="o">=</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">target_critic_one_weights</span> <span class="o">=</span> <span class="n">critic_one_target</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">target_critic_two_weights</span> <span class="o">=</span> <span class="n">critic_two_target</span><span class="p">.</span><span class="n">weights</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">critic_one_weights</span><span class="p">)):</span>
            <span class="n">target_critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">target_critic_two_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">critic_two_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_critic_two_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">critic_one_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_critic_one_weights</span><span class="p">)</span>   
        <span class="n">critic_two_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_critic_two_weights</span><span class="p">)</span>



<span class="n">profits_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">elapsedtime_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">max_return_test</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>
<span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">bool_fortrain</span> <span class="o">=</span> <span class="bp">False</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    
    <span class="c1">### Train for each epoch
</span>    
    <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> <span class="c1"># 시작시점
</span>    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>  
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_train</span><span class="p">)</span><span class="o">-</span><span class="mi">25</span><span class="p">):</span>
        <span class="n">count_step_fortrain</span> <span class="o">+=</span> <span class="mi">1</span>  
        <span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epoch</span> <span class="o">/</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
        <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_train</span><span class="p">,</span><span class="n">PV_prod_train</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span>     

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">count_step_fortrain</span> <span class="o">&gt;</span> <span class="n">period_step_fortrain</span><span class="p">:</span> 
                <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">actorupdate</span><span class="o">=</span><span class="n">bool_fortrain</span><span class="p">)</span>
                <span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">bool_fortrain</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">bool_fortrain</span>
                
                
    <span class="c1">### Validation for each epoch  
</span>    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">testcase_actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">testcase_battenergy</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">epoch_return_test</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> 
        <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_test</span><span class="p">)</span><span class="o">-</span><span class="mi">24</span><span class="p">):</span>
            <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_test</span><span class="p">,</span><span class="n">PV_prod_test</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="n">testcase_actions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">testcase_battenergy</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">energy_batt</span><span class="p">)</span>
            <span class="n">epoch_return_test</span> <span class="o">+=</span> <span class="n">reward</span>
            <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="n">profits_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">)</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_profit_test_td3.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">profits_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">max_return_test</span> <span class="o">&lt;</span> <span class="n">epoch_return_test</span><span class="p">:</span>
            <span class="n">max_return_test</span> <span class="o">=</span> <span class="n">epoch_return_test</span>
            <span class="n">actor_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'actor_trainedmodel_td3.h5'</span><span class="p">)</span>
            <span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'critic_one_trainedmodel_td3.h5'</span><span class="p">)</span>
            <span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'critic_two_trainedmodel_td3.h5'</span><span class="p">)</span>
                    
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_actions_test_td3.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_actions</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_battenergy_test_td3.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_battenergy</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                        
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>   
        <span class="n">elapsedtime_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"Validation: profit of epoch {} is {}, maximum profit is {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="nf">round</span><span class="p">(</span><span class="n">max_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'one epoch 수행에 {}초 걸렸습니다'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_time_test_td3.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">elapsedtime_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="soft-actor-critic-sac">Soft Actor-Critic (SAC)</h2>

<p>SAC에서는 ‘stochastic’ actor를 가정한다. 즉 actor는 특정 확률분포로부터 action을 도출한다. $a_{t} \sim \pi_{\phi}(a|s_{t})$ 인 것이다.</p>

<p>Actor의 직접적인 출력은 정규분포의 평균값 그리고 표준편차의 로그값이고, 이로부터 정의되는 정규분포로부터 샘플을 뽑거나 (training) 평균값을 (validation) 뽑는다. 만약 bounded action인 경우 tanh kernel을 추가해서 action을 결정한다.</p>

<p>Stochastic actor를 쓰기 때문에, DQN/ DDPG/ TD3에서 그랬던 것처럼 hand-crafted noise를 따로 추가하지 않아도 자동으로 훈련 과정에서 exploration이 된다는 장점이 있다.</p>

<p>그리고 SAC에서는 신경망들을 훈련 시 `최대화’ 대상 목적함수에 entropy term $-\alpha \text{log} \pi_{\phi}(a|s_{t}) $ 이 추가된다 (로그확률값은 actor를 call 할 때 받아옴).</p>

<p>정보이론에서 Entropy는 음의 확률에 로그확률을 곱한 값이고 목적함수는 평균을 의미하므로 앞에 확률값이 생략된 것으로 보면 위 term은 entropy를 의미한다. Entropy가 클수록 해당 확률분포가 균등분포에 가까워지므로, 결과적으로 exploration을 장려하게 된다.</p>

<p>$\alpha$는 temperature parameter로, 클수록 entropy의 최대화에 가중치를 많이 줘서 균등분포에 더 가까워진다. SAC에서는 $\alpha$를 사전에 고정된 값으로 결정하지 않고, $\alpha$가 minimum expected entropy 조건 하의 return 최대화 문제의 dual problem의 Lagrangian multiplier임에 착안해 그 값을 변경해 나간다. 그러므로 $\alpha$의 초기값은 사용자가 결정하지만, 그 값은 훈련을 거치면서 지속적으로 수정된다. (역시 상세 내용은 논문 원문을 참고하자.)</p>

<p>SAC 훈련 코드는 아래와 같다 <a href="https://github.com/shakti365/soft-actor-critic">(코드 작성에 참고한 포스팅).</a> 코드 내 주석은 지난 포스팅의 DDPG 코드 대비 다른 부분에 대해서만 추가하였다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">tensorflow_probability</span> <span class="k">as</span> <span class="n">tfp</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="c1">### hyperparameters
</span>
<span class="n">alpha_lr</span> <span class="o">=</span> <span class="mf">0.00005</span> <span class="c1"># temperature parameter에 대한 learning rate
</span><span class="n">actor_lr</span> <span class="o">=</span> <span class="mf">0.0005</span>
<span class="n">critic_lr</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">alpha_initial</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># temperature parameter의 초기값
</span><span class="n">target_entropy</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="p">.</span><span class="nf">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># 1은 DoF of action
</span><span class="n">rewardscalefactor</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># SAC가 reward scale에 민감하므로 잘 선택해야 함: reward가 너무 낮으면 너무 exploration만 해버리고, reward가 너무 높으면 처음엔 학습이 빨리 되는 것 같아 보이지만 poor local minima로 수렴함이 알려짐
</span><span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.98</span>
<span class="n">period_step_fortrain</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### microgrid system data
</span>
<span class="n">PV_prod_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_train.npy'</span><span class="p">)</span>
<span class="n">PV_prod_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_test.npy'</span><span class="p">)</span>  

<span class="n">load_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_train.npy'</span><span class="p">)</span>
<span class="n">load_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_test.npy'</span><span class="p">)</span>

<span class="n">prate_h2</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="n">eff_h2</span> <span class="o">=</span> <span class="mf">0.65</span>

<span class="n">capa_batt</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">eff_batt</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">initialenergy_batt</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="n">price_h2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">cost_loss</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">load_peak</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pv_peak</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">inputlen_load</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">inputlen_pv</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### Neural net configuration
</span>
<span class="k">class</span> <span class="nc">Critic</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Critic</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>         
        <span class="n">self</span><span class="p">.</span><span class="n">input_load</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_pv</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_others</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_action</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_all</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_action</span><span class="p">])</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_all</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_qval</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_action</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">output_qval</span><span class="p">])</span>     
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">input_action</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">input_action</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">Actor</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Actor</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>       
        <span class="n">self</span><span class="p">.</span><span class="n">input_load</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_pv</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span><span class="p">)</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">input_others</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_all</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">])</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_all</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_action_mean</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span> <span class="c1"># 정규분포의 평균
</span>        <span class="n">self</span><span class="p">.</span><span class="n">output_action_stddev</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span> <span class="c1"># 정규분포의 표준편차
</span>        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">output_action_mean</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">output_action_stddev</span><span class="p">])</span>     
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>        
        <span class="n">mu</span><span class="p">,</span> <span class="n">logsigma</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span> <span class="c1"># 정규분포의 평균, 로그표준편차
</span>        <span class="n">sigma</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">logsigma</span><span class="p">)</span> <span class="c1"># 로그표준편차를 표준편차로 변환
</span>        <span class="n">dist</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="nc">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span> <span class="c1"># 정규분포 정의
</span>        <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> <span class="c1"># Training 시
</span>            <span class="n">action_temp</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">sample</span><span class="p">()</span> <span class="c1"># 정규분포로부터 임의로 샘플 뽑아서 action 결정 
</span>        <span class="k">else</span><span class="p">:</span> <span class="c1"># Validation 시
</span>            <span class="n">action_temp</span> <span class="o">=</span> <span class="n">mu</span> <span class="c1"># Validation 시에는 mean action으로 (deterministic action)
</span>        <span class="n">action</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">action_temp</span><span class="p">)</span> <span class="c1"># tanh activation function을 이용한 bounded action 구현
</span>        <span class="n">logprob_temp</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">log_prob</span><span class="p">(</span><span class="n">action_temp</span><span class="p">)</span>
        <span class="n">logprob</span> <span class="o">=</span> <span class="n">logprob_temp</span> <span class="o">-</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">action</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1e-16</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># log-probability 반환
</span>        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">logprob</span>
        

<span class="n">critic_one_learning</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span>
<span class="n">critic_one_target</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span>
<span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_one_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_one_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span>

<span class="n">critic_two_learning</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span>
<span class="n">critic_two_target</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span>
<span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_two_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_two_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span> 

<span class="n">actor_learning</span> <span class="o">=</span> <span class="nc">Actor</span><span class="p">()</span>
<span class="n">actor_target</span> <span class="o">=</span> <span class="nc">Actor</span><span class="p">()</span>
<span class="n">actor_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">actor_lr</span><span class="p">))</span>
<span class="n">actor_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">actor_lr</span><span class="p">))</span>
<span class="n">actor_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">actor_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">alpha_initial</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># temperature parameter 정의
</span><span class="n">alpha_optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">alpha_lr</span><span class="p">)</span>

<span class="n">actor_weight_temp</span> <span class="o">=</span> <span class="n">actor_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span>
<span class="n">critic_one_weight_temp</span> <span class="o">=</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span>
<span class="n">critic_two_weight_temp</span> <span class="o">=</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span>


<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="n">replay_buffer</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">experience</span><span class="p">[</span><span class="n">field_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">field_index</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span>



<span class="k">def</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">profile_load</span><span class="p">,</span><span class="n">profile_pv</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]))</span> <span class="p">)</span>
    
    <span class="n">action</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>
    <span class="n">action</span> <span class="o">=</span> <span class="n">action</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> 
        
    <span class="n">p_h2_send</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="n">prate_h2</span><span class="o">*</span><span class="n">action</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">p_h2_send</span> <span class="o">=</span> <span class="o">-</span><span class="n">prate_h2</span><span class="o">*</span><span class="n">action</span>
    <span class="n">p_load</span> <span class="o">=</span> <span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">load_peak</span>
    <span class="n">p_pv</span> <span class="o">=</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">pv_peak</span>
    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">capa_batt</span>
        
    <span class="c1"># p_curtail = 0
</span>    <span class="n">p_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">p_net_beforebatt</span> <span class="o">=</span> <span class="n">p_pv</span> <span class="o">-</span> <span class="n">p_load</span> <span class="o">+</span> <span class="n">p_h2_receive</span> <span class="o">-</span> <span class="n">p_h2_send</span>
    
    <span class="k">if</span> <span class="n">p_net_beforebatt</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">capa_batt</span> <span class="o">&gt;=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">capa_batt</span>
            <span class="c1"># p_curtail = (energy_batt + p_net_beforebatt*eff_batt - capa_batt)/eff_batt 
</span>    <span class="k">else</span><span class="p">:</span> 
        <span class="k">if</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">/</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">p_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span> <span class="o">-</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span>           
    
    <span class="n">reward</span> <span class="o">=</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_send</span><span class="o">*</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_receive</span><span class="o">/</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">cost_loss</span><span class="o">*</span><span class="n">p_loss</span>
    <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt_after</span><span class="o">/</span><span class="n">capa_batt</span>
    
    <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_load</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt_after</span><span class="p">]))</span> <span class="p">)</span>         
        <span class="n">replay_buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="o">*</span><span class="n">rewardscalefactor</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">energy_batt_after</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span>



<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">actorupdate</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">input_load</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">input_pv</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">input_load_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_pv_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="n">actions_by_target</span><span class="p">,</span> <span class="n">logprobs_actions_target</span> <span class="o">=</span> <span class="nf">actor_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">)</span><span class="c1"># action 뿐 아니라 로그확률도 불러옴, 로그확률은 entropy term에 사용됨
</span>    
    <span class="n">Q_values_one_by_target</span> <span class="o">=</span> <span class="nf">critic_one_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">,</span><span class="n">actions_by_target</span><span class="p">)</span>
    <span class="n">Q_values_two_by_target</span> <span class="o">=</span> <span class="nf">critic_two_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">,</span><span class="n">actions_by_target</span><span class="p">)</span>
    <span class="n">Q_values_min_by_target</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">minimum</span><span class="p">(</span><span class="n">Q_values_one_by_target</span><span class="p">,</span> <span class="n">Q_values_two_by_target</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">stop_gradient</span><span class="p">(</span><span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="p">(</span><span class="n">Q_values_min_by_target</span> <span class="o">-</span> <span class="n">alpha</span><span class="o">*</span><span class="n">logprobs_actions_target</span><span class="p">))</span> <span class="c1"># entropy term이 추가됨됨
</span>    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">Q_values_one</span> <span class="o">=</span> <span class="nf">critic_one_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1">#
</span>        <span class="n">loss_critic_one</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">Q_values_one</span><span class="p">))</span> 
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_critic_one</span><span class="p">,</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">Q_values_two</span> <span class="o">=</span> <span class="nf">critic_two_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">loss_critic_two</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">Q_values_two</span><span class="p">))</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_critic_two</span><span class="p">,</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">actorupdate</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>    
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
            <span class="n">actions_by_learner</span><span class="p">,</span> <span class="n">logprobs_actions</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">)</span>
            <span class="n">Q_values_one</span> <span class="o">=</span> <span class="nf">critic_one_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions_by_learner</span><span class="p">)</span>
            <span class="n">Q_values_two</span> <span class="o">=</span> <span class="nf">critic_two_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions_by_learner</span><span class="p">)</span>
            <span class="n">Q_values_min</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">math</span><span class="p">.</span><span class="nf">minimum</span><span class="p">(</span><span class="n">Q_values_one</span><span class="p">,</span> <span class="n">Q_values_two</span><span class="p">)</span>
            <span class="n">loss_actor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">alpha</span><span class="o">*</span><span class="n">logprobs_actions</span> <span class="o">-</span> <span class="n">Q_values_min</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_actor</span><span class="p">,</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">actor_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> <span class="c1"># temperature parameter의 업데이트
</span>            <span class="n">actions_by_learner</span><span class="p">,</span> <span class="n">logprobs_actions</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">)</span>
            <span class="n">loss_alpha</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">alpha</span><span class="o">*</span><span class="p">(</span><span class="n">logprobs_actions</span><span class="o">+</span><span class="n">target_entropy</span><span class="p">))</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_alpha</span><span class="p">,</span> <span class="p">[</span><span class="n">alpha</span><span class="p">])</span>
        <span class="n">alpha_optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="p">[</span><span class="n">alpha</span><span class="p">]))</span>
        
        <span class="n">actor_weights</span> <span class="o">=</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">target_actor_weights</span> <span class="o">=</span> <span class="n">actor_target</span><span class="p">.</span><span class="n">weights</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">actor_weights</span><span class="p">)):</span>
            <span class="n">target_actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">actor_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_actor_weights</span><span class="p">)</span>
        
        <span class="n">critic_one_weights</span> <span class="o">=</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">critic_two_weights</span> <span class="o">=</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">target_critic_one_weights</span> <span class="o">=</span> <span class="n">critic_one_target</span><span class="p">.</span><span class="n">weights</span>
        <span class="n">target_critic_two_weights</span> <span class="o">=</span> <span class="n">critic_two_target</span><span class="p">.</span><span class="n">weights</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">critic_one_weights</span><span class="p">)):</span>
            <span class="n">target_critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">target_critic_two_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">critic_two_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_critic_two_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">critic_one_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_critic_one_weights</span><span class="p">)</span>    
        <span class="n">critic_two_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_critic_two_weights</span><span class="p">)</span>    



<span class="n">profits_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">elapsedtime_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">max_return_test</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>
<span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">bool_fortrain</span> <span class="o">=</span> <span class="bp">False</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    
    <span class="c1">### Train for each epoch
</span>    
    <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span>
    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>  
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_train</span><span class="p">)</span><span class="o">-</span><span class="mi">25</span><span class="p">):</span>
        <span class="n">count_step_fortrain</span> <span class="o">+=</span> <span class="mi">1</span>      
        <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_train</span><span class="p">,</span><span class="n">PV_prod_train</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span>     

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">count_step_fortrain</span> <span class="o">&gt;</span> <span class="n">period_step_fortrain</span><span class="p">:</span> 
                <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">actorupdate</span><span class="o">=</span><span class="n">bool_fortrain</span><span class="p">)</span>
                <span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">bool_fortrain</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">bool_fortrain</span>                                   
                <span class="n">actor_weight_temp</span> <span class="o">=</span> <span class="n">actor_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span>
                <span class="n">critic_one_weight_temp</span> <span class="o">=</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span>
                <span class="n">critic_two_temp</span> <span class="o">=</span> <span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">()</span>
                    
    <span class="c1">### Validation for each epoch  
</span>    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">testcase_actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">testcase_battenergy</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">epoch_return_test</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span>
        <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_test</span><span class="p">)</span><span class="o">-</span><span class="mi">24</span><span class="p">):</span>
            <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_test</span><span class="p">,</span><span class="n">PV_prod_test</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
            <span class="n">testcase_actions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">testcase_battenergy</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">energy_batt</span><span class="p">)</span>
            <span class="n">epoch_return_test</span> <span class="o">+=</span> <span class="n">reward</span>
            <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="n">profits_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">)</span>   
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_profit_test_sac.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">profits_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">max_return_test</span> <span class="o">&lt;</span> <span class="n">epoch_return_test</span><span class="p">:</span>
            <span class="n">max_return_test</span> <span class="o">=</span> <span class="n">epoch_return_test</span>
            <span class="n">actor_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'actor_trainedmodel_sac.h5'</span><span class="p">)</span>
            <span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'critic_one_trainedmodel_sac.h5'</span><span class="p">)</span>
            <span class="n">critic_two_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'critic_two_trainedmodel_sac.h5'</span><span class="p">)</span>
                    
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_actions_test_sac.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_actions</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_battenergy_test_sac.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_battenergy</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                        
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>   
        <span class="n">elapsedtime_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"Validation: profit of epoch {} is {}, maximum profit is {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="nf">round</span><span class="p">(</span><span class="n">max_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'one epoch 수행에 {}초 걸렸습니다'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'Temperature parameter 값은 {}입니다.'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">alpha</span><span class="p">.</span><span class="nf">numpy</span><span class="p">()))</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_time_test_sac.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">elapsedtime_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>SAC 훈련에서 주의할 점은, 가끔 $\alpha$가 NaN이 되기도 한다는 것이다. (솔직히 아직은 이유를 모르겠다… 사실 이 부분은 100% 이해를 한 게 아니라서, 위 reference page에서 한 방식을 그대로 쓴 것이다.) $\alpha$가 NaN이 되면 더 이상 훈련이 되지 않으니, learning rate를 더 줄이거나 한 후 처음부터 다시 훈련을 시켜야 한다.</p>

<p><br /></p>

<h2 id="td3-sac를-통한-continuous-control-결과">TD3/ SAC를 통한 continuous control 결과</h2>

<p>결과를 보면, TD3 control에서는 낮 송전 기간에 쭉 최대송전에 가깝게 하지 않고 송전량을 줄였다가 다시 늘리는 패턴이 보인다. 한편 SAC control에서는 최대송전과 최대수전을 하는 경우가 거의 없다.</p>

<p><img src="/assets/images/reinforcefive/result_td3sac.png" alt="result_td3sac" class="align-center" />
<em>TD3/ SAC로 도출한 수전/송전 control. LP control과는 차이가 있음.</em></p>

<p>TD3와 SAC으로 도출한 control 적용 시 validation case에 대한 누적 비용은 각각 85유로, 118유로이다. 이는 DDPG control (125유로) 보다는 조금 나은 결과지만, 여전히 DQN control (50유로) 에 뒤진다.</p>

<p>Vincent의 마이크로그리드 사례에서는, 미래를 안다는 가정 하에 도출한 LP solution에서의 action이 (엄밀히는 continuous지만) 거의 discrete에 가까운 모습이다. 그러므로, action을 state의 continuous function으로 근사하는 DDPG/ TD3/ SAC보다는, discrete function으로 근사하는 DQN이 더 나은 것으로 추정된다.</p>

<p>심지어 이는 시뮬레이션으로 계산되는 마이크로그리드의 누적비용 측면에서만 생각한 것이며, 계산 시간까지 고려하면 DQN의 computational efficiency가 DDPG/ TD3/ SAC 대비 훨씬 높다.</p>

<p><br />
실제로 에너지기술연구원에서 히트펌프 제어기를 심층강화학습으로 훈련시킨 연구에서도 (아래 Youtube 영상), SAC 기반 continuous control을 연구과정에서 시도하기는 했으나 최종적으로는 DQN으로 도출한 discrete control을 사용 및 논문화하였다 (히트펌프의 경우 여러 대를 설치 후 매 시간별로 몇 대나 가동할 것이냐를 결정하는 discrete control이 가능하기도 하다).</p>

<!-- Courtesy of embedresponsively.com -->

<div class="responsive-video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/L9Ye1gALFAk" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </div>

<p><br /></p>

<h2 id="나가며">나가며</h2>

<p>데이터 사이언스에서 ‘Data Generating Process (DGP)에 맞는 방법을 써라’ 라는 격언이 있는데, 이번 사례도 이와 유사한 교훈을 주는 사례인 것 같다.</p>

<p>미래를 모두 안다는 가정 하에 선형계획법으로 얻은 optimal solution에서의 action이 discrete action과 상당히 유사함을, 강화학습 계산 전에 미리 알 수 있었다. 그렇다면 이 문제에 있어 더 맞는 강화학습 방법은 discrete control 방법이며, 굳이 continuous control 방법을 시도해도 discrete 대비 더 나은 결과를 얻지 못하는 것이 놀랍지 않은 것이다.</p>

<p><br />
(사족: 그런데, 사실 Vincent의 마이크로그리드 사례처럼 계통으로부터의 수전/송전 한도가 ‘peak 부하 밑으로’ 제한되어 있는 경우가 결코 흔치는 않을 것이다. 솔직히 말하면, 실제 현실에서 일반적인 case라기보다는, DQN 적용이 용이하도록 어느 정도 꾸며낸 case라는 느낌을 받는다. <br />
실제로는 열병합발전기/ 냉난방설비 등 제어 가능한 설비의 출력을 action으로 두고, 계통으로부터의 수전/송전은 action에 따라 자동으로 결정되는 환경변수들로 두는 것이 더 합리적으로 보인다. 다만 이는 강화학습으로 안정적인 economic control을 도출하기가 쉽지 않아 보이는데, 이에 관련된 논문을 향후 찾아볼 생각이다.)</p>

<div class="notice--info">

강화학습 기반 마이크로그리드 control<br /><br />

1) <a href="/reinforceone.html">문제의식 및 케이스 소개</a><br />
2) <a href="/reinforcetwo.html">Q-learning 개념</a><br />
3) <a href="/reinforcethree.html">Deep Q-Network를 통한 discrete control 도출</a><br />
4) <a href="/reinforcefour.html">DDPG를 통한 continuous control 도출</a><br />
5) <b>TD3, SAC를 통한 continuous control 도출</b>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="energymanagement" /><category term="강화학습" /><category term="녹색섬" /><category term="Python" /><summary type="html"><![CDATA[Deep Deterministic Policy Gradient (DDPG) 로 도출한 수전/송전의 continuous control이, 놀랍게도(?) Vincent의 마이크로그리드 사례에서는, DQN으로 도출한 3-actions discrete control 대비 더 좋지 않았다 (3개 action들은 각각 1.1kW 수전/ 1.1kW 송전/ idle).]]></summary></entry><entry><title type="html">강화학습 기반 마이크로그리드 control - 4) DDPG를 통한 continuous control 도출</title><link href="https://song4energyndata.github.io/reinforcefour.html" rel="alternate" type="text/html" title="강화학습 기반 마이크로그리드 control - 4) DDPG를 통한 continuous control 도출" /><published>2023-06-25T00:00:00+09:00</published><updated>2023-06-25T00:00:00+09:00</updated><id>https://song4energyndata.github.io/reinforcefour</id><content type="html" xml:base="https://song4energyndata.github.io/reinforcefour.html"><![CDATA[<p>Vincent의 마이크로그리드 사례에 ‘discrete’ action (1.1kW 수전/ 1.1kW 송전/ idle) 기반의 Deep Q-Network (DQN) 을 적용한 결과, 미래를 모른 채 과거 24시간 동안의 태양광 발전량과 부하 정보를 활용하더라도 충분히 economic control이 가능했다.</p>

<p><img src="/assets/images/reinforceone/system.png" alt="system" class="align-center" />
<em>Vincent의 연구에서 가정된 마이크로그리드.</em></p>

<p>그러나 실제로는 수전/송전이 continuous action이다. 그러므로, continuous action을 다루는 심층강화학습 기법을 적용하면 더 우수한 economic control이 가능할 지 궁금해진다.</p>

<p>이번에는 continuous control의 기본적인 방법인 <a href="https://arxiv.org/abs/1509.02971">Deep Deterministic Policy Gradient (DDPG)</a>를 적용해서, 수전/송전에 대한 continuous control을 도출해본다.</p>

<p><br /></p>

<h2 id="actor와-critic-신경망">Actor와 critic 신경망</h2>
<p>Continuous action인 경우 가능한 action의 수가 사실상 무한대이므로, DQN에서처럼 state를 입력받아 각 action 별 Q-value를 모두 계산하는 신경망을 구성할 수는 없다.</p>

<p>대신에, 두 개의 신경망을 구성하되 하나는 state를 입력받고 continuous action의 값을 출력하고, 다른 하나는 state와 action을 입력받아 그 state-action pair의 Q-value를 출력하도록 한다. 두 신경망 중 전자를 actor (action을 결정함), 후자를 critic (value를 평가함) 이라 부른다.</p>

<p>이 때 actor는 state를 받고 deterministic한 action을 출력하는 policy로 볼 수 있다. 그래서 이 방법에는 Deep Deterministic Policy Gradient (DDPG) 라는 이름이 붙었다.</p>

<p>특히 이 마이크로그리드 사례에서 action은 하한이 -1.1, 상한이 1.1로 정해져 있다. 이러한 ‘bounded’ action을 구현하기 위해, actor의 output layer에 tanh (하이퍼볼릭 탄젠트) activation function을 걸어준다.</p>

<p><br /></p>

<h2 id="target-신경망">Target 신경망</h2>
<p>한편, DDPG에서는 ‘target’ 신경망을 구성해서 학습의 안정성을 향상시킨다. Actor와 critic 각각의 target 신경망들은 원래 actor와 critic의 복사본으로 시작해서, Q-learning에서 next state에 대한 값을 도출하는 데 이용된 후 천천히 업데이트된다.</p>

<p>구체적으로, 원래 신경망들의 parameter를 $\theta$, target 신경망들의 parameter를 $\theta’$라 하고, 원래 actor와 target actor를 각각 $\mu(s)$와 $\mu’(s)$, 원래 critic과 target critic을 각각 $Q(s,a)$와 $Q’(s,a)$라 하자.</p>

<p>그러면, critic 신경망 훈련 시의 목적함수는 $\hat{Q}(s_{t},a_{t})$와 $r_{t+1} + \gamma \text{max}_{\mu’} Q’(s_{t+1},\mu’(s_{t+1}))$ 간 차이의 평균제곱합이다. 두 번째 항이 target 신경망에 의해 계산되었음에 주목한다.</p>

<p>한편 actor 신경망 훈련 시의 목적함수는 $-Q(s_{t},\mu(s_{t}))$, 즉 음의 Q-value이다. Actor는 Q-value를 최대화하는 action을 도출해야 하기 때문이다. Actor 훈련 시의 목적함수는 target 신경망에 의해 계산되지 않았다.</p>

<p>원래 critic과 actor에 대해 가중치 업데이트를 수행한 후, target critic과 actor에 대한 가중치 업데이트는 작은 양수 $\tau$에 대해 아래와 같이 수행한다. $\tau$가 작으므로 (대략 0.05 전후), $\theta’$는 ‘느리게’ 업데이트된다.</p>

<p>$\theta’ \leftarrow \tau \theta + (1-\tau) \theta’$</p>

<p>Q-learning에서 Q-value에 대한 두 추정치 $Q(s_{t},a_{t})$와 $r_{t+1} + \gamma \text{max}_{a_{t+1}} Q(s_{t+1},a_{t+1})$가 말 그대로 ‘둘 다 추정치’이다. 즉 추정치를 추정치 기반으로 추정한다 (이를 bootstrap이라고도 한다).</p>

<p>이 때문에 운 나쁘게 추정이 잘못된 방향으로 진행되기 시작하면, 훈련이 발산해버리기 쉽다. Target 신경망 구성을 통해, Q-value 추정의 변화를 완화하여 훈련이 발산할 가능성을 크게 줄일 수 있다.</p>

<p>(보다 더 상세한 내용은 <a href="https://arxiv.org/abs/1509.02971">논문 원문</a>을 참고하길 바란다)</p>

<p><br /></p>

<h2 id="ddpg-코드">DDPG 코드</h2>
<p>이제 DDPG를 적용하여 continuous controller를 훈련하는 코드를 보자 <a href="https://antonai.blog/reinforcement-learning-in-continuous-action-spaces-part-1-ddpg/">(해당 코드 작성에 참고한 DDPG 코딩 설명 포스트).</a> 코드 내 주석은 지난 포스팅의 DQN 코드 대비 다른 부분에 대해서만 추가하였다. (<a href="https://github.com/song4energyndata/Codes/tree/main/reinforcementlearning/microgrid_Vincent">GitHub Repo 링크</a>)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">concatenate</span><span class="p">,</span> <span class="n">Flatten</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="c1">### hyperparameters
</span>
<span class="n">actor_lr</span> <span class="o">=</span> <span class="mf">0.0005</span> <span class="c1"># actor NN의 learning rate
</span><span class="n">critic_lr</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># critic NN의 learning rate
</span><span class="n">tau</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="c1"># target NN 업데이트 속도 조절 계수
</span><span class="n">rewardscalefactor</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.98</span>
<span class="n">period_step_fortrain</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### microgrid system data
</span>
<span class="n">PV_prod_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_train.npy'</span><span class="p">)</span> 
<span class="n">PV_prod_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_test.npy'</span><span class="p">)</span> 

<span class="n">load_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_train.npy'</span><span class="p">)</span>
<span class="n">load_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_test.npy'</span><span class="p">)</span>

<span class="n">prate_h2</span> <span class="o">=</span> <span class="mf">1.1</span>
<span class="n">eff_h2</span> <span class="o">=</span> <span class="mf">0.65</span>

<span class="n">capa_batt</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">eff_batt</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">initialenergy_batt</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="n">price_h2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">cost_loss</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">load_peak</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pv_peak</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">inputlen_load</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">inputlen_pv</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### Neural net configuration
</span>
<span class="k">class</span> <span class="nc">Critic</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span> <span class="c1"># Q-value를 추정하는 NN (action이 continuous)
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Critic</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span> <span class="c1"># tf.Keras.Model 상속받는 이유는 main코드에서 get_weights, set_weights 등을 매번 model 메서드를 불러오지 않고도 편하게 쓰기 위함          
</span>        <span class="n">self</span><span class="p">.</span><span class="n">input_load</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">input_pv</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_others</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">input_action</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># action 값 (state 뿐 아니라 action도 input임)
</span>        <span class="n">self</span><span class="p">.</span><span class="n">concat_all</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_action</span><span class="p">])</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_all</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_qval</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_action</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">output_qval</span><span class="p">])</span>     
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">input_action</span><span class="p">):</span> <span class="c1"># state 뿐 아니라 action도 input임        
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">input_action</span><span class="p">))</span> <span class="c1"># output은 입력된 state-action pair에 대한 Q-value '단일값'
</span>
<span class="k">class</span> <span class="nc">Actor</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span> <span class="c1"># (Continuous) Action을 결정하는 policy NN
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">Actor</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>        
        <span class="n">self</span><span class="p">.</span><span class="n">input_load</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">input_pv</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_conv</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span> <span class="o">=</span> <span class="nc">Flatten</span><span class="p">()(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_conv_concat</span><span class="p">)</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">input_others</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">self</span><span class="p">.</span><span class="n">concat_all</span> <span class="o">=</span> <span class="nf">concatenate</span><span class="p">([</span><span class="n">self</span><span class="p">.</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">])</span> 
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">concat_all</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_1</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">output_action</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'tanh'</span><span class="p">)(</span><span class="n">self</span><span class="p">.</span><span class="n">hidden_dense_2</span><span class="p">)</span> <span class="c1"># Node 갯수는 action의 자유도이며, tanh activation은 action(충/방전) 이 [-1,1] 범위의 bounded action임을 반영함
</span>        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">input_load</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_pv</span><span class="p">,</span><span class="n">self</span><span class="p">.</span><span class="n">input_others</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">self</span><span class="p">.</span><span class="n">output_action</span><span class="p">])</span>     
    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">):</span> <span class="c1"># state가 input임        
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span>

<span class="n">critic_one_learning</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span> 
<span class="n">critic_one_target</span> <span class="o">=</span> <span class="nc">Critic</span><span class="p">()</span> <span class="c1"># target 신경망 정의
</span><span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_one_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">critic_lr</span><span class="p">))</span>
<span class="n">critic_one_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span> <span class="c1"># target 신경망의 가중치의 초기값은 원래 신경망의 가중치와 같게 둠.
</span>
<span class="n">actor_learning</span> <span class="o">=</span> <span class="nc">Actor</span><span class="p">()</span>
<span class="n">actor_target</span> <span class="o">=</span> <span class="nc">Actor</span><span class="p">()</span> <span class="c1"># target 신경망 정의
</span><span class="n">actor_learning</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">actor_lr</span><span class="p">))</span>
<span class="n">actor_target</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">actor_lr</span><span class="p">))</span>
<span class="n">actor_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">actor_learning</span><span class="p">.</span><span class="nf">get_weights</span><span class="p">())</span> <span class="c1"># target 신경망의 가중치의 초기값은 원래 신경망의 가중치와 같게 둠.
</span>


<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="n">replay_buffer</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> 
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span> 
    <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span> 
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">experience</span><span class="p">[</span><span class="n">field_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span> 
        <span class="k">for</span> <span class="n">field_index</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span>



<span class="k">def</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">profile_load</span><span class="p">,</span><span class="n">profile_pv</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]))</span> <span class="p">)</span>
    
    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span> <span class="ow">and</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> <span class="c1"># exploration during training
</span>        <span class="n">action</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># exploration 시 -1~+1 사이의 실수를 균등분포에서 추출
</span>    <span class="k">else</span><span class="p">:</span> <span class="c1"># exploitation
</span>        <span class="n">action</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)).</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># action net의 output은 tensor이므로, 이를 numpy 변환 후 [0][0]으로 불러와야 int 변수가 됨
</span>    
    <span class="c1"># Unscaling
</span>    <span class="n">p_h2_send</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="n">prate_h2</span><span class="o">*</span><span class="n">action</span> <span class="c1"># 여기서 action은 전기 '수전'에 대해 양수라고 가정, action은 [-1,1] 구간의 실수이므로 prate_h2를 곱해 [-1.1,1.1] 구간의 실수가 되도록 함
</span>    <span class="k">else</span><span class="p">:</span>
        <span class="n">p_h2_send</span> <span class="o">=</span> <span class="o">-</span><span class="n">prate_h2</span><span class="o">*</span><span class="n">action</span> <span class="c1"># action은 전기 '송전'에 대해 음수
</span>    <span class="n">p_load</span> <span class="o">=</span> <span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">load_peak</span> 
    <span class="n">p_pv</span> <span class="o">=</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">pv_peak</span> 
    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">capa_batt</span> 
        
    <span class="c1">#p_curtail = 0
</span>    <span class="n">p_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">p_net_beforebatt</span> <span class="o">=</span> <span class="n">p_pv</span> <span class="o">-</span> <span class="n">p_load</span> <span class="o">+</span> <span class="n">p_h2_receive</span> <span class="o">-</span> <span class="n">p_h2_send</span> 
    
    <span class="k">if</span> <span class="n">p_net_beforebatt</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">capa_batt</span> <span class="o">&gt;=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span><span class="p">:</span> 
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">capa_batt</span>
            <span class="c1"># p_curtail = (energy_batt + p_net_beforebatt*eff_batt - capa_batt)/eff_batt 
</span>    <span class="k">else</span><span class="p">:</span> 
        <span class="k">if</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span><span class="p">:</span> 
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">/</span><span class="n">eff_batt</span> 
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">p_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span> <span class="o">-</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span>           
    
    <span class="n">reward</span> <span class="o">=</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_send</span><span class="o">*</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_receive</span><span class="o">/</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">cost_loss</span><span class="o">*</span><span class="n">p_loss</span> 
    <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt_after</span><span class="o">/</span><span class="n">capa_batt</span> 
    
    <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_load</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt_after</span><span class="p">]))</span> <span class="p">)</span>         
        <span class="n">replay_buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="o">*</span><span class="n">rewardscalefactor</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span> 
    <span class="k">return</span> <span class="n">energy_batt_after</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span>



<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">actorupdate</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">input_load</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">input_pv</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">input_load_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_pv_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        
    <span class="n">actions_by_target</span> <span class="o">=</span> <span class="nf">actor_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># nextstate에 대한 action은 target net으로 도출
</span>    <span class="n">actions_by_target</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">clip</span><span class="p">(</span><span class="n">actions_by_target</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [-1,1] 범위로 제한
</span>    
    <span class="n">Q_values_one_by_target</span> <span class="o">=</span> <span class="nf">critic_one_target</span><span class="p">(</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">,</span><span class="n">actions_by_target</span><span class="p">)</span> <span class="c1"># nextstate에 대한 Q-value는 target net으로 도출
</span>    <span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">stop_gradient</span><span class="p">(</span><span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">Q_values_one_by_target</span><span class="p">)</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> <span class="c1"># critic net 업데이트를 위한 자동미분 (actor net 업데이트와 별개로 둠)        
</span>        <span class="n">Q_values_one</span> <span class="o">=</span> <span class="nf">critic_one_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># critic_one_learning을 gradient descent로 훈련시키려면, GradientTape 구문 내에서 현재 state-action에 대한 Q_value Tensor를 critic_one_learning으로 다시 불러와야 함
</span>        <span class="n">loss_critic_one</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">Q_values_one</span><span class="p">))</span> <span class="c1"># 평균제곱오차 계산
</span>    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_critic_one</span><span class="p">,</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span> 
    <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
     
    <span class="k">if</span> <span class="n">actorupdate</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>    
        <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> <span class="c1"># actor net 업데이트를 위한 자동미분 (critic net 업데이트와 별개로 둠)  
</span>            <span class="n">actions_by_learner</span> <span class="o">=</span> <span class="nf">actor_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">)</span> <span class="c1"># actor_learning을 gradient descent로 훈련시키려면, GradientTape 구문 내에서 현재 state에 대한 action Tensor를 actor_learning으로 다시 불러와야 함
</span>            <span class="n">Q_values_one</span> <span class="o">=</span> <span class="nf">critic_one_learning</span><span class="p">(</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">,</span><span class="n">actions_by_learner</span><span class="p">)</span> <span class="c1"># actor_learning으로 다시 불러온 action 기반으로 Q-value 계산
</span>            <span class="n">loss_actor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">Q_values_one</span><span class="p">)</span> <span class="c1"># 음의 Q-value 최소화, 즉 Q-value를 최대화하도록 actor를 업데이트함
</span>        <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss_actor</span><span class="p">,</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">actor_learning</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span>
        
        <span class="n">actor_weights</span> <span class="o">=</span> <span class="n">actor_learning</span><span class="p">.</span><span class="n">weights</span> <span class="c1"># 원래 net의 weight 불러옴 (연산을 위해)
</span>        <span class="n">target_actor_weights</span> <span class="o">=</span> <span class="n">actor_target</span><span class="p">.</span><span class="n">weights</span> <span class="c1"># target net의 weight 불러옴
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">actor_weights</span><span class="p">)):</span> <span class="c1"># Target net 가중치 업데이트
</span>            <span class="n">target_actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_actor_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1"># tau가 작으므로 target net이 '천천히' 업데이트됨
</span>        <span class="n">actor_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_actor_weights</span><span class="p">)</span> <span class="c1"># 업데이트된 가중치로 설정
</span>        
        <span class="n">critic_one_weights</span> <span class="o">=</span> <span class="n">critic_one_learning</span><span class="p">.</span><span class="n">weights</span> <span class="c1"># 원래 net의 weight 불러옴 (연산을 위해)        
</span>        <span class="n">target_critic_one_weights</span> <span class="o">=</span> <span class="n">critic_one_target</span><span class="p">.</span><span class="n">weights</span> <span class="c1"># target net의 weight 불러옴
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">critic_one_weights</span><span class="p">)):</span>  <span class="c1"># Target net 가중치 업데이트
</span>            <span class="n">target_critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="n">critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">tau</span><span class="p">)</span> <span class="o">*</span> <span class="n">target_critic_one_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1"># tau가 작으므로 target net이 '천천히' 업데이트됨          
</span>        <span class="n">critic_one_target</span><span class="p">.</span><span class="nf">set_weights</span><span class="p">(</span><span class="n">target_critic_one_weights</span><span class="p">)</span> <span class="c1"># 업데이트된 가중치로 설정  
</span>


<span class="n">profits_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">elapsedtime_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">max_return_test</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>
<span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">bool_fortrain</span> <span class="o">=</span> <span class="bp">False</span>


<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> 
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    
    <span class="c1">### Train for each epoch
</span>    
    <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> 
    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>  
    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_train</span><span class="p">)</span><span class="o">-</span><span class="mi">25</span><span class="p">):</span> 
        <span class="n">count_step_fortrain</span> <span class="o">+=</span> <span class="mi">1</span>  
        <span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epoch</span> <span class="o">/</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span> 
        <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_train</span><span class="p">,</span><span class="n">PV_prod_train</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span>     

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">count_step_fortrain</span> <span class="o">&gt;</span> <span class="n">period_step_fortrain</span><span class="p">:</span> 
                <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span><span class="n">actorupdate</span><span class="o">=</span><span class="n">bool_fortrain</span><span class="p">)</span>
                <span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">bool_fortrain</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">bool_fortrain</span> <span class="c1"># 한 번은 critic만, 한 번은 actor &amp; target까지 전부 업데이트하는 과정을 교대로 진행
</span>                
                
    <span class="c1">### Validation for each epoch  
</span>    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">testcase_actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">testcase_battenergy</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">epoch_return_test</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> <span class="c1"># 시작시점   
</span>        <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>
        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_test</span><span class="p">)</span><span class="o">-</span><span class="mi">24</span><span class="p">):</span> 
            <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_test</span><span class="p">,</span><span class="n">PV_prod_test</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> 
            <span class="n">testcase_actions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">testcase_battenergy</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">energy_batt</span><span class="p">)</span>
            <span class="n">epoch_return_test</span> <span class="o">+=</span> <span class="n">reward</span> 
            <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="n">profits_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">)</span>    
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_profit_test_ddpg.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">profits_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
    
        <span class="k">if</span> <span class="n">max_return_test</span> <span class="o">&lt;</span> <span class="n">epoch_return_test</span><span class="p">:</span>
            <span class="n">max_return_test</span> <span class="o">=</span> <span class="n">epoch_return_test</span>
            <span class="n">actor_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'actor_trainedmodel_ddpg.h5'</span><span class="p">)</span>
            <span class="n">critic_one_learning</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'critic_one_trainedmodel_ddpg.h5'</span><span class="p">)</span>
                    
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_actions_test_ddpg.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_actions</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_battenergy_test_ddpg.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_battenergy</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                        
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>   
        <span class="n">elapsedtime_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"Validation: profit of epoch {} is {}, maximum profit is {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="nf">round</span><span class="p">(</span><span class="n">max_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'one epoch 수행에 {}초 걸렸습니다'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_time_test_ddpg.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">elapsedtime_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="ddpg를-통한-continuous-control-결과">DDPG를 통한 continuous control 결과</h2>
<p>DDPG 훈련 결과, validation case에서의 누적 비용은 125유로이다.</p>

<p>놀랍게도(?), continuous control (DDPG) 의 결과가 3-action discrete control (DQN) 의 결과 (누적비용 50유로) 보다 나쁘다. 어떻게 된 걸까?</p>

<p>아래 그림으로 action을 비교해 보자.</p>

<p><img src="/assets/images/reinforcefour/result_ddpg.png" alt="result_ddpg" class="align-center" />
<em>DDPG로 도출한 수전/송전 control. LP control과는 차이가 있음.</em></p>

<p>태양광 발전량이 많아 낮에 송전하는 기간의 밤 시간대에 LP와 DQN에선 action의 값이 0, 즉 idle이다. 그러나 DDPG에서는 수전을 한다. 반대로 태양광 발전량이 적어 낮에 수전하는 기간의 밤 시간대에도 LP와 DQN에선 action이 idle인데 DDPG에서는 일부 송전을 한다.</p>

<p>즉 LP와 DQN control에서는 수 시간 연속으로 idle인 기간에, DDPG control에서는 송전 혹은 수전을 행한다. 그런데 이것이 sub-optimal control인 것으로 보인다.</p>

<p>이는 state를 input으로 하는 nonlinear continuous function 근사로는, 대부분의 input에 대해 output이 0, -1, +1 셋 중 하나이고 그 외 일부 input에 대해서만 값이 -1~0 또는 0~1 사이의 값을 출력하는 function을 (LP control에서처럼) 만들어내기 어렵기 때문인 것으로 추측된다.</p>

<p>즉, 미래를 모두 안다고 가정했을 때의 LP control은 DDPG로 도출한 control과는 거리가 있으며 DQN으로 도출한 control에 더 가까운 형태를 띤다. 그렇기 때문에, 놀랍게도(?) Vincent의 마이크로그리드 사례에서는 DQN의 discrete control이 DDPG의 continuous control 대비 더 나은 것으로 보인다.</p>

<p><br />
그러나 누군가는 이렇게 반박할 수 있다. “DDPG는 초창기 기법이다. 몇 년 뒤 Twin Delayed Deep Deterministic policy gradient (TD3)나 Soft Actor-Critic (SAC)처럼, 더 진보된 continuous control 방법들이 나왔다. 더 진보된 방법을 쓰면, 완벽한 continuous control을 얻을 것이다.”</p>

<p>과연 어떨까? 다음 포스팅에서 확인해 보겠다.</p>

<div class="notice--info">

강화학습 기반 마이크로그리드 control<br /><br />

1) <a href="/reinforceone.html">문제의식 및 케이스 소개</a><br />
2) <a href="/reinforcetwo.html">Q-learning 개념</a><br />
3) <a href="/reinforcethree.html">Deep Q-Network를 통한 discrete control 도출</a><br />
4) <b>DDPG를 통한 continuous control 도출</b><br />
5) <a href="/reinforcefive.html">TD3, SAC를 통한 continuous control 도출</a>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="energymanagement" /><category term="강화학습" /><category term="녹색섬" /><category term="Python" /><summary type="html"><![CDATA[Vincent의 마이크로그리드 사례에 ‘discrete’ action (1.1kW 수전/ 1.1kW 송전/ idle) 기반의 Deep Q-Network (DQN) 을 적용한 결과, 미래를 모른 채 과거 24시간 동안의 태양광 발전량과 부하 정보를 활용하더라도 충분히 economic control이 가능했다.]]></summary></entry><entry><title type="html">강화학습 기반 마이크로그리드 control - 3) Deep Q-Network를 통한 discrete control 도출</title><link href="https://song4energyndata.github.io/reinforcethree.html" rel="alternate" type="text/html" title="강화학습 기반 마이크로그리드 control - 3) Deep Q-Network를 통한 discrete control 도출" /><published>2023-06-11T00:00:00+09:00</published><updated>2023-06-11T00:00:00+09:00</updated><id>https://song4energyndata.github.io/reinforcethree</id><content type="html" xml:base="https://song4energyndata.github.io/reinforcethree.html"><![CDATA[<p>Vincent의 마이크로그리드 사례에서 Q-learning의 concept를 이용하기 위해, 실제로는 수전/송전이 continuous한 값임에도 불구하고, 1.1kW 수전/ 1.1kW 송전/ idle 의 3가지 action만을 고려하기로 했다. 각 action 별 인덱스는 0, 1, 2라 하자.</p>

<p><img src="/assets/images/reinforceone/system.png" alt="system" class="align-center" />
<em>Vincent의 연구에서 가정된 마이크로그리드.</em></p>

<p>이 때 심층신경망은 state를 입력받아 3개 action 각각의 Q-value의 추정치 $Q(s_{t},0), Q(s_{t},1), Q(s_{t},2)$ 를 출력으로 계산한다. 이 심층신경망은 매 훈련 주기마다 튜플 $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다.</p>

<p><br /></p>

<h2 id="심층신경망-구성-및-훈련-컨셉">심층신경망 구성 및 훈련 컨셉</h2>
<p>심층신경망 구성은 아래 그림과 같다.</p>

<p><img src="/assets/images/reinforcethree/nn.png" alt="nn" class="align-center" />
<em>Vincent의 연구에서 사용된 심층신경망 구성. (논문의 그림을 필자가 재구성하였음)</em></p>

<p>직전 24시간의 태양광 발전량은 첫 번째 Conv1D 층에, 직전 24시간의 부하는 두 번째 Conv1D 층에, 그리고 직전 1시간의 배터리 내 에너지양은 위 두 Conv1D층과 연결되는 Dense층에 바로 연결된다.</p>

<p>그리고 Dense층이 하나 더 있고, 이 층을 거쳐서 최종적으로 3개의 output node가 각 action별 Q-value를 출력한다. Conv1D 층을 쓰는 이유는, 태양광 발전량과 부하가 시간적인 정보를 갖고 있으므로 이를 반영하기 위함이다.</p>

<p>해당 심층신경망 훈련을 위한 training set은 특정 2년 (17,520시간) 동안의 시간별 태양광발전량과 부하 자료이다. 해당 모델이 직전 24시간의 정보를 state로 사용하므로 control은 $t=25,26,\cdots, 17520$ 에 대해 정해진다. Validation set은 별도의 특정 1년 (8,760시간) 동안의 시간별 태양광 발전량과 부하 자료이다.</p>

<p>Training set에 대해서는 $\epsilon$-greedy policy를, validation set에 대해서는 greedy policy를 적용해 action을 결정한다.</p>

<p>매 time step (데이터에서의 1시간) 별로 state와 action에 따른 마이크로그리드 내 에너지 흐름 및 수전/송전에 따른 손익 (reward) 와 이번 시점의 배터리 내 에너지 (다음 시점에서의 state임) 를 계산하고, 매 24시간 주기로 심층신경망 훈련을 gradient descent로 수행한다. 이를 training set의 17,520-24 시간에 대해 수행하면 1 epoch이다.</p>

<p>매 심층신경망 훈련 시 사용하는 데이터는 기본적으로 (state, action, reward, next state) 를 묶은 tuple로, 일종의 ‘경험’으로 볼 수 있다. 즉 시점 $t$에서 ($s_{t},a_{t},r_{t+1},s_{t+1}$) 를 추후 훈련에 쓸 수 있도록 buffer에 저장한다.</p>

<p>그리고 24시간 주기의 훈련에서는 직전 24시간의 tuple들이 아닌, buffer 내에서 랜덤하게 뽑은 32개 시간의 tuple들을 이용해 훈련시킨다. 이를 통해 훈련에 쓰이는 tuple들 간의 ‘시간적 상관성’을 감소시켜, 훈련의 효율성을 높일 수 있다.</p>

<p><br /></p>

<h2 id="dqn-코드">DQN 코드</h2>
<p>이제 훈련 concept는 대략 이해가 될 것이니, 코드를 보자.</p>

<p>이 코드는 필자가 직접 작성하였다. Vincent의 학위논문에서 해당 연구에 사용한 코드의 <a href="https://github.com/VinF/deer/tree/master/examples/MG_two_storages">Github 링크</a>를 제공하나, 각 모듈별로 코드 파일들을 지나치게 분리해 놓아 사용이 여의치 않았다. 이에 필자가 ‘모든 기능들을 한 파일에 넣은 공부용’ 코드를 따로 만들었다. (<a href="https://github.com/song4energyndata/Codes/tree/main/reinforcementlearning/microgrid_Vincent">GitHub Repo 링크</a>)</p>

<p>(코드 작성 시 <a href="https://product.kyobobook.co.kr/detail/S000001810262">핸즈온 머신러닝</a>의 강화학습 chapter의 Cartpole 예제에 대한 Deep Q-Network 코드를 참고하였다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="c1">### hyperparameters
</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.005</span><span class="p">)</span> <span class="c1"># learning rate 너무 높으면 발산할 수 있음에 주의
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">discount_factor</span> <span class="o">=</span> <span class="mf">0.98</span>
<span class="n">period_step_fortrain</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">rewardscalefactor</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">6</span>
<span class="n">buffer_size</span> <span class="o">=</span> <span class="mi">20000</span>



<span class="c1">### microgrid system data
</span>
<span class="c1"># 시간별 데이터 출처: https://github.com/VinF/deer/tree/master/examples/MG_two_storages/data
</span><span class="n">PV_prod_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_train.npy'</span><span class="p">)</span> <span class="c1"># [0,1] 구간 내로 scaled된 데이터임, unscaling은 play_one_step 함수 내에서 이루어짐
</span><span class="n">PV_prod_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'BelgiumPV_prod_test.npy'</span><span class="p">)</span> 

<span class="n">load_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_train.npy'</span><span class="p">)</span> <span class="c1"># [0,1] 구간 내로 scaled된 데이터임, unscaling은 play_one_step 함수 내에서 이루어짐
</span><span class="n">load_test</span>  <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="s">'example_nondeterminist_cons_test.npy'</span><span class="p">)</span>

<span class="n">prate_h2</span> <span class="o">=</span> <span class="mf">1.1</span> <span class="c1"># 수전/송전 상한
</span><span class="n">eff_h2</span> <span class="o">=</span> <span class="mf">0.65</span> <span class="c1"># 수소-전기 변환효율
</span>
<span class="n">capa_batt</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1"># 배터리 용량 (겉보기용량 말고 SOC 상하한 고려한 실용량이라 가정)
</span><span class="n">eff_batt</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># 배터리 충방전 효율
</span><span class="n">initialenergy_batt</span> <span class="o">=</span> <span class="mf">0.0</span> <span class="c1"># epoch의 시작에서 배터리 내 에너지량 (최대저장가능량 대비 상대비율, Qval NN에는 이 상대비율이 입력되며, play_one_step 함수 내에서의 에너지시스템 밸런스 수식에서는 실제 에너지값으로 변환됨
</span>
<span class="n">price_h2</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">cost_loss</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">load_peak</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pv_peak</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">inputlen_load</span> <span class="o">=</span> <span class="mi">24</span>
<span class="n">inputlen_pv</span> <span class="o">=</span> <span class="mi">24</span>



<span class="c1">### Neural net configuration
</span>
<span class="n">n_outputs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">input_load</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 과거 24시간의 부하, shape의 두번째 숫자는 채널 수 (컬러사진의 RGB 등), 채널 수를 정의해야 Conv1D가 작동함
</span><span class="n">input_pv</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 과거 24시간의 태양광발전량
</span><span class="n">hidden_conv_load</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">input_load</span><span class="p">)</span>
<span class="n">hidden_conv_pv</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">input_pv</span><span class="p">)</span>
<span class="n">concat_conv</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">hidden_conv_load</span><span class="p">,</span><span class="n">hidden_conv_pv</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">hidden_conv_concat</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Conv1D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)(</span><span class="n">concat_conv</span><span class="p">)</span>
<span class="n">flatten_conv</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">()(</span><span class="n">hidden_conv_concat</span><span class="p">)</span> <span class="c1"># Dense층 직전에 Conv층을 Flatten해야 함
</span><span class="n">input_others</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># 직전 시간의 배터리 내 에너지량
</span><span class="n">concat_all</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">([</span><span class="n">flatten_conv</span><span class="p">,</span><span class="n">input_others</span><span class="p">])</span> 
<span class="n">hidden_dense_1</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">concat_all</span><span class="p">)</span>
<span class="n">hidden_dense_2</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"relu"</span><span class="p">)(</span><span class="n">hidden_dense_1</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">n_outputs</span><span class="p">)(</span><span class="n">hidden_dense_2</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">output</span><span class="p">])</span>



<span class="k">def</span> <span class="nf">e_greedy_policy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span><span class="n">epsilon</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span> <span class="c1"># epsilon-greedy policy
</span>    <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span> <span class="c1"># epsilon의 확률로 exploration
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># action을 랜덤하게 선택
</span>    <span class="k">else</span><span class="p">:</span> <span class="c1"># exploitation
</span>        <span class="n">input_load</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Conv1D의 input이므로 채널 수 1 명시
</span>        <span class="n">input_pv</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">input_others</span> <span class="o">=</span><span class="n">state</span><span class="p">[(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Dense층의 input이므로 채널 수는 필요 없음
</span>        <span class="n">Q_values</span> <span class="o">=</span> <span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span> <span class="c1"># 각 action 별 Q-value 도출
</span>        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Q_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 가장 큰 Q-value에 대응하는 action 선택      
</span>        <span class="c1"># 주의: for loop 안에서 DNN에 input을 입력해 output 계산 시 model()로 해야지, model.predict()로 하면 안 됨! 메모리 누수가 발생함 (model.predict는 대량의 input data를 'model.predict를 한 번만 호출해서' 처리하는 데 특화됨, https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict 참고)
</span>


<span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="n">replay_buffer</span> <span class="o">=</span> <span class="nf">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">buffer_size</span><span class="p">)</span> <span class="c1"># replay buffer 정의
</span>
<span class="k">def</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> <span class="c1"># batch_size만큼의 경험들의 state들, action들, reward들, nextstate들의 리스트들을 반환
</span>    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">replay_buffer</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1"># replay buffer 내 경험들 중 랜덤하게 batch_size만큼의 경험들을 지정 (인덱스 불러옴)
</span>    <span class="n">batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">replay_buffer</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span> <span class="c1"># 위에서 불러온 인덱스를 이용해 batch_size 만큼의 경험들을 batch 리스트에 담음
</span>    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">experience</span><span class="p">[</span><span class="n">field_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">experience</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span> <span class="c1"># 하나의 array 안에 batch 내 각 경험별 값들이 들어감 
</span>        <span class="k">for</span> <span class="n">field_index</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span> <span class="c1"># 총 4개의 array를 반환, 각각은 (batch 내 sample경험들의) state들, action들, reward들, nextstate들의 리스트임
</span>    <span class="k">return</span> <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span>



<span class="k">def</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">profile_load</span><span class="p">,</span><span class="n">profile_pv</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span> <span class="c1"># 마이크로그리드 시스템의 시간별 operation 모델링
</span>        
    <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_load</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="n">inputlen_pv</span><span class="p">:</span><span class="n">hour</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt</span><span class="p">]))</span> <span class="p">)</span>
    
    <span class="n">action</span> <span class="o">=</span> <span class="nf">e_greedy_policy</span><span class="p">(</span><span class="n">state</span><span class="p">,</span><span class="n">epsilon</span><span class="p">)</span> <span class="c1"># epsilon-greedy policy에 따라 action 도출
</span>    <span class="n">p_h2_send</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 수소로 생산된 전기 수전
</span>        <span class="n">p_h2_receive</span> <span class="o">=</span> <span class="n">prate_h2</span>
    <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># 수소 생산용 전기 송전
</span>        <span class="n">p_h2_send</span> <span class="o">=</span> <span class="n">prate_h2</span>
       

    <span class="n">p_load</span> <span class="o">=</span> <span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">load_peak</span> <span class="c1"># 현재 시간의 부하 (action 결정 기준이 아님!), 입력자료가 [0,1]로 scaled된 걸 unscaling
</span>    <span class="n">p_pv</span> <span class="o">=</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="p">]</span><span class="o">*</span><span class="n">pv_peak</span> <span class="c1"># 현재 시간의 발전량 (action 결정 기준이 아님!), 입력자료가 [0,1]로 scaled된 걸 unscaling  
</span>    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">capa_batt</span> <span class="c1"># 입력자료가 [0,1]로 scaled된 걸 unscaling
</span>    
    <span class="c1">#p_curtail = 0
</span>    <span class="n">p_loss</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="n">p_net_beforebatt</span> <span class="o">=</span> <span class="n">p_pv</span> <span class="o">-</span> <span class="n">p_load</span> <span class="o">+</span> <span class="n">p_h2_receive</span> <span class="o">-</span> <span class="n">p_h2_send</span> <span class="c1"># 태양광 생산, 부하 충족, H2 보내거나 받은 후 수용가 입장에서 전기에너지가 남으면 양수, 부족하면 음수
</span>    
    <span class="k">if</span> <span class="n">p_net_beforebatt</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 전기에너지가 남으므로 배터리에 저장하고, 만약 배터리도 꽉 찬다면 curtail함
</span>        <span class="k">if</span> <span class="n">capa_batt</span> <span class="o">&gt;=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span><span class="p">:</span> <span class="c1"># 배터리에 잔여 충전 가능한 에너지가 위에서 남은 에너지(에서 변환손실 제한 에너지) 이상일 경우
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">*</span><span class="n">eff_batt</span>
        <span class="k">else</span><span class="p">:</span> <span class="c1"># 남은 에너지를 배터리에 다 충전하면 꽉 차고도 남아서, curtail해야 함
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">capa_batt</span>
            <span class="c1">#p_curtail = (energy_batt + p_net_beforebatt*eff_batt - capa_batt)/eff_batt # 괄호 안은 배터리 내부 기준이며, 수용가 모선 기준 양을 구하려면 eff_batt로 나눠줘야 함
</span>    <span class="k">else</span><span class="p">:</span> <span class="c1"># 전기에너지가 부족하므로 배터리 에너지를 써야 함, 배터리 에너지로도 부족하면 loss임
</span>        <span class="k">if</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span><span class="p">:</span> <span class="c1"># 배터리 에너지로 충당 가능한 경우
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt</span> <span class="o">+</span> <span class="n">p_net_beforebatt</span><span class="o">/</span><span class="n">eff_batt</span> <span class="c1"># p_net_beforebatt가 음수이므로 마이너스값이 부족한 에너지'량'이고 그걸 '빼'므로 결과적으로 플러스
</span>        <span class="k">else</span><span class="p">:</span> <span class="c1"># 부족해 loss 발생
</span>            <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">p_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">p_net_beforebatt</span> <span class="o">-</span> <span class="n">energy_batt</span><span class="o">*</span><span class="n">eff_batt</span>           
    
    <span class="n">reward</span> <span class="o">=</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_send</span><span class="o">*</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">price_h2</span><span class="o">*</span><span class="n">p_h2_receive</span><span class="o">/</span><span class="n">eff_h2</span> <span class="o">-</span> <span class="n">cost_loss</span><span class="o">*</span><span class="n">p_loss</span>
    <span class="n">energy_batt_after</span> <span class="o">=</span> <span class="n">energy_batt_after</span><span class="o">/</span><span class="n">capa_batt</span> <span class="c1"># 배터리 내 저장량을 [0,1] 범위로 scaling함
</span>    
    <span class="k">if</span> <span class="n">training</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">concatenate</span><span class="p">(</span> <span class="p">(</span><span class="n">profile_load</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_load</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">profile_pv</span><span class="p">[</span><span class="n">hour</span><span class="o">-</span><span class="p">(</span><span class="n">inputlen_pv</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span><span class="n">hour</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">energy_batt_after</span><span class="p">]))</span> <span class="p">)</span>         
        <span class="n">replay_buffer</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="o">*</span><span class="n">rewardscalefactor</span><span class="p">,</span> <span class="n">next_state</span><span class="p">))</span> <span class="c1"># replay buffer에는 scaled reward를 넣으며, tuple을 append함에 주의
</span>    <span class="k">return</span> <span class="n">energy_batt_after</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="c1"># scaled 배터리 내 저장량, unscaled reward, action index 반환
</span>


<span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span> <span class="c1"># 심층신경망에 대해 Gradient descent 기반 가중치 업데이트 수행
</span>
    <span class="n">states</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">next_states</span> <span class="o">=</span> <span class="nf">sample_experiences</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
        
    <span class="n">input_load</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 
    <span class="n">input_pv</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others</span> <span class="o">=</span> <span class="n">states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">input_load_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="n">inputlen_load</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_load</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_pv_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,</span><span class="n">inputlen_load</span><span class="p">:(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">inputlen_pv</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">input_others_next</span> <span class="o">=</span> <span class="n">next_states</span><span class="p">[:,(</span><span class="n">inputlen_load</span><span class="o">+</span><span class="n">inputlen_pv</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
      
    <span class="n">next_Q_values</span> <span class="o">=</span> <span class="nf">model</span><span class="p">((</span><span class="n">input_load_next</span><span class="p">,</span><span class="n">input_pv_next</span><span class="p">,</span><span class="n">input_others_next</span><span class="p">))</span> <span class="c1"># Q-learning을 위해, 'next'state에서의 각 action 별 Q-value 추정치들 반환
</span>    <span class="n">max_next_Q_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">next_Q_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 각 경험별로 nextstate에 대한 Q-value가 더 높은 행동의 Q-value 사용
</span>    <span class="n">target_Q_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">rewards</span> <span class="o">+</span> <span class="n">discount_factor</span> <span class="o">*</span> <span class="n">max_next_Q_values</span><span class="p">)</span> <span class="c1"># Q-value를 reward와 nextstate에 대한 Q-value(discounted)의 합으로 표현
</span>    <span class="n">target_Q_values</span> <span class="o">=</span> <span class="n">target_Q_values</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 뒤의 Q_values와 차원 맞춰줌
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">one_hot</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">n_outputs</span><span class="p">)</span> <span class="c1"># 각 경험 별 action을 one-hot encoding 형태로 만들어줌 (각 행이 경험)
</span>    <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span> <span class="c1"># 자동 미분
</span>        <span class="n">all_Q_values</span> <span class="o">=</span> <span class="nf">model</span><span class="p">((</span><span class="n">input_load</span><span class="p">,</span><span class="n">input_pv</span><span class="p">,</span><span class="n">input_others</span><span class="p">))</span> 
        <span class="n">Q_values</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">all_Q_values</span> <span class="o">*</span> <span class="n">mask</span><span class="p">,</span> <span class="c1"># mask를 곱해서, 각 경험별로 그 state에서 취하지 않은 action에 대해서는 Q-value에 0이 곱해지도록 함
</span>                                 <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># 각 행 별 합을 구함, 위의 masking 덕분에 그 state에서 취한 action에 대한 Q-value가 됨, keepdims를 True로 설정해 2차원 행렬 형태 유지
</span>        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_mean</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">target_Q_values</span><span class="p">,</span><span class="n">Q_values</span><span class="p">))</span> <span class="c1"># 평균제곱오차 계산
</span>    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">)</span> <span class="c1"># loss 함수를 model의 trainable variables 전체에 대해 미분
</span>    <span class="n">optimizer</span><span class="p">.</span><span class="nf">apply_gradients</span><span class="p">(</span><span class="nf">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="p">.</span><span class="n">trainable_variables</span><span class="p">))</span> <span class="c1"># Adam optimizer로 parameter update 수행, zip으로 gradient와 parameter pair를 맞춰줌
</span>


<span class="n">profits_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">elapsedtime_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">max_return_test</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span> 
    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># 맨 첫 번째 epoch에서는 훈련을 시작하지 않고 buffer를 채움, 두 번째 epoch부터는 buffer에 sample들이 채워졌으므로 훈련함
</span>        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
    
    <span class="c1">### Train for each epoch  
</span>    <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> <span class="c1"># 시작시점
</span>    <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span>  <span class="c1"># 배터리 내 에너지의 초기값
</span>    
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_train</span><span class="p">)</span><span class="o">-</span><span class="mi">25</span><span class="p">):</span> <span class="c1"># 데이터 내의 마지막 시점이 nextstate에만 포함될 때까지 (대신 termination state는 따로 없음)
</span>        <span class="n">count_step_fortrain</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">epsilon</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">epoch</span> <span class="o">/</span> <span class="mi">50</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span> <span class="c1"># epsilon을 1에서 시작해 조금씩 선형적으로 줄임, 이 경우 초반에는 거의 다 exploration이므로 한 epoch가 매우 빨리 계산되나, 중반을 넘어가면 거의 exploitation이며 이 때 매 step마다 DNN을 call하므로 느려짐
</span>        <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_train</span><span class="p">,</span><span class="n">PV_prod_train</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="n">epsilon</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># energy_batt가 반복 갱신됨
</span>        <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># 다음 시간으로  
</span>
        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">count_step_fortrain</span> <span class="o">&gt;</span> <span class="n">period_step_fortrain</span><span class="p">:</span> <span class="c1"># 훈련 주기, 매 시간마다 train하면 epoch당 시간이 너무 길어지고 overfitting 우려도 있어, 매 24시간마다 훈련함, 첫 epoch에서는 replay buffer를 채우기만 하고, 나머지 99 epoch 동안 심층신경망 가중치를 업데이트함
</span>                <span class="nf">training_step</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span> <span class="c1"># DNN 훈련을 위한 Gradient Descent 수행
</span>                <span class="n">count_step_fortrain</span> <span class="o">=</span> <span class="mi">0</span>


    <span class="c1">### Validation for each epoch  
</span>    <span class="k">if</span> <span class="n">epoch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">testcase_actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">testcase_battenergy</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">epoch_return_test</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># return (각 시점별 수익의 총 합) 초기화
</span>        
        <span class="n">hour</span> <span class="o">=</span> <span class="mi">24</span> <span class="c1"># 시작시점   
</span>        <span class="n">energy_batt</span> <span class="o">=</span> <span class="n">initialenergy_batt</span> <span class="c1"># 배터리 내 에너지의 초기값
</span>        
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">load_test</span><span class="p">)</span><span class="o">-</span><span class="mi">24</span><span class="p">):</span> <span class="c1"># 데이터 내의 마지막 시점이 nextstate에만 포함될 때까지 (대신 termination state는 따로 없음)
</span>            <span class="n">energy_batt</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">action</span> <span class="o">=</span> <span class="nf">play_one_step</span><span class="p">(</span><span class="n">load_test</span><span class="p">,</span><span class="n">PV_prod_test</span><span class="p">,</span><span class="n">hour</span><span class="p">,</span><span class="n">energy_batt</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># energy_batt가 반복 갱신됨
</span>            <span class="n">testcase_actions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
            <span class="n">testcase_battenergy</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">energy_batt</span><span class="p">)</span>
            <span class="n">epoch_return_test</span> <span class="o">+=</span> <span class="n">reward</span> <span class="c1"># 누적보상 계산
</span>            <span class="n">hour</span> <span class="o">+=</span> <span class="mi">1</span> <span class="c1"># 다음 시간으로    
</span>        
        <span class="n">profits_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">)</span> <span class="c1"># 각 epoch별 총 수익 로그 저장
</span>        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_profit_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">profits_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                
        <span class="k">if</span> <span class="n">max_return_test</span> <span class="o">&lt;</span> <span class="n">epoch_return_test</span><span class="p">:</span> <span class="c1"># Validation set에서의 총 수익의 최대값 갱신시마다 저장 (unlearn하게 되더라도 중간에 best performance였던 모델을 남김)
</span>            <span class="n">max_return_test</span> <span class="o">=</span> <span class="n">epoch_return_test</span>
            <span class="n">model</span><span class="p">.</span><span class="nf">save_weights</span><span class="p">(</span><span class="s">'trainedmodel_dqn.h5'</span><span class="p">)</span> <span class="c1"># 모델 가중치 저장
</span>                    
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_actions_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># Validation case에서의 시간별 action 로그 저장
</span>                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_actions</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
            
            <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_battenergy_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># Validation case에서의 시간별 배터리 내 저장된 에너지 로그 저장
</span>                    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">testcase_battenergy</span><span class="p">:</span>
                        <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
                        
        <span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>   
        <span class="n">elapsedtime_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"Validation: profit of epoch {} is {}, maximum profit is {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="nf">round</span><span class="p">(</span><span class="n">epoch_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="nf">round</span><span class="p">(</span><span class="n">max_return_test</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'one epoch 수행에 {}초 걸렸습니다'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">round</span><span class="p">(</span><span class="n">elapsed_time</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="s">'trajectory_time_test_dqn.txt'</span><span class="p">,</span> <span class="s">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span> <span class="c1"># 각 epoch별 소요시간 로그 저장
</span>            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">elapsedtime_test</span><span class="p">:</span>
                <span class="n">f</span><span class="p">.</span><span class="nf">write</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">line</span><span class="si">}</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>Epoch당 계산 시간이 긴데, 이유는 매 시간 별 action을 결정할 때마다 심층신경망에 state를 입력해 Q-value들을 계산하는 과정을, training case에 대해서는 이를 8760x2-24번, validation case에 대해서는 8760-24번을 수행해야 하기 때문이다.</p>

<p><br /></p>

<h2 id="dqn을-통한-discrete-control-결과">DQN을 통한 discrete control 결과</h2>
<p>훈련을 수행하면, validation case 기준으로 불과 몇 epoch만에 누적 비용이 200유로 이하로 줄어든다. 그리고 99 epoch 훈련 동안 validation case에 대해 가장 좋은 결과를 보인 모델의 경우 누적 비용이 27유로이다.</p>

<p><img src="/assets/images/reinforcethree/trainingrecord.png" alt="trainingrecord" class="align-center" width="80%" />
<em>훈련 epoch 별 validation case의 누적 ‘수익’.</em></p>

<p>누적비용 27유로는, 미래를 안다고 가정하고 선형계획법 (Linear Programming, LP) 으로 도출한 control 시의 누적비용 -50유로에 근접한 값이다.</p>

<p>그러므로, 미래를 모르면서 과거 24시간 정보만 갖고 도출한 ‘discrete’ control 것 치고는 훌륭해 보인다. (Random control 시의 누적비용 2500~2700유로와 비교하면 큰 개선이다.)</p>

<p>시간별 action (계통으로부터의 수전) 이 LP와 DQN에서 각각 어떻게 결정되었는지를 아래 그림과 같이 보자.</p>

<p><img src="/assets/images/reinforcethree/result_dqn.png" alt="result_dqn" class="align-center" />
<em>DQN으로 도출한 수전/송전 control. LP control과 어느 정도 비슷함.</em></p>

<p>LP와 DQN으로 도출한 두 control들이 생각보다는 비슷하다. ‘대체로’ LP control에서서 수전하는 시간대에 DQN control에서도 수전하고, LP control에서 송전하는 시간대에 DQN control에서도 송전하며, LP control에서 idle인 시간대에 DQN control에서도 idle이다.</p>

<p>특히 LP control은 [-1.1,1.1] 범위 내의 실수로 주어지는 ‘continuous’ control임에도 불구하고, DQN의 action들에 대응하는 최대치 송전/최대치 수전/ idle인 경우가 많다는 점이 특기할 만하다. 이 덕분에, 3-action DQN으로 우수한 economic control을 얻을 수 있는 것으로 보인다.</p>

<p><br /></p>

<h2 id="continuous-control을-한다면">Continuous control을 한다면?</h2>
<p>그렇지만, LP control에서와 DQN control 간에 최대치 송전/ 최대치 수전/ idle 지속시간의 차이가 있고, LP control에서 이 3개 값이 아닌 다른 값인 경우도 (즉 최대치가 아닌 양으로 송전/수전하는 경우도) 분명히 많이 존재한다.</p>

<p>그렇다면 [-1.1,1.1] 범위 내의 실수로 action을 도출하는, continuous control 심층강화학습 기법을 쓰면 어떨까? 최대치가 아닌 송전/ 수전의 가능성까지 반영한 controller를 훈련함으로써, validation case에 대해 더 낮은 누적비용을 달성하는 control 도출이 가능할까?</p>

<p>다음 포스팅에서는, continuous control을 위한 심층강화학습 중 가장 기본적이면서 중요한 방법인 Deep Deterministic Policy Gradient (DDPG) 를 적용하는 방법 및 결과를 설명한다.</p>

<div class="notice--info">

강화학습 기반 마이크로그리드 control<br /><br />

1) <a href="/reinforceone.html">문제의식 및 케이스 소개</a><br />
2) <a href="/reinforcetwo.html">Q-learning 개념</a><br />
3) <b>Deep Q-Network를 통한 discrete control 도출</b><br />
4) <a href="/reinforcefour.html">DDPG를 통한 continuous control 도출</a><br />
5) <a href="/reinforcefive.html">TD3, SAC를 통한 continuous control 도출</a>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="energymanagement" /><category term="강화학습" /><category term="녹색섬" /><category term="Python" /><summary type="html"><![CDATA[Vincent의 마이크로그리드 사례에서 Q-learning의 concept를 이용하기 위해, 실제로는 수전/송전이 continuous한 값임에도 불구하고, 1.1kW 수전/ 1.1kW 송전/ idle 의 3가지 action만을 고려하기로 했다. 각 action 별 인덱스는 0, 1, 2라 하자.]]></summary></entry><entry><title type="html">강화학습 기반 마이크로그리드 control - 2) Q-learning 개념</title><link href="https://song4energyndata.github.io/reinforcetwo.html" rel="alternate" type="text/html" title="강화학습 기반 마이크로그리드 control - 2) Q-learning 개념" /><published>2023-06-10T00:00:00+09:00</published><updated>2023-06-10T00:00:00+09:00</updated><id>https://song4energyndata.github.io/reinforcetwo</id><content type="html" xml:base="https://song4energyndata.github.io/reinforcetwo.html"><![CDATA[<p>지난 포스팅에서, Vincent의 태양광 기반 마이크로그리드의 누적 비용을 최소화하는 최적 control 문제를 소개했다. 또한 이를 선형계획법으로 풀 경우 ‘미래의 태양광 발전량과 부하를 안다’라는, ‘비현실적’인 가정 하의 control을 도출함을 보였다.</p>

<p>이번 포스팅에서는 ‘매 시점별로 과거의 자료만을 갖고’ control하는 데 필요한 강화학습의 이론적 내용을 최대한 간단히 소개한다 (강화학습에 대한 상세 내용은 <a href="https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf">Sutton의 Introduction</a> 참고 바람)</p>

<p><br /></p>

<h2 id="state-action-pair-별-누적-보상">State-action pair 별 누적 보상</h2>
<p>먼저, 강화학습에서 가장 널리 쓰이는 방법인인 Q-learning을 간단히 설명한다.</p>

<p>어떤 환경에서 시점 t에 state $s_{t}$에 있고, 이 때 action $a_{t}$를 수행하면 reward $r_{t+1}$을 받으면서 ‘next’ state $s_{t+1}$로 전이된다고 하자.</p>

<p><img src="/assets/images/reinforceone/reinforcement_basic.png" alt="reinforcement_basic" class="align-center" width="70%" />
<em>강화학습 개요. State $S_t$에서 Action $A_t$를 취하면 Reward $R_{t+1}$을 얻으면서 State $S_{t+1}$로 전이됨.</em></p>

<p>Vincent의 마이크로그리드 사례에서는, 시점 $t$에서 state는 $t-N, t-(N-1), …, t-1$ 시점들의 태양광발전량과 부하 및 $t-1$시점의 배터리 내 에너지량들의 총 $2N+1$차원 벡터로 두었고, action은 net 수전량 $p_{\text{import}}[t]-p_{\text{export}}[t]$이다 (net 송전 시 마이너스). Reward는 계통으로 송전시의 수익 (양의 reward) 또는 계통으로부터 수전하거나 loss of load가 발생할 때의 비용 (음의 reward) 이다.</p>

<p>참고로 ESS의 충/방전은, 계통 수전/송전 값이 결정되면 에너지 밸런스를 맞추도록 ‘자동으로’ 결정된다고 가정한다. 이런 식으로 action의 자유도(degree of freedom)를 줄여야 실제 계산이 용이해진다.</p>

<p><br />
각 state $s$에서 action $a$를 할 확률을 나타내는 policy $\pi(a \vert s)$가 주어졌다고 하자. 그리고 시점 $t$에서의 state $s_t$이고, 시점 $t$에서는 poilcy $\pi(a \vert s)$에 관계없이 특정 action $a_t$를 결정하되, 다음 시점인 $t+1$부터는 $\pi(a \vert s)$에 따라 action들 $a_{t+1}, a_{t+2}, \cdots$를 결정한다고 하자.</p>

<p>이 때, state-action pair $(s_t,a_t)$에 대해 ‘미래의 reward들을 합친 누적 보상(return)의 기대값’ $q_{\pi}(s_{t},a_{t})$는 다음과 같다.</p>

<p>$ q_{\pi}(s_{t},a_{t}) = \mathbb{E} [r_{t+1} + \gamma r_{t+2} + \gamma^2 r_{t+3} + \cdots] $</p>

<p>우변에 기대값 기호 $ \mathbb{E}$가 붙은 이유는, 일반적으로는 같은 $s_{t}$에서 같은 $a_{t}$를 수행하더라도, 그 결과인 $r_{t+1}$과 $s_{t+1}$는 그때그때 다를 수 있으며 (즉 random, stochastic일 수 있음), 이에 따라 $t+1$시점 이후의 보상과 상태 전이도 달라질 수 있기 때문이다. 마이크로그리드 케이스에서도, 태양광 발전량과 부하는 외생적으로 random하게 결정되며 이에 따라 수전/송전량이 결정되므로, reward도 random하게 결정된다.</p>

<p>$\gamma$는 1보다는 작되 1에 가까운 양수로 discount factor이다. 이를 곱하지 않으면, 환경에서의 행동이 특정 시점에 반드시 끝나는 게 아닌 한 누적비용이 무한대가 될 수 있다. 그러므로 discount factor를 곱해줘야 누적비용이 유한한 값으로 보장된다.</p>

<p><br /></p>

<h2 id="누적-보상-추정-bellman-equation과-q-learning">누적 보상 추정: Bellman equation과 Q-learning</h2>

<p>한편 시점 $t+1$에 대해서도 $q_{\pi}(s_{t+1},a_{t+1})$이 정의되므로, 위 식은 아래와 같이 $q_{\pi}$에 대해 재귀적인(recursive) 식으로 쓸 수 있다.</p>

<p>$ q_{\pi}(s_{t},a_{t}) = \mathbb{E} [r_{t+1} + \gamma q_{\pi}(s_{t+1},a_{t+1}) ] $</p>

<p>특히 주어진 policy가 ‘최적의’ 즉 optimal policy라면, 시점 $t+1$부터의 action들은 미래 누적비용의 기대값을 최대화도록 선택될 것이다. 따라서 ‘optimal policy 조건 하의’ 누적 보상의 기대값 $q_{\ast}$에 대해, $\text{max}$를 포함하는 아래 식이 성립한다.</p>

<p>$ q_{\ast} (s_{t},a_{t}) = \mathbb{E} [r_{t+1} + \gamma \text{max}_{a_{t+1}} q_{\ast} (s_{t+1},a_{t+1}) ] $</p>

<p>이를 Bellman equation이라 한다.</p>

<p><br />
우리는 optimal policy 및 각 state-action pair 별 $q_{\ast}(s,a)$ 값을 모른다. 그러므로 처음에는 특정 policy 및 $q_{\ast}(s,a)$에 대한 추정량 $Q(s,a)$의 초기값으로부터 출발한다. 그리고 해당 policy 및 $Q(s,a)$를 업데이트시켜서, 점차 optimal policy 및 $q_{\ast}(s,a)$에 근접하게 만들어야 한다.</p>

<p>Bellman equation의 식을 보면, 우변에서 next state에 대해 $q_{\ast}$ 값을 최대화하는 action을 선택함이 전제되어 있다. 이에 착안해, 아래와 같은 $Q(s,a)$의 업데이트 방법을 생각할 수 있다.</p>

<p>$ Q(s_{t},a_{t}) \leftarrow (1-\alpha) Q(s_{t},a_{t}) + \alpha [r_{t+1} + \gamma \text{max}_{a_{t+1}} Q(s_{t+1},a_{t+1})] $</p>

<p>즉 시점 $t$에서 state $s_t$일 때 action $a_t$를 수행하여 reward $r_{t+1}$을 얻고 next state $s_{t+1}$로 전이되었다면, $s_{t+1}$에서 가능한 action들 중 추정량 $Q(s_{t+1},a_{t+1})$를 최대화하는 action $a_{t+1}$을 선택한다고 가정하고 $Q(s_{t},a_{t})$를 업데이트한다. (여기서 $\alpha$는 작은 양수로, learning rate이다)</p>

<p>처음에는 모든 state-action pair들에 대해 $Q(s,a)$를 0으로 초기화하고, 시점 $t$에서 action을 결정해서 $t+1$로 넘어갈 때마다 위와 같이 업데이트 한다.</p>

<p>처음에는 모든 $Q$값이 0이므로 각 state $s$ 별로 $Q(s,a)$를 최대화하는 $a$가 무작위이다. 그러나 업데이트를 수행하면서 ‘실제 환경에서 얻은 정보’인 reward $r_{t+1}$ 를 계속 반영하므로, 업데이트를 거듭할수록 $Q(s,a)$가 점차 $ q_{\ast} (s,a)$에 가까워짐이 알려져 있다. 이에 따라, $Q(s,a)$를 최대화하는 $a$가 무엇인지 뚜렷해지므로 policy도 업데이트되는 셈이다.</p>

<p>이러한 업데이트 방법을 Q-learning이라 한다.</p>

<p><br />
Vincent의 마이크로그리드 사례에서는, 실제 수전량은 -1.1에서 +1.1 사이의 실수이지만 (마이너스값은 송전), 문제를 간단히 하기 위해 세 가지의 ‘discrete’ action들로 구성된 action set (1.1kW로 수전, 1.1kW로 송전, 수전도 송전도 하지 않음 (idle)) 을 가정했다.</p>

<p>위 세 가지 action 각각의 각 action의 인덱스를 0,1,2라 하자. 그리고 시점 $t$에서 상태가 $s_t$일 때 3개의 action들 중 0번 action을 $a_t$로써 정해서 reward $r_{t+1}$을 얻은 후 다음 상태 $s_{t+1}$로 전이되었다고 하자.</p>

<p>그러면 현재의 추정량들 $Q(s_t,0)$, $Q(s_{t+1},0)$, $Q(s_{t+1},1)$, $Q(s_{t+1},2)$를 사용해서, 추정량 $Q(s_t,0)$를 업데이트할 수 있다. 이를 시점 $t, t+1, \cdots$ 에 대해 계속 반복한다.</p>

<p><br /></p>

<h2 id="현재의-action-결정-exploration-exploitation">현재의 action 결정: Exploration/ Exploitation</h2>

<p>위에서 $q_{\pi}(s_t,a_t)$를 설명할 때, 시점 $t+1$부터는 policy $\pi$를 따라 action들 $a_{t+1}, a_{t+2}, \cdots$를 결정하되, 시점 $t$에서는 $\pi$에 관계없이 action $a_t$를 결정한다고 했다.</p>

<p>그러면, $a_t$는 어떻게 결정해야 하는가?</p>

<p>가장 직관적인 방법은, 시점 $t$의 state가 $s_t$로 주어졌을 때 $Q(s_t,a_t)$를 최대화하는 action으로 결정하는 것이다. 이러한 $a_t$ 결정 규칙을 ‘greedy’ policy라 한다.</p>

<p>그러나 greedy policy는 controller 훈련을 끝낸 후 ‘validation 및 실제 구동 시’에 적용해야지, ‘훈련 중’에 적용하는 것은 적절하지 않다.</p>

<p>학습 초기에 아직 아무 정보도 학습하지 못했는데 단순히 $Q$ 값이 가장 큰 action만을 계속 하는 것은, 마치 평균적 보상이 다른 여러 개의 슬롯머신을 눈 앞에 두고도, 처음에 고른 몇 개의 슬롯머신 중 좋아 보이는 것만 계속 누르는 것과 비슷하다.</p>

<p>누적 보상을 최대화하려면 어떤 슬롯머신이 가장 (평균적으로) 큰 보상을 주는지 확인하는 절차가 먼저 필요하며, 이를 위해 초반에는 여러 슬롯머신들을 돌아가면서 눌러봐야 한다. 강화학습에서는 이를 exploration(탐색)이라 한다.</p>

<p>탐색을 통해 어떤 슬롯머신이 보상을 많이 주는지 감이 잡히면 그때부터 보상을 많이 주는 슬롯머신을 계속 누르면 되며, 이를 exploitation이라 한다. Q-learning에서 greedy policy는 exploitation’만’ 하는 것에 해당한다.</p>

<p>훈련 시에는 (특히 초반에는) exploration을 겸해서 해 줘야 더 좋은 action을 판별할 가능성이 열린다. 그러므로 시점 $t$에서 $a_t$를 결정할 때, 보통 주어진 값 $\epsilon$만큼의 확률로 $a_t$를 $Q(s_t,a_t)$ 값에 상관없이 random하게 결정한다 (exploration). 그리고 $1-\epsilon$의 확률로 $Q(s_t,a_t)$ 값이 최대가 되는 $a_t$를 결정한다 (exploitation).</p>

<p>이렇게 exploration과 exploitation 간 balance를 갖춘 $a_t$ 결정 규칙을  $\epsilon$-greedy policy라 한다. ($\epsilon$는 훈련 내내 고정되어야 하는 것은 아니며, 훈련 초기에는 크게 하고 훈련이 진행될수록 줄여서 적용할 수도 있다.)</p>

<p>(Exploration/ exploitation에 대해 제대로 이해하고 싶으면, Sutton의 책 2장의 ‘Multi-armed Bandits’를 공부하기 바란다)</p>

<p><br /></p>

<h2 id="state-action-pair-수가-매우-많은-경우-q-value-근사를-위한-딥러닝-사용">State-action pair 수가 매우 많은 경우: Q-value 근사를 위한 딥러닝 사용</h2>
<p>지금까지 설명한 방법은, state-action pair의 수가 많지 않을 경우 각 state-action pair별 $Q$값들을 담는 table을 만들어 그대로 적용할 수 있다.</p>

<p>이를테면 아래와 같은 공간에서 상하좌우로 한 칸씩 이동 가능한 환경에서 최단거리를 찾는 문제 (Gridworld) 에서는, 격자 수가 한정되어 있으므로 각 격자(state)-이동방향(action) pair 별로 $Q$값들을 따로 계산할 수 있다.</p>

<p><img src="/assets/images/reinforcetwo/gridworld.png" alt="gridworld" class="align-center" />
<em>Gridworld 환경. 칸이 38개이고 action은 상하좌우 4개이므로, state-action pair 총 152개 각각에 대해 Q-value를 추정할 수 있다.</em></p>

<p>하지만 많은 경우 state가 continuous이거나, discrete라도 그 수가 매우 많다.</p>

<p>잘 알려진 cartpole 문제의 경우, action은 ‘수레를 정해진 힘으로 왼쪽으로 가속/ 오른쪽으로 가속’ 딱 두 개의 값 중 하나를 가지는 이진수로 볼 수 있으나, state는 ‘수레의 위치와 속도, 막대의 각도와 각속도’로 4차원의 연속된 벡터로 볼 수 있다. 연속변수이므로, state의 수가 ‘무한대’이다. 그러므로, 각 state-action pair에 대해 table 방식으로 $Q$값들을 따로 계산할 수는 없다.</p>

<p><img src="/assets/images/reinforcetwo/cart_pole.gif" alt="cart_pole" class="align-center" width="70%" />
<em>Cartpole 환경. State 수가 무한하므로, 각 state-action pair에 대해 Q-value를 정의할 수 없다.</em></p>

<p>Vincent의 마이크로그리드 케이스에서도 마찬가지이다. State (직전 $N$시간 동안의 시간별 부하와 태양광 발전량, 그리고 배터리에 저장된 에너지)가 $2N+1$차원의 continuous vector이기 때문이다.</p>

<p>이런 경우 ‘모든 state-action pair 각각에 대해’ $Q$를 계산한다는 것은 사실상 불가능하다. 그렇다면 어떻게 해야 하나?</p>

<p><br />
만약 state-action pair와 Q값 간의 관계가 어떤 domain knowledge에 의해 명확하게 정의될 수 있다면, 해당 관계를 명확한 수식으로 표현하여 $Q$를 쉽게 계산할 수 있을 것이다.</p>

<p>그러나 이 케이스를 포함한 많은 경우, state-action과 $Q$값 간의 관계식을 명확한 수식으로 나타낼 수 있을 것이라 기대되지 않는다.</p>

<p><br />
그렇다면, state $s_t$를 입력으로 받고 각 action 별 $Q(s_t,a_t)$ 값들을 출력으로 하는 심층신경망 (Deep Neural Network, DNN) 모델을 훈련하는 것이 현실적인 방법이다.</p>

<p>심층신경망은 계산비용은 매우 높지만, node 수가 충분하면 어떤 비선형 함수도 근사할 수 있기 때문에 nonlinear function approximator로 기능한다는 점을 이용하는 것이다.</p>

<p><img src="/assets/images/reinforcetwo/reinforcement_deep.png" alt="reinforcement_deep" class="align-center" width="80%" />
<em>‘심층’강화학습 개요. Action 결정이 심층신경망에 기반해 이루어짐.</em></p>

<p>이 심층신경망 모델은 매 훈련 주기마다 tuple $(s_{t},a_{t},s_{t+1},r_{t+1})$ 의 batch를 받아서 업데이트된다. 이 때 훈련 주기는 1 time step보다 길 수 있으며, batch라 함은 여러 시점들의 tuple들을 한꺼번에 훈련에 사용함을 의미한다.</p>

<p>업데이트 시 최소화 대상 목적함수는 $Q(s_{t},a_{t})$와 $r_{t+1} + \gamma \text{max}_{a_{t+1}} Q(s_{t+1},a_{t+1})$ 간 차이의 평균제곱이다. Gradient descent 기반으로 심층신경망의 가중치를 수정해감에 따라, $Q(s_{t},a_{t})$가 $q_{\ast}(s_{t},a_{t})$에 가까워질 것이라 기대할 수 있다.</p>

<p>이를 Deep Q-Network (DQN) 이라 한다. (위 cartpole 문제도 DQN으로 푼다)</p>

<p><br />
다음 포스팅에서는 마이크로그리드 문제에 Deep Q-Network를 적용하는 과정과 결과에 대해 상세히 설명한다.</p>

<div class="notice--info">

강화학습 기반 마이크로그리드 control<br /><br />

1) <a href="/reinforceone.html">문제의식 및 케이스 소개</a><br />
2) <b>Q-learning 개념</b><br />
3) <a href="/reinforcethree.html">Deep Q-Network를 통한 discrete control 도출</a><br />
4) <a href="/reinforcefour.html">DDPG를 통한 continuous control 도출</a><br />
5) <a href="/reinforcefive.html">TD3, SAC를 통한 continuous control 도출</a>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="energymanagement" /><category term="강화학습" /><summary type="html"><![CDATA[지난 포스팅에서, Vincent의 태양광 기반 마이크로그리드의 누적 비용을 최소화하는 최적 control 문제를 소개했다. 또한 이를 선형계획법으로 풀 경우 ‘미래의 태양광 발전량과 부하를 안다’라는, ‘비현실적’인 가정 하의 control을 도출함을 보였다.]]></summary></entry><entry><title type="html">로지스틱 회귀에서의 over-confidence에 대한 이해</title><link href="https://song4energyndata.github.io/overconfidence.html" rel="alternate" type="text/html" title="로지스틱 회귀에서의 over-confidence에 대한 이해" /><published>2023-05-28T00:00:00+09:00</published><updated>2023-05-28T00:00:00+09:00</updated><id>https://song4energyndata.github.io/overconfidence</id><content type="html" xml:base="https://song4energyndata.github.io/overconfidence.html"><![CDATA[<p>Logistic regression에서는 각 point 별로 response $y$가 0과 1 중 1일 확률 추정값 $\hat{y}$를 제공한다 (물론 실제 $y$값들은 알려져 있다). 한편, feature space에서 response가 1인 point들과 0인 point들이 완전히 linearly separable하면 (즉 $\hat{y}=0.5$를 기준으로 misclassified point가 하나도 없으면), logistic regression 추정이 되지 않음이 잘 알려져 있다.</p>

<h2 id="over-confidence란">Over-confidence란</h2>
<p>Feature space에서 response가 1인 point들과 0인 point들이 ‘거의’ linearly separable인 경우 (즉 $\hat{y}=0.5$를 기준으로 misclassified point들이 ‘거의’ 없는 경우) 에도 문제가 발생한다. 이 경우 계수추정량들의 magnitude가 매우 커지고, 그 결과 추정값들이 모든 경우에 대해 1 또는 0에 아주 가까워진다. 이를 어느 class에 속할지에 대해 지나치게 확신한다고 해서, over-confidence라 한다.</p>

<p>Toy problem을 예시로 들면, 아래와 같은 두 class의 point들을 분류하는 plane을 ($\hat{y}=0.5$를 기준으로) logistic regression으로 찾는다고 하자.</p>

<p><img src="/assets/images/overconfidence/overconfidence.png" alt="overconfidence" class="align-center" />
<em>두 class의 point들을 분류하는 plane을 찾는 문제, 각 경우에 대해 misclassified point 개수가 다름.</em></p>

<p>Plane을 $\beta_1 x_1 + \beta_2 x_2 + \beta_0 = 0$ 이라 할 때, 기울기가 -1이고 원점을 지나는 직선일 것이므로 $\beta_1 \approx \beta_2$,$\beta_0 \approx 0$임은 자명하다. 각 경우에 대해 $\beta_1$의 계수추정량들 및 계수추정량의 $t$-value들을 구하면 아래와 같다.</p>

<p>1) Many misclassifications: $\hat{\beta_1} = 8.85$, $t$-value는 $18.4$ <br /><br />
2) A few misclassifications: $\hat{\beta_1} = 29.6$, $t$-value는 $13.8$ <br /><br />
3) Perfect separation: $\hat{\beta_1} = 9,824$, $t$-value는 $0.8$ <br /></p>

<p>Misclassified point의 비중이 적을수록 계수추정량의 magnitude는 커지고, $t$-value는 작아진다. Python에서는 perfectly separable case에 대해서도 결과를 제공하기는 하는데, t-value를 보면 계수의 값에 별 의미는 없는 것으로 보인다.</p>

<p><br /></p>
<h2 id="over-confidence가-발생하는-이유">Over-confidence가 발생하는 이유</h2>

<p>Over-confidence에 대해 아주 엄밀한 설명은 아직 만나보지 못했지만, 필자가 간단히 수학적으로/ 직관적으로 생각해 본 바는 아래와 같다.</p>

<p>먼저 수학적으로는 다음과 같다.</p>

<p>로지스틱 회귀에서의 cost function은 ‘negative’ log-likelihood $-\sum_{i=1}^{N}[y_{i} \text{log}\hat{y}_{i} + (1-y_{i})\text{log}(1-\hat{y}_{i})]$ 이고 $ y_{i} \in \lbrace 0,1 \rbrace$이며 $0 \leq \hat{y}_{i}\leq 1$이다.</p>

<p>그러므로 실제 response가 1인 점을 기준으로, 추정값이 1에서 멀어지고 0으로 가까워질수록 penalty가 exponential하게 증가한다. 이는 실제 response가 0인데 추정값이 1에 가까워질 경우에도 마찬가지이다.</p>

<p>이 때 $\hat{y}=0.5$ 기준으로 misclassified point가 여럿 있는 경우에는, 해당 point들 때문에 생기는 exponential penalty를 줄이기 위해 추정값들이 1 또는 0에 너무 가까워지지 않도록 계수의 magnitude를 작게 설정해야 한다.</p>

<p>그러나 계수의 magnitude를 작게 할수록, 실제 값이 1이고 추정값이 1에 가까운 경우에도 완전히 1에 매우 가깝기보다는 1보다 어느 정도는 작은 값이 될 것이다. 실제 값이 0이고 추정값이 0인 경우에도 0보다 어느 정도는 큰 값이 될 것이다. 이 차이 또한 작게나마 penalty로 계산된다.</p>

<p>misclassified point가 매우 조금밖에 없을 경우에는, misclassified point의 penalty가 아무리 exponential하게 증가한다고 해도 그 숫자 자체가 매우 적기 때문에, 올바르게 분류된 point들에 대한 $\hat{y}$가 1 또는 0에 매우 가까워지도록 계수의 magnitude를 크게 설정하는 것이 total penalty를 더 작게 만드는 선택일 수 있는 것이다.</p>

<p><br />
다음으로 직관적으로는 아래와 같다.</p>

<p>Misclassified point가 여럿 있는 경우에는, boundary 근처 point들에 대해 이 분류가 맞다는 확신을 가지기가 어려울 것이다 (말 그대로 misclassification이 많으니까). 그래서 확률 추정값을 0.5에 가깝게 주는 것이 자연스럽다.</p>

<p>그러나 misclassified point가 거의 없는 경우에는, 분류가 잘 되니 boundary 근처 point들에 대해서도 보다 더 확신을 가질 것이다. 그러므로 확률 추정값도 0 또는 1에 가깝게 준다고 보는 것이 자연스럽다.</p>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="mathstat" /><category term="회귀분석" /><summary type="html"><![CDATA[Logistic regression에서는 각 point 별로 response $y$가 0과 1 중 1일 확률 추정값 $\hat{y}$를 제공한다 (물론 실제 $y$값들은 알려져 있다). 한편, feature space에서 response가 1인 point들과 0인 point들이 완전히 linearly separable하면 (즉 $\hat{y}=0.5$를 기준으로 misclassified point가 하나도 없으면), logistic regression 추정이 되지 않음이 잘 알려져 있다.]]></summary></entry><entry><title type="html">강화학습 기반 마이크로그리드 control - 1) 문제의식 및 케이스 소개</title><link href="https://song4energyndata.github.io/reinforceone.html" rel="alternate" type="text/html" title="강화학습 기반 마이크로그리드 control - 1) 문제의식 및 케이스 소개" /><published>2023-05-21T00:00:00+09:00</published><updated>2023-05-21T00:00:00+09:00</updated><id>https://song4energyndata.github.io/reinforceone</id><content type="html" xml:base="https://song4energyndata.github.io/reinforceone.html"><![CDATA[<p>재생 발전의 비중이 커질수록, 당장 몇 시간 뒤의 발전량 및 순 부하 (재생발전량을 제한 net power load) 예측조차도 어려워진다. 이런 상황에서 과거 데이터들을 잘 이용해서 ‘경제적으로’ 전력을 공급하도록 설비들을 control하는 것이, ‘스마트’그리드의 중요한 과제이다.</p>

<p><img src="/assets/images/reinforceone/renewableuncertainty.png" alt="renewableuncertainty" class="align-center" width="80%" />
<em>풍력발전 예측 시의 신뢰구간이 큼. 즉, 재생발전 비중이 높으면 발전량의 단기적 예측도 어려움.<br />(출처: http://www.ningzhang.net/Renewables.html)</em></p>

<p><br /></p>

<h2 id="선형계획법의-한계-미래를-안다고-가정-비현실적">선형계획법의 한계: 미래를 안다고 가정 (비현실적)</h2>

<p>이 블로그의 ‘Optimal System’ 카테고리에, 필자가 선형계획법 기반의 최적 에너지시스템 구성 및 스케줄링 도출을 설명했으며 해당 내용에는 <a href="https://song4energyndata.github.io/linprogfive.html">태양광/ 풍력 등 재생발전 비중이 높은 시스템 대상 분석</a>도 포함되어 있다.</p>

<p>그런데 선형계획법 기반 에너지시스템 스케줄링에서는, ‘미래’의 발전량과 부하를 ‘정확히 알 경우의’ control을 도출한다는 한계점이 있다 (실제로는 미래를 정확히 알 수 없음에도).</p>

<p>최적화 문제의 변수들이 각 시간별 수전/ 충전/ 방전 등이라 할 때, 해당 문제의 제약조건들로 ‘모든 시간에 대한’ 에너지 밸런스 제약이 포함된 상태에서 최적화를 수행하기 때문이다.</p>

<p><br />
예시를 하나 들자. Vincent의 Liege 대학 박사학위논문 <a href="https://orbi.uliege.be/handle/2268/214216">‘Contributions to deep reinforcement learning and its applications in smartgrids’</a> 에서 연구대상으로 삼은 가상의 마이크로그리드 시스템은 아래와 같다.</p>

<p>최대부하 2kW 수준의 전기부하가 있으며, 이 부하에 전력을 공급하는 수단으로는 정격출력 12kW급 태양광 패널, 실용량 15kWh급 배터리 (충방전 효율은 80%), 그리고 부하에 연결된 수소연료전지 기반 중앙 계통이 있다.</p>

<p><img src="/assets/images/reinforceone/system.png" alt="system" class="align-center" />
<em>Vincent의 연구에서 가정된 마이크로그리드.</em></p>

<p>태양광 발전량이 부족할 경우 중앙 수소연료전지 시스템으로부터 전기를 받을 수 있다(수전). 또는 태양광 발전량이 수요를 초과할 경우 전기를 역송해서 중앙 수소연료전지 시스템이 그린수소를 생산하도록 할 수 있다.</p>

<p>이 문제에서는 특이하게도, 계통 사이에 오갈 수 있는 전력이 1.1kW로 제한되어 있다 (개인적으로 일반적인 case는 아니라는 생각이 들지만… 일단 받아들이자).</p>

<p>이때 계통으로부터 전력을 받는 데 드는 비용은 해당 전기에너지 생산에 필요한 양만큼의 수소의 가격, 계통으로 잉여전력을 보낼 때의 수익은 해당 전기에너지로 만들 수 있는 양만큼의 수소의 가격이다.</p>

<p>이 논문의 가정에서는 수소 에너지 기준으로 1kWh 당 0.1유로이며 수소-전기 간 변환효율은 65%이므로, 보낼 때의 수익은 약 0.065유로/kWh, 받을 때의 비용은 약 0.154유로/kWh이다. 즉 역송 시의 수익이 수전 시의 비용보다 더 적다.</p>

<p>만약 태양광발전이 없고 배터리도 완방되어 있고 계통으로부터 1.1kW를 수전받음에도 부하를 충당하지 못할 경우, loss of load에 대한 큰 penalty성 비용 2.0유로/kWh가 발생한다 (부하 공급 실패에 대한 penalty를 큰 비용으로 환산함).</p>

<p>그러므로 특정 시간에 잉여전력이 많더라도, 이를 전부 송전해서 수소 가격만큼의 수익을 내려다가 나중에 태양광 발전량이 부족해지면 큰 손실을 볼 수 있다. 그러므로 배터리 내 에너지 저장량을 ‘적절히’ 유지해야 한다.</p>

<p>만약 잉여 태양광전력이 너무 많아서 배터리 완충 + 계통으로 1.1kW 송전 시에도 전력이 남으면, 이는 curtail(출력제한)된다. 출력제한은 전기를 버리는 것이므로, 수익을 내지 않는다.</p>

<p><br />
시간 인덱스가 $t \in  \lbrace 1, 2, …, T \rbrace$ 일 때, 모든 시간의 비용의 합을 최소화하는 계통으로부터의 수전/송전, 에너지저장장치의 충전/방전량을 결정하고자 한다. 최적화 문제는 아래와 같다.</p>

<p>Minimize $ \sum_{t=1}^{T} 0.154 p_{\text{import}}[t] - \sum_{t=1}^{T} 0.065 p_{\text{export}}[t] + \sum_{t=1}^{T} 2 p_{\text{loss}}[t] $</p>

<p>Subject to</p>

<p>$ p_{\text{load}}[t] = p_{\text{pv}}[t] + p_{\text{import}}[t] - p_{\text{export}}[t] + p_{\text{disch}}[t] - p_{ch}[t] + p_{\text{loss}}[t] - p_{\text{curtail}}[t]  \quad \forall t$</p>

<p>$ e_{\text{batt}}[t] = e_{\text{batt}}[t-1] + 0.8 p_{\text{ch}}[t] - p_{\text{disch}}/0.8 \quad \forall t,\,\, e_{\text{batt}}[0]=0  $</p>

<p>$ p_{\text{import}}[t] \leq 1.1, \,\, p_{\text{export}}[t] \leq 1.1 \quad \forall t$</p>

<p>위에서 load는 부하, pv는 태양광, import는 계통으로부터의 수전, export는 계통으로의 송전, disch는 배터리 방전, ch는 배터리 충전, loss는 전력 부족 시 loss of load, curtail은 전력 초과 시 출력제한, batt는 배터리이다. $p$는 전력, $e$는 저장된 에너지, $\mu$는 효율이다. $p_{\text{load}}[t]$와 $p_{\text{pv}}[t]$는 input data로써 주어져 있고, 나머지 nonnegative 변수들의 값을 결정한다.</p>

<p>(참고로 보통은 battery의 c-rate까지 고려해야 하지만, Vincent의 논문에서는 배터리가 순간적인 발전량 전부를 유입시킬 수 있다고 가정했으므로 c-rate는 고려하지 않았다.)</p>

<p>위 선형계획 문제를 Python에서 cvxopt 패키지와 glpk solver로 구성하고 푸는 코드는 아래와 같다. (<a href="https://github.com/song4energyndata/Codes/tree/main/linearprogramming/microgrid_Vincent">GitHub Repo 링크</a>)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">cvxopt</span> <span class="kn">import</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">spmatrix</span><span class="p">,</span> <span class="n">sparse</span><span class="p">,</span> <span class="n">glpk</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="n">load_peak</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">pv_peak</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">eff_h2</span> <span class="o">=</span> <span class="mf">0.65</span> <span class="c1"># 수소-전기 변환효율
</span>
<span class="n">capa_batt</span> <span class="o">=</span> <span class="mi">15</span> <span class="c1"># 배터리 용량 (겉보기용량이 아닌, SOC 상하한 고려한 실용량이라 가정)
</span><span class="n">eff_batt</span> <span class="o">=</span> <span class="mf">0.9</span> <span class="c1"># 배터리 충방전 효율
</span><span class="n">initialenergy_batt</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="n">price_h2</span> <span class="o">=</span> <span class="mf">0.1</span> <span class="c1"># 수소에너지의 가격 (Euro/kWh)
</span><span class="n">cost_loss</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># loss of load penalty (Euro/kWh)
</span><span class="n">maxrate_h2</span> <span class="o">=</span> <span class="mf">1.1</span> <span class="c1"># 계통으로부터의 송전/ 계통으로의 수전 의 상한 (kW)
</span>

<span class="n">data_load</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"load_test.txt"</span><span class="p">)</span>
<span class="n">data_pv</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"pv_test.txt"</span><span class="p">)</span>
<span class="n">p_load</span> <span class="o">=</span> <span class="n">data_load</span><span class="p">[</span><span class="mi">24</span><span class="p">:]</span> <span class="o">*</span> <span class="n">load_peak</span>
<span class="n">p_pv</span> <span class="o">=</span> <span class="n">data_pv</span><span class="p">[</span><span class="mi">24</span><span class="p">:]</span> <span class="o">*</span> <span class="n">pv_peak</span>
<span class="n">t</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">p_load</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">block_eye</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">spmatrix</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nf">range</span><span class="p">(</span><span class="n">size</span><span class="p">),</span><span class="nf">range</span><span class="p">(</span><span class="n">size</span><span class="p">))</span> 

<span class="k">def</span> <span class="nf">block_zeros</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sparse</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">))))</span>

<span class="k">def</span> <span class="nf">block_ones</span><span class="p">(</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sparse</span><span class="p">(</span><span class="nf">matrix</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">))))</span>

<span class="k">def</span> <span class="nf">block_batt</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sparse</span><span class="p">([[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="mi">1</span><span class="p">)],[</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">size</span><span class="p">)]])</span> <span class="o">-</span> <span class="nf">sparse</span><span class="p">([[</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">size</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="mi">1</span><span class="p">)]])</span>


<span class="n">Aeq_balance</span> <span class="o">=</span> <span class="nf">sparse</span><span class="p">([[</span><span class="o">-</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)],</span> <span class="p">[</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)],</span> <span class="p">[</span><span class="o">-</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)],</span> <span class="p">[</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)],</span> <span class="p">[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)],</span> <span class="p">[</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)],</span> <span class="p">[</span><span class="o">-</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)]])</span> <span class="c1"># 변수 순서: 송전, 수전, 충전, 방전, 배터리내에너지, loss of load, curtailment
</span><span class="n">beq_balance</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">(</span><span class="n">p_load</span><span class="o">-</span><span class="n">p_pv</span><span class="p">,</span><span class="n">tc</span><span class="o">=</span><span class="s">'d'</span><span class="p">)</span>

<span class="n">Aeq_batterydynamic</span> <span class="o">=</span> <span class="nf">sparse</span><span class="p">([[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="o">-</span><span class="n">eff_batt</span><span class="o">*</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_eye</span><span class="p">(</span><span class="n">t</span><span class="p">)</span><span class="o">/</span><span class="n">eff_batt</span><span class="p">],[</span><span class="nf">block_batt</span><span class="p">(</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">t</span><span class="p">)]])</span>
<span class="n">beq_batterydynamic</span> <span class="o">=</span> <span class="nf">block_zeros</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">lowerbounds</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">([[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">matrix</span><span class="p">([</span><span class="n">initialenergy_batt</span><span class="p">])],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)]])</span> 
<span class="n">upperbounds</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">([[</span><span class="n">maxrate_h2</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="n">maxrate_h2</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">matrix</span><span class="p">([</span><span class="n">initialenergy_batt</span><span class="p">])],[</span><span class="n">capa_batt</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="n">np</span><span class="p">.</span><span class="n">inf</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)]])</span> 

<span class="n">A_lowerbound</span> <span class="o">=</span> <span class="o">-</span><span class="nf">block_eye</span><span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">b_lowerbound</span> <span class="o">=</span> <span class="o">-</span><span class="n">lowerbounds</span><span class="p">.</span><span class="n">T</span>

<span class="n">A_upperbound</span> <span class="o">=</span> <span class="nf">block_eye</span><span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">b_upperbound</span> <span class="o">=</span> <span class="n">upperbounds</span><span class="p">.</span><span class="n">T</span>

<span class="n">c</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">([[</span><span class="n">price_h2</span><span class="o">*</span><span class="n">eff_h2</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="o">-</span><span class="n">price_h2</span><span class="o">/</span><span class="n">eff_h2</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)],[</span><span class="o">-</span><span class="n">cost_loss</span><span class="o">*</span><span class="nf">block_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)],[</span><span class="nf">block_zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">t</span><span class="p">)]])</span>

<span class="n">Aeq</span> <span class="o">=</span> <span class="nf">sparse</span><span class="p">([</span><span class="n">Aeq_balance</span><span class="p">,</span><span class="n">Aeq_batterydynamic</span><span class="p">])</span>
<span class="n">beq</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">([</span><span class="n">beq_balance</span><span class="p">,</span><span class="n">beq_batterydynamic</span><span class="p">])</span>

<span class="n">A</span> <span class="o">=</span> <span class="nf">sparse</span><span class="p">([</span><span class="n">A_lowerbound</span><span class="p">,</span> <span class="n">A_upperbound</span><span class="p">])</span>
<span class="n">b</span> <span class="o">=</span> <span class="nf">matrix</span><span class="p">([</span><span class="n">b_lowerbound</span><span class="p">,</span> <span class="n">b_upperbound</span><span class="p">])</span>


<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">x</span><span class="o">=</span><span class="n">glpk</span><span class="p">.</span><span class="nf">lp</span><span class="p">(</span><span class="o">-</span><span class="n">c</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">Aeq</span><span class="p">,</span><span class="n">beq</span><span class="p">,</span><span class="n">options</span><span class="o">=</span><span class="p">{</span> <span class="s">'msg_lev'</span><span class="p">:</span> <span class="s">'GLP_MSG_ON'</span><span class="p">})</span> <span class="c1"># c는 수익 관점의 벡터임, 그러므로 수익의 최'대'화를 위해 '마이너스' c를 입력
</span><span class="n">elapsed_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

<span class="n">profit</span> <span class="o">=</span> <span class="p">(</span><span class="n">c</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="n">profit</span><span class="p">)</span>
</code></pre></div></div>

<p>특정 1년의 1월 2일~12월 31일에 대해 최적화 수행 시, 비용은 -50유로, 즉 누적해서 50유로의 수익을 낸다 (이는 다음 포스팅에서부터 소개할 강화학습에 대한 validation case이며, 왜 1월 2일부터인지는 다음 포스팅에서 설명한다).</p>

<p>여기서 $t=1$일 때의 $p_{\text{export}}[1]$와 $p_{\text{import}}[1]$을 결정하는 데 쓰이는 정보는, $p_{\text{pv}}[1], p_{\text{pv}}[2], \cdots, p_{\text{pv}}[T]$ 즉 모든 시간의 태양광 발전량 값들 및 $p_{\text{load}}[1], p_{\text{load}}[2], \cdots, p_{\text{load}}[T]$ 즉 모든 시간의 부하 값들이다. 즉 ‘미래를 정확히 알 때의’ control이다.</p>

<p>그러나 이는 비현실적인 가정이다. 현실 세계에서는 시점 $k$의 $p_{\text{export}}[k]$와 $p_{\text{import}}[k]$를 결정하는 데 실제로 쓰일 수 있는 정보가, 과거의 정보 $p_{\text{pv}}[1], \cdots, p_{\text{pv}}[k-1], p_{\text{load}}[1], \cdots, p_{\text{load}}[k-1]$로 한정된다.</p>

<p><br />
이를 보완하기 위한 방법으로, 시점 $k$ 기준으로 시점 $k+1, k+2, \cdots, k+N$ ($N$은 24~168 즉 하루~일주일 정도의 비교적 짧은 기간) 까지에 대한 ‘작은 문제’를 풀어 해를 얻고, 그 해에서 시점 $k$의 control만 취하는 과정을 반복하는 ‘rolling horizon’ 방법이 있다.</p>

<p><img src="/assets/images/reinforceone/rolling.png" alt="rolling" class="align-center" width="70%" />
<em>Rolling horizon 기반 control. 가까운 미래에 대한 예측 기반으로 현재의 control을 결정.<br />출처: <a href="https://doi.org/10.1016/j.apenergy.2015.05.090">Silvente et al. (2015)</a></em></p>

<p>그러나 이는 두 가지 한계점이 있다.</p>

<p>첫째, 이를 현실에서 사용하려면 단기라도 어쨌거나 미래 $N$시간 동안의 발전량과 부하 ‘예측’이 필요하다는 것이다. 재생발전 비중이 증가할수록 이에 대한 예측이 실제로부터 벗어나기 쉽다는 것은 이미 본문의 맨 위에서 언급했다.</p>

<p>둘째, 해당 control은 현재 및 $N$시간 뒤까지 발생하는 비용의 합만을 최소화하지, 그보다 더 미래까지의 ‘누적비용’은 고려하지 않는다.</p>

<p><br /></p>

<h2 id="강화학습을-쓴다면">강화학습을 쓴다면?</h2>

<p>그러면 어떻게 해야 ‘예측 없이 과거 정보만으로’, ‘먼 미래까지의 누적비용을 고려한’ 경제적 control을 도출할 수 있을까?</p>

<p>‘강화학습’ (Reinforcement Learning) 이라는 말을 들어봤을 것이다 (아마 AlphaGo의 학습 원리 등으로).</p>

<p>강화학습은, 주어진 환경에서 특정 상태(state)에 처했을 때 할 수 있는 행동(action)들 중 특정 행동을 함으로써 얻는 보상(reward), 특히 당장의 보상 뿐 아니라 중/장기적 관점에서 미래 보상의 ‘누적 합(return)’의 기대값을 최대화할 수 있도록, 상태 별 행동을 정하는 규칙 (policy) 을 도출하는 기계학습 방법이다.</p>

<p><img src="/assets/images/reinforceone/reinforcement_basic.png" alt="reinforcement_basic" class="align-center" width="70%" />
<em>강화학습 개요. State $S_t$에서 Action $A_t$를 취하면 Reward $R_{t+1}$을 얻으면서 State $S_{t+1}$로 전이됨.</em></p>

<p>Vincent의 마이크로그리드 문제에서 state를 특정 N시간 ‘전’까지의 부하와 태양광 발전량, action을 현재 시간에서의 수전/송전으로 두면, 강화학습을 적용해 controller를 훈련시킬 수 있다.</p>

<p>물론 이 controller를 사용할 경우의 누적 비용은, (미래를 다 안다고 가정해서 얻은) 선형계획법 결과 기반 control 시의 비용보다는 클 것이다. 그렇지만 적어도 random control보다는 훨씬 나은 성과를 낼 수 있을 것이다.</p>

<p>실제로 해당 학위논문의 에너지시스템 사례에 대해 수전을 플러스, 송전을 마이너스라 할 때 [-1.1,+1.1] 구간에 대한 uniform distribution을 가정해 all random으로 control을 한다면, validation case에서 누적 비용은 대략 2500~2700유로 정도이다. 그러나 강화학습으로 훈련시킨 controller를 쓰면 27유로로, LP 결과인 -50유로에 상당히 근접한 economic control이 된다.</p>

<p>다음 편부터는 강화학습 개념, 그리고 Vincent의 마이크로그리드 문제에 강화학습을 적용하는 방법 및 결과를 소개한다.</p>

<div class="notice--info">

강화학습 기반 마이크로그리드 control<br /><br />

1) <b>문제의식 및 케이스 소개</b><br />
2) <a href="/reinforcetwo.html">Q-learning 개념</a><br />
3) <a href="/reinforcethree.html">Deep Q-Network를 통한 discrete control 도출</a><br />
4) <a href="/reinforcefour.html">DDPG를 통한 continuous control 도출</a><br />
5) <a href="/reinforcefive.html">TD3, SAC를 통한 continuous control 도출</a>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="energymanagement" /><category term="선형계획법" /><category term="부하패턴" /><category term="경제성분석" /><category term="강화학습" /><category term="녹색섬" /><category term="Python" /><summary type="html"><![CDATA[재생 발전의 비중이 커질수록, 당장 몇 시간 뒤의 발전량 및 순 부하 (재생발전량을 제한 net power load) 예측조차도 어려워진다. 이런 상황에서 과거 데이터들을 잘 이용해서 ‘경제적으로’ 전력을 공급하도록 설비들을 control하는 것이, ‘스마트’그리드의 중요한 과제이다.]]></summary></entry><entry><title type="html">건물의 시간별 전기부하 학습 후 예측하기 - 딥러닝을 쓴다면?</title><link href="https://song4energyndata.github.io/predictiontwo.html" rel="alternate" type="text/html" title="건물의 시간별 전기부하 학습 후 예측하기 - 딥러닝을 쓴다면?" /><published>2023-04-16T00:00:00+09:00</published><updated>2023-04-16T00:00:00+09:00</updated><id>https://song4energyndata.github.io/predictiontwo</id><content type="html" xml:base="https://song4energyndata.github.io/predictiontwo.html"><![CDATA[<p>지난 포스팅에서는 건물의 시간별 전기부하 추정 모델을 딥러닝이 아닌 ‘전통적인’ 선형회귀 (Weighted Least squares + 잔차에 대한 SARMA) 로 만들어 adjusted $R^2$ 0.95 이상의 우수한 성능을 얻을 수 있음을 보였다.</p>

<p>이번 포스팅에서는, 딥러닝을 써서 모델을 만들어 본다.</p>

<p><br /></p>

<h2 id="dense-neural-net">Dense Neural Net</h2>

<p>전기부하 데이터는 시계열 데이터이므로 Recurrent Neural Network (RNN) 을 쓸 수 있으나, 먼저 단순한 Dense Neural Network (DNN) 을 사용해 보자.</p>

<p>이 경우 지난 포스팅의 선형회귀와 제대로 비교하기 위해서는, 선형회귀에서처럼 유형별 sub모델 4개를 만들고 predictor들도 이차항과 교차항을 제외하면 선형회귀에서와 똑같이 두어야 한다.</p>

<p>(단, 이차항과 교차항은 빼도 된다. NN이 제대로 적합된다면 기온/조도와 전기부하 간의 적절한 nonlinear function을 찾아줄 것이므로.)</p>

<p>여기서는 DNN은 2개의 Dense layer로 이루어져 있고 첫 layer의 node는 20개, 두 번째 layer의 node는 10개로 둔다. 훈련 epoch 수는 1000이고, optimizer는 특별한 이슈가 없으므로 가장 일반적인 Adam을 쓴다.</p>

<p>구체적인 코드는 아래와 같다 (전기부하 데이터를 최대값이 1 이하가 되게 scaling하였음에 주의한다. Scaling하지 않으면 적합 결과가 상수함수가 되어 전혀 추정을 하지 못한다).<br />(<a href="https://github.com/song4energyndata/Codes/tree/main/deeplearning/loadprediction">GitHub Repo 링크</a>)</p>

<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="n">workday_springfall_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"I_train.txt"</span><span class="p">)</span>
<span class="n">workday_summer_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"II_train.txt"</span><span class="p">)</span>
<span class="n">workday_winter_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"III_train.txt"</span><span class="p">)</span>
<span class="n">holiday_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"IV_train.txt"</span><span class="p">)</span>

<span class="n">workday_springfall_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"I_test.txt"</span><span class="p">)</span>
<span class="n">workday_summer_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"II_test.txt"</span><span class="p">)</span>
<span class="n">workday_winter_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"III_test.txt"</span><span class="p">)</span>
<span class="n">holiday_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"IV_test.txt"</span><span class="p">)</span>

<span class="n">actualpower</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"actualusage.txt"</span><span class="p">)</span>

<span class="n">n_node_firstlayer</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_node_secondlayer</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="k">def</span> <span class="nf">model_dnn</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
            <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">n_node_firstlayer</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">),</span>
            <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">n_node_secondlayer</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">),</span>
            <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">"linear"</span><span class="p">)</span> <span class="c1"># 계측형 데이터 예측이므로 마지막 층은 node 1개, activation은 linear
</span>            <span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
        


<span class="n">response_workday_summer_train</span> <span class="o">=</span> <span class="n">workday_summer_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span> <span class="c1"># [0,1] 구간즈음에 들어오게 scaling해야 함, 그렇지 않고 원본 쓰면 제대로 fit 안되고 대표값 1개만 반환함
</span><span class="n">features_workday_summer_train</span> <span class="o">=</span> <span class="n">workday_summer_train</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_workday_summer_train</span> <span class="o">=</span> <span class="n">workday_summer_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">response_workday_summer_test</span> <span class="o">=</span> <span class="n">workday_summer_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span>
<span class="n">features_workday_summer_test</span> <span class="o">=</span> <span class="n">workday_summer_test</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_workday_summer_test</span> <span class="o">=</span> <span class="n">workday_summer_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">model_workday_summer</span> <span class="o">=</span> <span class="nf">model_dnn</span><span class="p">()</span>

<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="s">"./dnn_workday_summer.h5"</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s">'loss'</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># monitor까지 해 줘야 파일이 저장됨
</span><span class="n">model_workday_summer</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"mse"</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">)</span> <span class="c1"># 계측형 데이터 예측이므로 loss function은 mse
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model_workday_summer</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features_workday_summer_train</span><span class="p">,</span><span class="n">response_workday_summer_train</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">])</span>

<span class="n">y_fit_workday_summer</span> <span class="o">=</span> <span class="n">model_workday_summer</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_workday_summer_train</span><span class="p">)</span>
<span class="n">y_pred_workday_summer</span> <span class="o">=</span> <span class="n">model_workday_summer</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_workday_summer_test</span><span class="p">)</span>



<span class="n">response_workday_winter_train</span> <span class="o">=</span> <span class="n">workday_winter_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span> <span class="c1"># [0,1] 구간즈음에 들어오게 scaling해야 함, 그렇지 않고 원본 쓰면 제대로 fit 안되고 대표값 1개만 반환함
</span><span class="n">features_workday_winter_train</span> <span class="o">=</span> <span class="n">workday_winter_train</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_workday_winter_train</span> <span class="o">=</span> <span class="n">workday_winter_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">response_workday_winter_test</span> <span class="o">=</span> <span class="n">workday_winter_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span>
<span class="n">features_workday_winter_test</span> <span class="o">=</span> <span class="n">workday_winter_test</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_workday_winter_test</span> <span class="o">=</span> <span class="n">workday_winter_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">model_workday_winter</span> <span class="o">=</span> <span class="nf">model_dnn</span><span class="p">()</span>

<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="s">"./dnn_workday_winter.h5"</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s">'loss'</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># monitor까지 해 줘야 파일이 저장됨
</span><span class="n">model_workday_winter</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"mse"</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">)</span> <span class="c1"># 계측형 데이터 예측이므로 loss function은 mse
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model_workday_winter</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features_workday_winter_train</span><span class="p">,</span><span class="n">response_workday_winter_train</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">])</span>

<span class="n">y_fit_workday_winter</span> <span class="o">=</span> <span class="n">model_workday_winter</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_workday_winter_train</span><span class="p">)</span>
<span class="n">y_pred_workday_winter</span> <span class="o">=</span> <span class="n">model_workday_winter</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_workday_winter_test</span><span class="p">)</span>



<span class="n">response_workday_springfall_train</span> <span class="o">=</span> <span class="n">workday_springfall_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span> <span class="c1"># [0,1] 구간즈음에 들어오게 scaling해야 함, 그렇지 않고 원본 쓰면 제대로 fit 안되고 대표값 1개만 반환함
</span><span class="n">features_workday_springfall_train</span> <span class="o">=</span> <span class="n">workday_springfall_train</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_workday_springfall_train</span> <span class="o">=</span> <span class="n">workday_springfall_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">response_workday_springfall_test</span> <span class="o">=</span> <span class="n">workday_springfall_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span>
<span class="n">features_workday_springfall_test</span> <span class="o">=</span> <span class="n">workday_springfall_test</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_workday_springfall_test</span> <span class="o">=</span> <span class="n">workday_springfall_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">model_workday_springfall</span> <span class="o">=</span> <span class="nf">model_dnn</span><span class="p">()</span>

<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="s">"./dnn_workday_springfall.h5"</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s">'loss'</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># monitor까지 해 줘야 파일이 저장됨
</span><span class="n">model_workday_springfall</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"mse"</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">)</span> <span class="c1"># 계측형 데이터 예측이므로 loss function은 mse
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model_workday_springfall</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features_workday_springfall_train</span><span class="p">,</span><span class="n">response_workday_springfall_train</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">])</span>

<span class="n">y_fit_workday_springfall</span> <span class="o">=</span> <span class="n">model_workday_springfall</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_workday_springfall_train</span><span class="p">)</span>
<span class="n">y_pred_workday_springfall</span> <span class="o">=</span> <span class="n">model_workday_springfall</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_workday_springfall_test</span><span class="p">)</span>



<span class="n">response_holiday_train</span> <span class="o">=</span> <span class="n">holiday_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span> <span class="c1"># [0,1] 구간즈음에 들어오게 scaling해야 함, 그렇지 않고 원본 쓰면 제대로 fit 안되고 대표값 1개만 반환함
</span><span class="n">features_holiday_train</span> <span class="o">=</span> <span class="n">holiday_train</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_holiday_train</span> <span class="o">=</span> <span class="n">holiday_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">response_holiday_test</span> <span class="o">=</span> <span class="n">holiday_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="mi">2000</span>
<span class="n">features_holiday_test</span> <span class="o">=</span> <span class="n">holiday_test</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span>
<span class="n">hourindex_holiday_test</span> <span class="o">=</span> <span class="n">holiday_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> 

<span class="n">model_holiday</span> <span class="o">=</span> <span class="nf">model_dnn</span><span class="p">()</span>

<span class="n">checkpoint_cb</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="s">"./dnn_holiday.h5"</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s">'loss'</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># monitor까지 해 줘야 파일이 저장됨
</span><span class="n">model_holiday</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"mse"</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="s">"adam"</span><span class="p">)</span> <span class="c1"># 계측형 데이터 예측이므로 loss function은 mse
</span><span class="n">history</span> <span class="o">=</span> <span class="n">model_holiday</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features_holiday_train</span><span class="p">,</span><span class="n">response_holiday_train</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb</span><span class="p">])</span>

<span class="n">y_fit_holiday</span> <span class="o">=</span> <span class="n">model_holiday</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_holiday_train</span><span class="p">)</span>
<span class="n">y_pred_holiday</span> <span class="o">=</span> <span class="n">model_holiday</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_holiday_test</span><span class="p">)</span>



<span class="n">fittedpower</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">8760</span><span class="p">,))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_fit_workday_summer</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">fittedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_workday_summer_train</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_fit_workday_summer</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_fit_workday_winter</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">fittedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_workday_winter_train</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_fit_workday_winter</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_fit_workday_springfall</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">fittedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_workday_springfall_train</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_fit_workday_springfall</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_fit_holiday</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">fittedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_holiday_train</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_fit_holiday</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
    
<span class="n">predictedpower</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="mi">8760</span><span class="p">,))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_pred_workday_summer</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">predictedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_workday_summer_test</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_pred_workday_summer</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_pred_workday_winter</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">predictedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_workday_winter_test</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_pred_workday_winter</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_pred_workday_springfall</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">predictedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_workday_springfall_test</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_pred_workday_springfall</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">y_pred_holiday</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">predictedpower</span><span class="p">[</span><span class="nf">int</span><span class="p">(</span><span class="n">hourindex_holiday_test</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">y_pred_holiday</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>    
    
<span class="n">fittedpower</span> <span class="o">=</span> <span class="n">fittedpower</span><span class="o">*</span><span class="mi">2000</span>   
<span class="n">predictedpower</span> <span class="o">=</span> <span class="n">predictedpower</span><span class="o">*</span><span class="mi">2000</span>   



<span class="k">def</span> <span class="nf">adjrsq</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span><span class="n">estimate</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
    <span class="n">bary</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
    <span class="n">SST</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">bary</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">SSR</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">estimate</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">SSR</span><span class="o">/</span><span class="p">(</span><span class="mi">8760</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">SST</span><span class="o">/</span><span class="p">(</span><span class="mi">8760</span><span class="o">-</span><span class="n">k</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">r</span>
    
<span class="n">adjRsq_train</span> <span class="o">=</span> <span class="nf">adjrsq</span><span class="p">(</span><span class="n">actualpower</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">fittedpower</span><span class="p">,</span><span class="n">features_workday_summer_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">adjRsq_test</span> <span class="o">=</span> <span class="nf">adjrsq</span><span class="p">(</span><span class="n">actualpower</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">predictedpower</span><span class="p">,</span><span class="n">features_workday_summer_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">adjRsq_train</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">adjRsq_test</span><span class="p">)</span>


<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">actualpower</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">fittedpower</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">actualpower</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">predictedpower</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p>Adjusted $R^2$를 계산해보면 훈련 set에 대한 값은 0.9509이다. 이는 Weighted Least square (WLS) 만 했을 때의 결과인 0.9263보다는 더 높지만, WLS에 잔차의 SARMA 모델 적합까지 추가 수행 시 결과인 0.9746보다는 낮다. 한편 검증 set에 대한 값은 0.8642로, WLS만 했을 때의 결과인 0.8716보다도 낮다.</p>

<p>검증 set에 대한 결과와 딥러닝 훈련에 드는 계산비용을 생각하면, 딥러닝이 우월하다고 볼 수 없다 (계산 시간만 따져도 몇 분 vs. 몇 초(WLS만 수행 시)).</p>

<p><img src="/assets/images/predictiontwo/fit_dnn.png" alt="fit_dnn" class="align-center" />
<img src="/assets/images/predictiontwo/predict_dnn.png" alt="predict_dnn" class="align-center" />
<em>$K$년도 데이터로 적합한 DNN 모델 기반 전기부하 추정.</em></p>

<p><br /></p>

<h2 id="recurrent-neural-net">Recurrent Neural Net</h2>
<p>그럼, RNN을 쓰면 어떨까?</p>

<p>RNN의 경우 이전 시간의 전기 부하가 predictor로 포함되는 구조이므로, 일 유형별로 sub모델을 4개 만들 수는 없다. 1번째 시간의 data point부터 8,760번째 시간의 point까지 연속적으로 모델에 흘러들어가야 하므로, 하나의 모델로 모든 시간의 전기 부하를 예측해야 한다. 그러므로 RNN의 predictor로는 일 유형(평일/휴일) dummy도 추가한다.</p>

<p>Layer 수와 node 수는 DNN에서와 같게 둔다. DNN에서 그래도 선형회귀와 비슷한 수준의 예측 성능을 보였으므로, layer 수와 node 수 결정이 잘못된 것은 아니라 판단했다.</p>

<p>코드는 아래와 같다.</p>

<p><br /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># -*- coding: utf-8 -*-
</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>

<span class="n">data_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"RNN_train.txt"</span><span class="p">)</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">loadtxt</span><span class="p">(</span><span class="s">"RNN_test.txt"</span><span class="p">)</span>

<span class="n">n_node_firstlayer</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_node_secondlayer</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span><span class="n">beta_1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span><span class="n">beta_2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>


<span class="n">response_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2000</span> <span class="c1"># scaling
</span><span class="n">features_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:].</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">37</span><span class="p">)</span> <span class="c1"># reshape 해 줘야 rnn코드가 돌아감
</span>
<span class="n">response_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2000</span>
<span class="n">features_test</span> <span class="o">=</span> <span class="n">data_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:].</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">37</span><span class="p">)</span>



<span class="n">model_rnn</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">SimpleRNN</span><span class="p">(</span><span class="n">n_node_firstlayer</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span><span class="mi">37</span><span class="p">]),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">SimpleRNN</span><span class="p">(</span><span class="n">n_node_secondlayer</span><span class="p">,</span><span class="n">return_sequences</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">TimeDistributed</span><span class="p">(</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="c1"># To make a sequence-to-sequence model, TimeDistributed should be used
</span>    <span class="p">])</span>

<span class="n">checkpoint_cb_rnn</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">callbacks</span><span class="p">.</span><span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="s">"./rnn.h5"</span><span class="p">,</span><span class="n">monitor</span><span class="o">=</span><span class="s">'loss'</span><span class="p">,</span><span class="n">save_best_only</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># monitor까지 해 줘야 파일이 저장됨
</span><span class="n">model_rnn</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">"mse"</span><span class="p">,</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>
<span class="n">history_rnn</span> <span class="o">=</span> <span class="n">model_rnn</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">features_train</span><span class="p">,</span><span class="n">response_train</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="n">n_epochs</span><span class="p">,</span><span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">checkpoint_cb_rnn</span><span class="p">])</span>

<span class="n">y_fit</span> <span class="o">=</span> <span class="p">(</span><span class="n">model_rnn</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_train</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2000</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">model_rnn</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">features_test</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2000</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>



<span class="k">def</span> <span class="nf">adjrsq</span><span class="p">(</span><span class="n">actual</span><span class="p">,</span><span class="n">estimate</span><span class="p">,</span><span class="n">k</span><span class="p">):</span>
    <span class="n">bary</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">actual</span><span class="p">)</span>
    <span class="n">SST</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">bary</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">SSR</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">actual</span> <span class="o">-</span> <span class="n">estimate</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">r</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">SSR</span><span class="o">/</span><span class="p">(</span><span class="mi">8760</span><span class="o">-</span><span class="n">k</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">SST</span><span class="o">/</span><span class="p">(</span><span class="mi">8760</span><span class="o">-</span><span class="n">k</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">r</span>
    
<span class="n">adjRsq_train</span> <span class="o">=</span> <span class="nf">adjrsq</span><span class="p">(</span><span class="n">data_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y_fit</span><span class="p">,</span><span class="n">features_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">adjRsq_test</span> <span class="o">=</span> <span class="nf">adjrsq</span><span class="p">(</span><span class="n">data_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">y_pred</span><span class="p">,</span><span class="n">features_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">adjRsq_train</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">adjRsq_test</span><span class="p">)</span>



<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">data_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_fit</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">data_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">((</span><span class="n">data_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">y_fit</span><span class="p">))</span>
</code></pre></div></div>

<p>계산에 걸리는 시간은 수십 분으로, 당연히 DNN보다도 훨씬 길다. 그렇다면 적합 결과는?</p>

<p>Adjusted $R^2$를 계산해보면 훈련 set에 대한 값은 0.6941, 검증 set에 대한 값은 0.4890으로, 처참한 수준이다. 심지어 훈련 set에 대해서조차 그렇다.</p>

<p><img src="/assets/images/predictiontwo/fit_rnn.png" alt="fit_rnn" class="align-center" />
<img src="/assets/images/predictiontwo/predict_rnn.png" alt="predict_rnn" class="align-center" />
<em>$K$년도 데이터로 적합한 RNN 모델 기반 전기부하 추정.</em></p>

<p>위 그림을 보면, RNN으로 추정한 부하 그래프가 매우 울퉁불퉁하다. 이는 Data Generating Process와 맞지 않는 모델을 사용한 것, 즉 mis-specification을 암시한다. (그러므로 RNN에 layer 또는 node를 추가하거나, 더 복잡한 방법인 LSTM/ GRU 등을 시도하는 것은 의미가 없다고 판단된다.)</p>

<p>실제로는, ‘그냥 무작정 RNN부터 쓰고 보는 사람’이라면 시간별/ 월별/ 일유형별 dummy variable 없이 온도와 조도만을 input으로 하여 신경망을 훈련시킬 가능성이 높다. 이 경우에 대해 adjusted $R^2$를 계산해 본 결과, 훈련 set에 대한 값은 0.3574, 검증 set에 대한 값은 0.2450으로 더욱 처참해진다.</p>

<p><img src="/assets/images/predictiontwo/fit_rnn_nodummy.png" alt="fit_rnn_nodummy" class="align-center" />
<img src="/assets/images/predictiontwo/predict_rnn_nodummy.png" alt="predict_rnn_nodummy" class="align-center" />
<em>$K$년도 데이터로 적합한 RNN 모델 기반 전기부하 추정 (시간별/ 월별/ 일유형별 dummy variable 없이).</em></p>

<p><br /></p>

<h2 id="나가며">나가며</h2>
<p>딥러닝이 음성인식과 자연어 처리에서 큰 진보를 이뤄내서 그런지, 이런 시계열 데이터 예측은 RNN으로 하면 다 해결될 거라 생각하는 경우가 많다.</p>

<p>그러나 간단한 선형회귀 모델도 잘 구성하면 NN보다 좋은 경우도 많고, 특히 RNN은 매우 복잡한 패턴이 stationary한 분포를 갖고 반복적으로 나타날 때 의미가 있지 (같은 나라/ 문법/ 분야 하의 문장들 등), 그렇지 않으면 계산 비용만 크게 소비하고 별 효과가 없다는 것은 계산과학 필드에서는 상식이다. 이러한 상식은 에너지 부하 데이터에 대해서도 마찬가지로 적용됨을 확인해 볼 수 있었다.</p>

<p>당장 이번 사례에서 선형회귀와 DNN에 대해 sub모델 4개를 구성한 것을 생각해 보면, 1년간의 시간별 부하 데이터는 non-stationary data이다. 이를 고려하지 않고 non-stationary data에 대해 무작정 단일한 RNN 모델을 쓰면, 결과가 이상하게 나올 수밖에 없다 (일유형 dummy변수를 추가하기는 했지만, 그것으로는 부족했다).</p>

<p>데이터의 non-stationarity를 고려해 sub모델 4개로 나누는 ‘데이터 전처리’와 오차의 자기상관성을 추가로 설명하는 과정을 거친 덕분에, 그리고 각 sub모델 별 구간 내의 non-linearity가 심하지 않았기에, 간단한 선형회귀 모델로 딥러닝보다 더 나은 결과를 빠르게 얻을 수 있었다. (거기에 더해, 선형회귀 모델은 딥러닝처럼 훈련 시마다 모델 parameter 값들이 다르게 나오지 않고 항상 같게 나온다는 장점도 있다.)</p>

<p>이렇듯 계산 시간도 빠르면서 성능도 나은 경우 ‘computational efficiency’가 좋다고 한다. 내가 가진 데이터에 대해 더 잘 알수록, 그리고 가능한 기법들 각각의 장단점에 대해 더 잘 알수록, ‘computationally efficient한’ 방법을 사용할 수 있을 가능성이 높다.</p>

<p><a href="https://pdsi.pabii.com/data-scientists-future-2/">(RNN과 전통적인 시계열 모델에 대해 참고할 만한 글)</a></p>

<div class="notice--info">

건물의 시간별 전기부하 학습 후 예측하기<br /><br />

1) <a href="/predictionone.html">딥러닝 대신 회귀분석으로</a><br />
2) <b>딥러닝을 쓴다면?</b>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="estimation" /><category term="회귀분석" /><category term="딥러닝" /><category term="부하패턴" /><summary type="html"><![CDATA[지난 포스팅에서는 건물의 시간별 전기부하 추정 모델을 딥러닝이 아닌 ‘전통적인’ 선형회귀 (Weighted Least squares + 잔차에 대한 SARMA) 로 만들어 adjusted $R^2$ 0.95 이상의 우수한 성능을 얻을 수 있음을 보였다.]]></summary></entry><entry><title type="html">건물의 시간별 전기부하 학습 후 예측하기 - 딥러닝 대신 회귀분석으로</title><link href="https://song4energyndata.github.io/predictionone.html" rel="alternate" type="text/html" title="건물의 시간별 전기부하 학습 후 예측하기 - 딥러닝 대신 회귀분석으로" /><published>2023-04-15T00:00:00+09:00</published><updated>2023-04-15T00:00:00+09:00</updated><id>https://song4energyndata.github.io/predictionone</id><content type="html" xml:base="https://song4energyndata.github.io/predictionone.html"><![CDATA[<p>시계열 데이터에 대해, 경우에 따라서는 전통적인 선형회귀가 딥러닝보다 더 좋은 예측력을 보인다는 놀라운(?) 사실을 아는가?</p>

<h2 id="건물의-시간별-전기-부하">건물의 시간별 전기 부하</h2>

<p>다음 그림은, 어떤 건물의 특정 1주일 간 각 시간별 전기 사용량 그래프들이다. 파란색 곡선은 K년도의 특정 1주일이고 (K는 2010~2022 사이의 어떤 자연수), 초록색 곡선은 K+1년도에서의 같은 1주일이다.</p>

<p><img src="/assets/images/predictionone/demands_winter.png" alt="demands_winter" class="align-center" />
<img src="/assets/images/predictionone/demands_summer.png" alt="demands_summer" class="align-center" />
<img src="/assets/images/predictionone/demands_spring.png" alt="demands_spring" class="align-center" />
<em>특정 건물 내 1주일 간의 시간별 전기 부하 (위에서부터 겨울, 여름, 봄)</em></p>

<p>두 해의 전기 사용량 패턴의 높이나 전반적인 모양이  비슷하다. 그러므로 해당 건물의 사용 행태나 건물 규모 또는 전기 요금체계 등에 급격한 변화가 없다면, 매년 비슷한 전기 사용 패턴을 보이리라 추측된다.</p>

<p><br />
그렇다면, K년도의 시간별 전기부하를 어떤 predictor들의 함수로써 학습시켰을 때, K+1년도의 predictor들 값만을 이용해 K+1년의 전기부하를 실제에 가깝게 예측할 수 있을까? 그리고 그 예측에는 어떤 방법을 사용해야 할까? 딥러닝 (Recurrent Neural Network 등)? 전통적인 선형회귀?</p>

<p>이러한 학습 및 예측을 수행해 보자. 이번 포스팅에서는, ‘딥러닝을 쓰지 않고’ 회귀분석으로 예측하는 모델을 구성해본다.</p>

<h2 id="회귀모델-설명">회귀모델 설명</h2>
<p><br /> 
Predictor로는 기온과 일조를 선택했다. ‘기상청에서 쉽게 구할 수 있으면서’ 건물의 에너지 사용량에 영향을 미칠 것으로 추정되기 때문이다. 기온은 건물의 냉난방 부하에 큰 영향을 미치고, 일조도 냉난방 부하에 어느 정도 영향을 미치면서 조명 부하에도 약간 영향을 미칠 것으로 추정된다. <a href="https://data.kma.go.kr/data/grnd/selectAsosRltmList.do?pgmNo=36">(기상청 종간기상관측자료 링크)</a></p>

<p><img src="/assets/images/predictionone/kma_data.png" alt="kma_data" class="align-center" width="70%" />
<em>기상청 종간기상관측자료에서 다운로드받은, 시간별 기온과 일조 자료 예시.</em></p>

<p>기온과 일조를 이용해 건물 전기 부하 예측이 높은 정확도로 가능하다면, 기상청에서 다음 날의 시간별 기온과 일조 예보를 보고 다음 날의 전기 부하 예측이 가능할 것이다.</p>

<p><br />
우선 기온과 조도, 그리고 기온과 조도의 이차항을 회귀모델의 predictor로 추가한다. 이 predictor들과 전기부하 간 관계가 비선형적일 수 있기 때문이다.</p>

<p>이를테면 기온이 높을수록 겨울의 난방부하는 감소하겠지만 여름의 냉방부하는 증가할 것이다. 또한 같은 계절 내에서 기온이 증가할 때 냉난방부하가 이에 대해 선형적으로 증가/감소하지 않을 수도 있다.</p>

<p>그리고 시간별 dummy variable들과 월별 dummy variable들도 회귀모델의 predictor로 추가한다. 하루 24시간 내의 각 시간별로는 전기 사용량이 다르고, 그 24시간 동안의 전기 부하 패턴의 모양도 월별로 다를 수 있기 때문이다 (특히 냉방/난방용 전기 사용이 있는 계절의 경우).</p>

<p>그리고 기온의 영향 또한 시간 및 월에 따라 다를 수 있으므로, dummy variable들과 기온 및 기온의 이차항 간 상호작용항들도 추가한다.</p>

<p><br /> 
여기서 약간의 도메인 지식에 기반해 다시 생각해보면, 기온과 조도가 부하에 영향을 크게 미치는 기간은 냉방/난방 설비를 가동하는 하절기와 동절기의 평일일 것으로 추정된다. 바꿔 말하면, 냉방/난방 설비를 가동하지 않는 춘추절기 및 휴일에는 기온과 조도의 영향이 미미할 것으로 추정된다.</p>

<p>그리고 맨 위의 그림을 잘 보면, 같은 평일이라도 겨울의 평일, 여름의 평일, 봄/가을의 평일의 24시간 동안의 전기부하 패턴의 모양에는 서로 차이가 있다.</p>

<p>구체적으로, 난방기간의 경우 아침에 부하가 제일 높고 퇴근시간까지 완만하게 감소하지만, 냉방기간의 경우 아침의 부하가 퇴근시간까지도 별로 줄어들지 않는다. 한편 냉/난방 기간이 아닌 경우 부하 자체가 작은 편이다. 또한 휴일의 부하패턴 모양은 평일과 달리 평평하며, 대신 이러한 평평한 패턴은 모든 계절에 대해 비슷하다.</p>

<p><br />
이러한 점들을 고려할 때, 모델을 아래의 4개 sub모델들로 분리하는 것이 적절해 보인다.</p>

<p>1) 냉방설비 가동기간 (5~9월) 평일 (Predictor는 월더미, 시간더미, 기온도, 일조, 월별 dummy와 시간별 dummy가 기온의 일차항 및 이차항과 곱해진 교차항들임)<br /></p>

<p>2) 난방설비 가동기간 (11~3월) 평일 (Predictor는 하절기 평일 모델에서와 같음)<br /></p>

<p>3) 그 외 기간 (4월, 10월) 평일 (Predictor는 시간별 dummy)<br /></p>

<p>4) 휴일 (Predictor는 월별 dummy와 시간별 dummy)</p>

<p><br />
K년도의 자료를 갖고, 4개 sub모델 각각에 대해 Weighted Least Squares (WLS)를 개별로 수행한다. Weight는 부하가 큰 시간일수록 크게 (즉 부하 값으로) 배정했다.</p>

<p>Ordinary Leasts Squares (OLS)가 아닌 WLS를 쓴 이유는, 모델이 최대부하 값을 보다 더 잘 추정하도록 하기 위함이다 (최대부하 정보가 기본요금 설정 및 전력계통 설비 용량 선정 관점에서 중요한 정보이므로).</p>

<p>시간 $t$에서의 전기 부하를 $p_t$, 설명변수 벡터를 $x_t$라 할 때, 4개 sub모델 중 $k$번째 sub모델 $\mathcal{M}_{k}$의 계수 $\beta_k$에 대한 수식은 아래와 같다.</p>

<p>Minimize $ \sum_{t \in \mathcal{M}_{k}} p_{t} (p_{t} - x_{t}^{\top} \beta_k)^2 $</p>

<p>이는 $p_{t}$를 가중치로 하는 WLS이다. 위 목적함수를 최소화하는 $\beta_k$의 추정량 $\hat{\beta}_k$를 구한다. $\hat{\beta}_k$를 구하는 데에는 $K$년도의 자료만 사용하고, $K+1$년도의 자료는 사용하지 않음에 주의한다.</p>

<p><br /></p>

<h2 id="wls-회귀모델-적합-결과">WLS 회귀모델 적합 결과</h2>
<p>WLS로 적합된 회귀모델에, K+1년도의 각 시간별 설명변수 값들을 대입하면 K+1년도의 시간별 전기부하 추정치를 $\hat{p}_t = x_{t}^{\top} \hat{\beta}_k$ 로 구할 수 있다. 물론 이는 실제 전기부하 $p_t$와는 다르지만, 모델이 잘 적합되었다면 매우 비슷할 것이다. 이 회귀모델의 적합도는 얼마나 될까?</p>

<p>Adjusted $R^2$를 계산해보면, 훈련 set (K년도)에 대해서는 0.9263, 검증 set (K+1년도)에 대해서는 0.8716이다. 그림으로 보이면 아래와 같다</p>

<p><img src="/assets/images/predictionone/fit_wls.png" alt="fit_wls" class="align-center" />
<img src="/assets/images/predictionone/predict_wls.png" alt="predict_wls" class="align-center" />
<em>$K$년도 데이터로 적합한 WLS 모델 기반 전기부하 추정.</em></p>

<p>기상청의 공개 자료만을 사용했고 WLS 계산이 몇 초만에 된다는 걸 생각해보면, 구하기 쉬운 데이터와 적은 계산비용으로 나름 괜찮은 성능의 모델을 얻었다고 볼 수 있다.</p>

<p><br /></p>

<h2 id="오차의-자기상관을-seasonal-arma로-모델링">오차의 자기상관을 Seasonal ARMA로 모델링</h2>
<p>위 WLS에는 사실 오차의 자기상관 (autocorrelation in disturbances) 문제가 남아있다. 위 그림들에서 실제값과 예측값을 잘 보면, 예측값이 실제값보다 큰 시간이 어느 정도 연속되다가, 반대로 예측값이 실제값보다 작은 시간이 어느 정도 연속되는 것이 반복된다.</p>

<p>실제로 각 sub모델별로 WLS의 잔차에 대해 ACF (AutoCorrelation Function) 및 PACF (Partial ACF) plot을 그려보면, 아래 왼쪽 그림의 ACF plot에서 보듯 오차의 자기상관이 뚜렷하다. 시계열 데이터의 자기상관성 검정을 위한 Ljung-Box test 수행 시 $p$-value가 사실상 0으로 계산되어서, 자기상관이 없다는 귀무가설이 기각된다.</p>

<p><img src="/assets/images/predictionone/acfplot_before.png" alt="acfplot_before" class="align-center" width="90%" />
<em>하절기 sub모델의 WLS 잔차에 대한 ACF와 PACF plot.</em></p>

<p>이러한 오차의 자기상관은, 아직 잔차로부터 얻을 수 있는 정보가 남아 있음을 의미한다. 그렇다면 각 sub모델별로 $K$년도의 WLS 잔차들에 대해 시계열 모델을 적합하고, 해당 모델로 $K+1$년도의 WLS 잔차들을 설명하면 최종 모델의 adjusted $R^2$를 증가시킬 수 있을 것으로 기대된다.</p>

<p>통계처리용 언어 R에서 $\texttt{auto.arima()}$ 함수를 사용해, $K$년도 WLS 잔차에 ARMA 모델을 적합시킨다 (단, 차분은 하지 않으며 drift와 mean은 사용하지 않는다). 그리고 $K$년도 WLS 잔차에 대해 ARMA 모델로 설명되는 맞춘값을 얻는다.</p>

<p>또한 $K+1$년도 WLS 잔차에 대해, $K$년도 WLS 잔차로 적합시킨 ARMA 모델로 설명되는 맞춘값을 얻는다.</p>

<p>($K+1$년도 WLS 잔차로 새로운 ARMA 모델을 적합시킨 것이 아님에 유의. 만약 그랬다면 그건 반칙이다. 회귀모델의 적합은 어떤 경우에도 $K$년도 데이터만으로 이루어져야 한다.)</p>

<p>$K$년도 WLS 잔차에 ARMA 모델을 적합 후 해당 ARMA 모델의 잔차에 대해 ACF 및 PACF plot을 아래와 같이 그려보면, 자기상관성이 ‘거의’ 사라졌으나, 아직 24시간 주기의 자기상관성은 남아있다.</p>

<p><img src="/assets/images/predictionone/acfplot_after.png" alt="acfplot_before" class="align-center" width="90%" />
<em>하절기 sub모델의 WLS 잔차에 대해 ARMA 모델을 적합시킨 후, ARMA 모델의 잔차에 대한 ACF와 PACF plot.</em></p>

<p>이는 전기 사용량 자체가 24시간 주기로 반복되는 특성이 있기 때문이다. Ljung-Box test를 수행 시 $p$-value 또한 lag 23까지에 대해서는 전부 0.1 이상이나 lag 24에 대해서는 사실상 0이므로, 24시간 주기의 자기상관성이 존재한다.</p>

<p>이는 seasonal ARMA (SARMA) 모델을 적합시켜 반영할 수 있다. 이를테면 $\texttt{auto.arima()}$로 적합된 모델이 ARIMA$(1,0,2)$라 하자. 그러면 $\texttt{Arima()}$ 함수를 사용해 SARIMA$(1,0,2)(1,0,1)_{24}$ 모델을 적합한다.</p>

<p>$K$년도 WLS의 잔차에 SARMA 모델을 적합 후 해당 SARMA 모델의 잔차에 대해 ACF 및 PACF plot을 아래와 같이 그려보면, 드디어 자기상관성이 완전히 사라졌다.</p>

<p><img src="/assets/images/predictionone/acfplot_sarima.png" alt="acfplot_sarima" class="align-center" width="90%" />
<em>하절기 sub모델의 WLS 잔차에 대해 SARMA 모델을 적합시킨 후, SARMA 모델의 잔차에 대한 ACF와 PACF plot.</em></p>

<p>Ljung-Box test를 수행 시 $p$-value 또한 lag 24까지에 대해서도 0.1 이상이다. 또한 log-likelihood, AIC, BIC 등 지표도 ARMA 대비 SARMA 모델에서 더 좋았다.</p>

<p>WLS와 잔차에 대한 SARMA 적용 시 자기상관이 완전히 사라졌다는 것은, 기존 전기부하 자료에 강한 non-linearity가 존재하지 않음을 암시한다 (선형 모델로 거의 다 설명이 되니까).</p>

<p><br />
일부 독자는 ‘WLS 모델의 오차에 자기상관성 문제가 있으면, 시점 $t$의 전기 부하 예측 시의 설명변수로 과거 시점 ($t-1, t-2, \cdots$) 의 전기부하를 넣으면 되는 것 아닌가?’라고 생각할지도 모르겠다.</p>

<p>그러나 그 반대이다. 오차항에 자기상관이 있는 경우 과거 시점의 반응변수 (lagged dependent) 를 설명변수로 추가하면, 계수추정량이 ‘inconsistent’ 해진다는 것이 알려져 있다. Inconsistent란, ‘데이터가 많아져도 계수 추정량이 계수의 (숨겨진) 참값으로부터 벗어남’ 을 의미한다. (주로 계량경제 side의 회귀분석 강의에서 이를 가르친다)</p>

<p><br /></p>
<h2 id="오차의-자기상관-모델링을-통한-예측력-향상">오차의 자기상관 모델링을 통한 예측력 향상</h2>
<p>$K$년도 잔차로 적합한 SARMA 모델로 설명되는 맞춘값들을 기존 WLS 맞춘값들에 더하면, adjusted $R^2$가 증가할까?</p>

<p>그렇다. 훈련 set (K년도)에 대해서는 0.9263에서 0.9746으로, 검증 set (K+1년도)에 대해서는 0.8716에서 0.9734로 증가한다. 아래 그림을 보면, 오차의 자기상관을 반영하기 전과 비교해서, 예측값이 실제값에 더 가까워졌다.</p>

<p><img src="/assets/images/predictionone/fit_arma.png" alt="fit_arma" class="align-center" />
<img src="/assets/images/predictionone/predict_arma.png" alt="predict_arma" class="align-center" />
<em>$K$년도 데이터로 적합한 WLS + 잔차 SARMA 모델 기반 전기부하 추정.</em></p>

<p>Adjusted $R^2$가 꼭 절대적인 기준은 아니겠지만, 딥러닝을 쓰지 않고 전통적 회귀분석 기법만을 사용해서 검증 set에 대해 Adjusted $R^2$ 0.95 이상을 달성한 것은 상당히 고무적이다.</p>

<p><br />
그렇다면 딥러닝을 쓴다면 어떨까? Adjusted $R^2$ 0.99 정도는 쉽게 얻을 수 있을까?</p>

<p>이는 다음 포스팅에서 확인해 본다.</p>

<div class="notice--info">

건물의 시간별 전기부하 학습 후 예측하기<br /><br />

1) <b>딥러닝 대신 회귀분석으로</b><br />
2) <a href="/predictiontwo.html">딥러닝을 쓴다면?</a>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="estimation" /><category term="회귀분석" /><category term="딥러닝" /><category term="부하패턴" /><summary type="html"><![CDATA[시계열 데이터에 대해, 경우에 따라서는 전통적인 선형회귀가 딥러닝보다 더 좋은 예측력을 보인다는 놀라운(?) 사실을 아는가?]]></summary></entry><entry><title type="html">건축물 별 월별 에너지 사용량 데이터셋 - 3) 월별 사용량 크기가 이상한 data point 제거</title><link href="https://song4energyndata.github.io/monthlyenergythree.html" rel="alternate" type="text/html" title="건축물 별 월별 에너지 사용량 데이터셋 - 3) 월별 사용량 크기가 이상한 data point 제거" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-26T00:00:00+09:00</updated><id>https://song4energyndata.github.io/monthlyenergythree</id><content type="html" xml:base="https://song4energyndata.github.io/monthlyenergythree.html"><![CDATA[<p><a href="/monthlyenergytwo.html">이전 포스팅</a>에서는 건물 월별 에너지 사용량의 ‘추이’가 이상한 data point를 판별하는 방법을 설명했다. 이번 포스팅에서는 월별 에너지 사용량의 ‘크기(magnitude)’가 이상한 data point를 판별하는 방법을 설명한다.</p>

<p><br /></p>

<h2 id="에너지-사용량-크기-측면에서의-outlier">에너지 사용량 크기 측면에서의 outlier</h2>
<p>상식적으로, 같은 용도의 건물이라면 크기가 큰 건물일수록 에너지 사용량이 큰 경향이 있을 것이다. 이를테면 서울 내 업무용 건물들의 1월 전기 사용량을 연면적 (모든 층의 바닥면적의 합, 단 주차장이나 공용시설 등은 제외) 에 대해 scatter plot하면 아래 그림과 같다.</p>

<p><img src="/assets/images/monthlyenergythree/outliers.png" alt="outliers" class="align-center" width="70%" />
<em>x축이 연면적, y축이 1월 전기 사용량. 위쪽에 outlier들이 보임 (붉은 점들).</em></p>

<p>다소 데이터의 흩어짐(분산)이 크긴 하나, 어쨌든 연면적이 클수록 ‘평균적으로는’ 전기 사용량이 커지는 경향이 있다.</p>

<p><br />
그런데, 위 그림의 붉은 점들은 딱 봐도 ‘크기가 이상한’ data point, 소위 말해서 ‘outlier’이다. 건물 연면적을 고려했을 때 전기 사용량의 값이 지나치게 크다.</p>

<p>이는 측정/기재 오류일 수도 있고, 어쩌면 정말로 저만큼 많은 전기를 쓰는 것일 수도 있다. 그러나 만에 하나 정말로 저렇게 많은 전기를 사용한다고 하더라도, 그런 건물은 일반적이지 않으므로 따로 떼어서 별도의 모델링을 하는 것이 맞다.</p>

<p>즉, ‘일반적인’ 건물들에 대한 통계적 연구 수행을 위해서는 위 outlier들은 제거해야 한다.</p>

<p><br /></p>
<h2 id="outlier-판별-방법">Outlier 판별 방법</h2>
<p>그럼 outlier는 어떻게 판별하나? 데이터의 size가 그렇게 크지 않고 설명변수가 하나라면, 그냥 그래프를 그려서 눈으로 보고 제거할 수도 있을 것이다. 그러나 데이터 size도 커지고 설명변수도 둘 이상이 되면, 눈으로 보기 매우 힘들다 (이를 테면 반응변수를 에너지 사용량으로 하는 회귀모델에 대해, 설명변수가 건물 연면적 뿐 아니라 건물 층수, 사용연수, 재질 등 여러 가지가 될 수 있다.</p>

<p>그러므로 시각화를 필요로 하지 않으면서 outlier를 판별할 수 있는, 이전 포스팅에서처럼 지표(metric)에 기반해서 판별하는 방법이 필요하다.</p>

<p><br />
여기서 생각해 볼 수 있는 것은, 위 그림에서 outlier들이 있을 때와 없을 때 각 경우에 대해 회귀분석을 했을 때의 직선의 기울기이다. 위 그림 기준으로는 빨간 점들이 없을 때 계산된 직선의 기울기에 비해, 빨간 점들이 있을 때 계산된 직선의 기울기가 더 가파를 것이다. 즉 outlier들이 있을 때 구한 회귀계수와 없을 때 구한 회귀계수 간에 유의미한 차이가 있을 것이다.</p>

<p>반대로, 검정 점들 중 몇 개 정도를 없애고 회귀계수를 계산했다고 하자. 그 결과는 아마, 모든 점들이 있을 때의 회귀계수와 별 차이가 없을 것이다.</p>

<p>그렇다면, 각 data point $i$에 대해, $i$가 포함되어 있을 때 구한 회귀계수와 $i$가 제외될 때 구한 회귀계수 간의 표준화된 차이를 모든 data point들 각각에 대해 구한다면, 그 차이가 큰 data point가 outlier일 것임을 짐작할 수 있다.</p>

<p>이러한 ‘특정 점 $i$의 유무에 따른 회귀계수 간 표준화된 차이’를 Cook’s Distance라 한다. 
$m$월의 전기 사용량을 반응변수로 하는 회귀모델에 대해, Cook’s Distance의 수식은 아래와 같다.</p>

<p>\begin{align} 
D_{i}^{elec,m}=\frac{\left({\hat{\beta}}^{elec,m}-{\hat{\beta}}_{-i}^{elec,m}\right)^{\top}X^{\top}X\left({\hat{\beta}}^{elec,m}-{\hat{\beta}}_{-i}^{elec,m}\right)}{k \cdot MSR^{elec,m}} 
\notag
\end{align}</p>

<p>$\hat{\beta}$는 data point $i$를 포함해 모든 data point들이 있을 때 구한 회귀계수이고, $\hat{\beta}_{-i}$는 data point $i$만을 dataset으로부터 뺐을 때 구한 회귀계수이다. $X$는 설명변수 행렬로, $i$번째 행이 $i$번째 data point에 대한 설명변수들로 구성된 행벡터이다 (여기서 설명변수는 연면적, 층수, 사용연도, 재질, …, 그리고 상수항 표현을 위한 1). 분모의 $k$는 설명변수 개수이고, $MSR$은 잔차의 평균제곱합이다.</p>

<p><br />
이 때, 혹자는 계산시간 관련해서 우려를 표할 수 있다. 만약 data point가 수십만 개면, Cook’s Distance들을 계산하기 위해 수십만 번의 회귀분석을 계산해야 되는 것이 아닐까? 그러면 시간이 너무 오래 걸리지 않을까?</p>

<p>다행히도 그렇지 않다. 단 한 번의 회귀분석과 한 번의 행렬 연산으로, 모든 data point 각각에 대한 Cook’s Distance들을 계산할 수 있다. Cook’s Distance의 다른 식은 아래와 같다.</p>

<p>\begin{align} 
D_{i}^{elec,m}=\frac{\hat{\epsilon}_{i}^{elec,m}h_{ii}}{k \cdot MSR^{elec,m}\left(1-h_{ii}\right)^2}
\notag
\end{align}</p>

<p>여기서 $\hat{\epsilon}_{i}^{elec,m}$는 $i$번째 잔차, $h_{ii}$는 hat matrix $X\left(X^{\top} X \right)^{-1}X^{\top}$의 $i$번째 대각성분이다.</p>

<p>(역시 자세한 내용은 <a href="https://product.kyobobook.co.kr/detail/S000002582053">Montgomery의 Introduction to Linear Regression</a>의 7단원을 참고하길 바란다.)</p>

<p><br />
필자가 알기로는 Cook’s D에는 어떤 rule of thumb로써의 수치가 있지는 않은 듯 하다. 사전에 정의한 갯수만큼의 데이터를, Cook’s D가 큰 순서대로 제거하는 것이 현실적인 방법으로 보인다.</p>

<p>단, 주의할 점은, 한 번의 Cook’s D 계산 후 data point 여러 개를 제거하면 안 된다. Cook’s D가 가장 큰 ‘하나의’ point만 제거하고, 다시 모든 point Cook’s D를 계산해서 또 하나를 제거하고 다시 계산하는 과정을 반복해야 한다.</p>

<p>이는 Cook’s D 자체가 ‘하나의’ data point의 유무 간 차이에 대해 정의되기 때문이다.</p>

<p>만약 어떤 dataset에 대해 Cook’s D를 계산했더니 point $i$에 대해 Cook’s D가 가장 크고 $j$에 대해 Cook’s D가 두 번째로 크다고 하자. 이 때 point $j$에 대한 Cook’s D는, point $i$가 dataset에 있다는 가정 하에 계산된다. 그런데 우리는 outlier를 제거해나가야 하므로, Cook’s D가 가장 큰 outlier $i$가 dataset에 있다는 가정 하에 나머지 point들에 대한 outlier 여부를 판단하는 것은 부자연스럽다.</p>

<div class="notice--info">

건축물 별 월별 에너지 사용량 데이터셋<br /><br />

1) <a href="/monthlyenergyone.html">모든 월에 대한 통합 및 표제부와의 결합 후 SQLite DB화</a><br />
2) <a href="/monthlyenergytwo.html">월별 사용 추이가 이상한 data point 제거</a><br />
3) <b>월별 사용량 크기가 이상한 data point 제거</b>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="dataset" /><category term="건물 에너지 데이터" /><category term="회귀분석" /><summary type="html"><![CDATA[이전 포스팅에서는 건물 월별 에너지 사용량의 ‘추이’가 이상한 data point를 판별하는 방법을 설명했다. 이번 포스팅에서는 월별 에너지 사용량의 ‘크기(magnitude)’가 이상한 data point를 판별하는 방법을 설명한다.]]></summary></entry><entry><title type="html">건축물 별 월별 에너지 사용량 데이터셋 - 2) 월별 사용 추이가 이상한 data point 제거</title><link href="https://song4energyndata.github.io/monthlyenergytwo.html" rel="alternate" type="text/html" title="건축물 별 월별 에너지 사용량 데이터셋 - 2) 월별 사용 추이가 이상한 data point 제거" /><published>2023-03-25T00:00:00+09:00</published><updated>2023-03-25T00:00:00+09:00</updated><id>https://song4energyndata.github.io/monthlyenergytwo</id><content type="html" xml:base="https://song4energyndata.github.io/monthlyenergytwo.html"><![CDATA[<p>이전 포스팅에서, 건물 지번별/월별 전기/도시가스 사용량 데이터와 표제부의 결합을 소개했다. 해당 데이터셋을 그대로 쓰면 되는가? 그렇지 않다. 분명히 ‘이상한’ data point들이 존재할 것이며, 이상한 data point들을 ‘전처리’해야 올바른 연구 결과를 얻을 수 있다.</p>

<p><br /></p>

<h2 id="데이터-전처리-종류">데이터 전처리 종류</h2>

<p>가장 먼저 떠올릴 전처리는, 누락이 있는 point 제거이다. 이미 이전 포스팅의 마지막 부분에서 SQLite DB로부터 서울 내 건물들 중 ‘전기 사용량 및 연면적 값의 누락이 없는’ point들만 불러왔다. 여기에 더해, 봄~가을의 도시가스 사용 내역이 있는데 겨울(12, 1, 2월)의 도시가스 사용 내역이 없는 point는 ‘이상한’ point로 보고 제거한다 (상식적으로 도시가스를 쓴다면 겨울에 집중적으로 쓰는 것이 정상이므로).</p>

<p><br />
그 외에 `이상하다’의 기준은, 크게 다음의 두 가지로 볼 수 있다.</p>

<p>1) 12개월 간 월별 에너지 사용량의 추이가 이상함 (전기 사용량 내역을 봤더니 봄/가을 사용량이 여름 사용량보다 월등히 높다든지)</p>

<p>2) 에너지 사용량의 크기(magnitude)가 이상함 (건물은 작은데 비슷한 크기의 타 건물들 대비 에너지 사용량이 지나치게 크다든지)</p>

<p>이러한 ‘이상함’의 이유를 정확히는 알 수 없다. 그러나 이러한 point들은 ‘일반적인’ 건물들에 대한 통계적 에너지 모델링에 도움이 되기는커녕 오히려 해가 될 것이므로, 조치를 취해야 한다.</p>

<p>(필자가 한 가지 발견했던 것은, 지하철 역사의 경우 사용량의 크기가 동일 면적의 타 건물들 대비 매우 컸다는 점이다. 지하철 운전을 위한 전기 사용이 각 역 건물에 대해 계량되는 것으로 추측만 할 뿐이다.)</p>

<p>각 건물의 지번별 데이터는 row의 수가 많다. 서울의 경우 데이터 전처리를 해도 만 단위이다. 데이터가 이 정도로 크면, 회귀분석 등을 할 때 모델을 잘 구성했다는 전제 하에 일관성(consistency)이 있다. 즉, 계수추정량이 실제 값에 가까울 확률이 매우 높다. 그러므로 ‘이상한’ data point는 전부 삭제한다.</p>

<p>이번 포스팅에서는 건물 월별 에너지 사용량의 `추이’가 이상한 data point를 판별하는 방법을 설명한다.</p>

<p><br /></p>

<h2 id="건물-월별-에너지-사용량의-추이">건물 월별 에너지 사용량의 ‘추이’</h2>
<p>건물 월별 에너지 사용량의 ‘정상적인’ 추이는 아래 그림과 같다.</p>

<p><img src="/assets/images/monthlyenergytwo/normalpattern.png" alt="normalpattern" class="align-center" />
<em>일반적인 월별 전기 사용량 추이(좌) 와 가스 사용량 추이(우)</em></p>

<p>일반적인 월별 전기 사용량 추이의 경우, 냉방으로 인해 여름의 사용량이 상대적으로 크다. 겨울의 전기 사용량은 봄/가을 대비 약간 크지만 전기난방을 하는 경우 건물에 따라 많이 클 수도 있고, 봄/ 가을과 거의 비슷할 수도 있다. 즉 월별 전기 사용량의 추이는 1~12월 plot 기준으로 중간이 튀어나온 압정 모양 혹은 더블유(W)자 모양을 띤다.</p>

<p>일반적인 월별 가스 사용량 추이의 경우, 난방으로 인해 겨울의 사용량이 매우 크다. 여름의 사용량은 대부분은 매우 작으나, 식당/ 목욕탕 등 비중이 큰 일부 건물에서는 여름에도 봄/ 가을과 비슷한 가스 사용량을 보이기도 한다. 즉 월별 가스 사용량의 추이는 유(U)자 모양을 띤다.</p>

<p><br />
그런데, 이와는 매우 다른 추이를 보이는 data point들이 있다. 예를 들면 아래 그림과 같다.</p>

<p><img src="/assets/images/monthlyenergytwo/abnormalpattern.png" alt="abnormalpattern" class="align-center" />
<em>비정상적인 월별 전기 사용량 추이(좌) 와 가스 사용량 추이(우)</em></p>

<p>정확히는, 위 그림은 `각 월별 사용량이 연간 사용량에서 차지하는 비중’을 나타낸 그림이다. 각 월별 전기 사용량을 원소로 하는 12차원 열벡터를 $y_{i}$라 할 때, 위 그림은 $y_{i} / \Vert y_{i} \Vert_{1}$이다.
위 그림에서 보이는 월별 사용량 추이는, 일반적인 추이와 거리가 멀다. 그러므로 해당 data point를 삭제해야 한다.</p>

<p><br /></p>

<h2 id="비정상적인-추이를-보이는-data-point-판별-방법">비정상적인 추이를 보이는 data point 판별 방법</h2>
<p>그러면, 이상한 추이를 보이는 data point들은 어떻게 판별할 수 있을까? 월별 비중 그림을 일일이 다 그려서? 데이터 size (data point의 개수) 가 수천개만 되어도 이는 불가능하다. 각 data point 별로 어떤 지표(metric)를 계산 후 그 지표의 크기로 이상한 point를 판별하는 방법이 필요하다.</p>

<p>위에서 언급한 각 월별 사용량 비중을 나타내는 벡터 $y_{i} / \Vert y_{i} \Vert_{1}$를 $\tilde{y}_{i}$라 하자. 그리고 모든 건물들에 대한 $\tilde{y}_{i}$들을 ‘행벡터들을 쌓는 방식으로’ 결합하여 만든 행렬 $\tilde{Y} = [\tilde{y}_{1},\tilde{y}_{2},\cdots, \tilde{y}_{N}]^{\top}$ 을 생각하자.</p>

<p>이 때, $i$번째 data point에 대해 스칼라 값 $\tilde{y}_{i}^{\top} (\tilde{Y}^{\top} \tilde{Y})^{-1} \tilde{y}_{i}$ 를 계산할 수 있다. 이 값이 큰 경우, $\tilde{y}_{i}$는 월별 사용량 비중 벡터들이 만드는 12차원 공간 내에서 다른 data point들로부터 멀리 떨어져 있는 ‘remote’ point임이 알려져 있다.</p>

<p>구체적으로는 $\tilde{y}_{i}^{\top} (\tilde{Y}^{\top} \tilde{Y})^{-1} \tilde{y}_{i}$는 행렬 $\tilde{Y} (\tilde{Y}^{\top} \tilde{Y})^{-1} \tilde{Y}^{\top}$의 대각성분이다. 만약 $\tilde{y}_{i}$가 어떤 회귀모델의 설명변수 벡터인 경우, 이를 hat matrix라고 부른다. Hat matrix의 대각성분은, data point들의 중심으로부터의 표준화된 거리를 의미한다.</p>

<p>(자세한 내용은 <a href="https://product.kyobobook.co.kr/detail/S000002582053">Montgomery의 Introduction to Linear Regression</a>의 7단원을 참고하길 바란다.)</p>

<p><br />
그러면 이 스칼라 값이 구체적으로 얼마 이상이면 remote point라고 볼 수 있을까? Rule of thumb가 되는 기준은 $2p/N$으로, $p$는 $\tilde{y}_{i}$가 설명변수 벡터라 할 때 설명변수의 수이고 (월별 에너지 사용량 case의 경우 12), $N$은 data point 수이다.</p>

<p>정리하면, ‘이상한’ 월별 전기 사용량 추이를 갖는 data point들은 아래 과정을 거쳐 판별한다.</p>

<p>1) 모든 data point들에 대한 월별 전기 사용량 자료를 월별 전기 사용량의 ‘비중’ 데이터로 변환 후 각 행이 월별 전기 사용량인 12열짜리 행렬 $\tilde{Y}$로써 결합</p>

<p>2) 위에서 설명한 행렬 $\tilde{Y} (\tilde{Y}^{\top} \tilde{Y})^{-1} \tilde{Y}^{\top}$를 계산</p>

<p>3) $i$번째 대각성분이 $24/N$ 이상인 경우 ‘이상한 월별 전기 사용량 추이’를 갖는 data point로 보고 삭제
이는 월별 가스에 대해서도 마찬가지로 수행한다.</p>

<p>(이상한 추이를 갖는 data point들 그림도, 위 과정을 통해 판별한 것이다)</p>

<p>다음 포스팅에서는 건물 월별 에너지 사용량의 ‘크기(magnitude)’가 이상한 data point를 판별하는 방법을 설명한다.</p>

<div class="notice--info">

건축물 별 월별 에너지 사용량 데이터셋<br /><br />

1) <a href="/monthlyenergyone.html">모든 월에 대한 통합 및 표제부와의 결합 후 SQLite DB화</a><br />
2) <b>월별 사용 추이가 이상한 data point 제거</b><br />
3) <a href="/monthlyenergythree.html">월별 사용량 크기가 이상한 data point 제거</a>

</div>]]></content><author><name>Jeonghun Song</name><email>song4energy@gmail.com</email></author><category term="dataset" /><category term="건물 에너지 데이터" /><category term="회귀분석" /><summary type="html"><![CDATA[이전 포스팅에서, 건물 지번별/월별 전기/도시가스 사용량 데이터와 표제부의 결합을 소개했다. 해당 데이터셋을 그대로 쓰면 되는가? 그렇지 않다. 분명히 ‘이상한’ data point들이 존재할 것이며, 이상한 data point들을 ‘전처리’해야 올바른 연구 결과를 얻을 수 있다.]]></summary></entry></feed>